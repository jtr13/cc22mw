[{"path":"index.html","id":"welcome","chapter":"1 Welcome!","heading":"1 Welcome!","text":"Let’s add content welcome page.Submit pull request .construction","code":""},{"path":"community-contribution.html","id":"community-contribution","chapter":"2 Community Contribution","heading":"2 Community Contribution","text":"fairly open-ended assignment provides opportunity receive credit contributing collective learning class, perhaps beyond. reflect minimum 3 hours work. complete assignment must submit short description contribution. appropriate, attach relevant files.many ways can contribute:organize lead workshop particular topic (date may assignment due date need schedule )help students find final project partnersgive well-rehearsed 5 minute lightning talk class datavis topic (theory tool) (email set date – may assignment due date need schedule )create video tutorial (length)create cheatsheet resourcewrite tutorial tool ’s well documentedbuild viz product (ex. htmlwidget RStudio add-) class usedesign home page (images, text /artwork) web site[idea](Note: translations allowed)may draw expand existing resources. , critical cite sources.","code":""},{"path":"community-contribution.html","id":"important-logistics","chapter":"2 Community Contribution","heading":"2.1 IMPORTANT LOGISTICS","text":"","code":""},{"path":"community-contribution.html","id":"groups","chapter":"2 Community Contribution","heading":"2.1.1 Groups","text":"may work partner choosing. work alone, need join group 1, simply submit work CourseWorks solo assignment.work partner, add group CC page People tab. Ed Discussion can used find partners similar interests.","code":""},{"path":"community-contribution.html","id":"what-to-submit","chapter":"2 Community Contribution","heading":"2.1.2 What to submit","text":"cases something tangible upload, tutorial, cheatsheet, etc. Alternatively may submit link material online (YouTube video, etc.) ’s nothing tangible include longer description (see 2.).cases something tangible upload, tutorial, cheatsheet, etc. Alternatively may submit link material online (YouTube video, etc.) ’s nothing tangible include longer description (see 2.).explanation motivation project, need addresses, evaluation project including learned / might differently next time. (1/2 page)explanation motivation project, need addresses, evaluation project including learned / might differently next time. (1/2 page)","code":""},{"path":"community-contribution.html","id":"submitting-your-assignment","chapter":"2 Community Contribution","heading":"2.1.3 Submitting your assignment","text":"must submit assignment twice: CourseWorks (can graded) class, details follow.CourseWorks submission (assignment): submit work .Rmd rendered .pdf .html file, just problem sets. work lend format, write assignment text box .CourseWorks submission (assignment): submit work .Rmd rendered .pdf .html file, just problem sets. work lend format, write assignment text box .Class (GitHub) submission: detail provided separate assignment.Class (GitHub) submission: detail provided separate assignment.","code":""},{"path":"community-contribution.html","id":"grading","chapter":"2 Community Contribution","heading":"2.1.4 Grading","text":"graded quality work, originality, effort invested. sources used must cited. looking value-added existing resources. example, excellent cheatsheet already exists ggplot2 creating new one useful unless represents significant improvement.","code":""},{"path":"github-submission-instructions.html","id":"github-submission-instructions","chapter":"3 GitHub submission instructions","heading":"3 GitHub submission instructions","text":"chapter gives information need upload community contribution. Please read entire document carefully making submission. particular note fact bookdown requires different .Rmd format ’re used , must make changes beginning file described submitting.","code":""},{"path":"github-submission-instructions.html","id":"background","chapter":"3 GitHub submission instructions","heading":"3.1 Background","text":"web site makes use bookdown package render collection .Rmd files nicely formatted online book chapters subchapters. job submit slightly modified version community contribution .Rmd file GitHub repository source files web site stored. backend, admins divide chapters book sections order .community contribution different format, create short .Rmd file explains , includes links relevant files, slides, etc. can post GitHub repo (another online site.)","code":""},{"path":"github-submission-instructions.html","id":"preparing-your-.rmd-file","chapter":"3 GitHub submission instructions","heading":"3.2 Preparing your .Rmd file","text":"submit ONE Rmd file.completing modifications, .Rmd look like sample .Rmd.Create concise, descriptive name project. instance, name base_r_ggplot_graph something similar work contrasting/working base R graphics ggplot2 graphics. Check .Rmd filenames file make sure name isn’t already taken. project name words joined underscores, white space. Use .Rmd .rmd. addition, letters must lowercase. Create copy .Rmd file new name.Create concise, descriptive name project. instance, name base_r_ggplot_graph something similar work contrasting/working base R graphics ggplot2 graphics. Check .Rmd filenames file make sure name isn’t already taken. project name words joined underscores, white space. Use .Rmd .rmd. addition, letters must lowercase. Create copy .Rmd file new name.Completely delete YAML header (section top .Rmd includes name, title, date, output, etc.) including --- line.Completely delete YAML header (section top .Rmd includes name, title, date, output, etc.) including --- line.Choose short, descriptive, human readable title project title show table contents – look examples panel left. Capitalize first letter (“sentence case”). first line document, enter single hashtag, followed single whitespace, title. important follow format bookdown renders title header. use single # headers anywhere else document.Choose short, descriptive, human readable title project title show table contents – look examples panel left. Capitalize first letter (“sentence case”). first line document, enter single hashtag, followed single whitespace, title. important follow format bookdown renders title header. use single # headers anywhere else document.second line blank, followed name(s):\n# Base R vs. ggplot2\n\nAaron Burr Alexander Hamilton\n\ncontent starts . second line blank, followed name(s):project requires data, please use built-dataset read directly URL, :\ndf <- readr::read_csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\")  absolutely must include data file, please use small one, many reasons desirable keep repository size small possible.project requires data, please use built-dataset read directly URL, :df <- readr::read_csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\")  absolutely must include data file, please use small one, many reasons desirable keep repository size small possible.included setup chunk .Rmd file, please remember remove label setup chunk, .e., use:\n{r, include=FALSE}\ninstead :\n{r setup, include=FALSE}included setup chunk .Rmd file, please remember remove label setup chunk, .e., use:instead :project requires libraries installed included document, please adhere following conventions. evaluate install.packages() statements document. Consumers .Rmd file won’t want packages get installed knit document. Include library() statements top .Rmd file, title, name, setup, content. chapter requires installation package source (GitHub installation), please add comment identifying . Please mention well PR. example library() section install statements won’t evaluated:\n\n# remotes::install_github(\"twitter/AnomalyDetection\")\nlibrary(\"AnomalyDetection\") # must installed sourceIf project requires libraries installed included document, please adhere following conventions. evaluate install.packages() statements document. Consumers .Rmd file won’t want packages get installed knit document. Include library() statements top .Rmd file, title, name, setup, content. chapter requires installation package source (GitHub installation), please add comment identifying . Please mention well PR. example library() section install statements won’t evaluated:developed .Rmd file moving library() statements rest file content, highly recommended knit review document . may change namespace available section code development, causing function work exhibit unexpected behavior.file contain getwd() / setwd() calls (never use scripts anyway!) write statements.Want get fancy? See optional tweaks section .","code":"# Base R vs. ggplot2\n\nAaron Burr and Alexander Hamilton\n\nYour content starts here. {r, include=FALSE}{r setup, include=FALSE}\n# remotes::install_github(\"twitter/AnomalyDetection\")\nlibrary(\"AnomalyDetection\") # must be installed from source"},{"path":"github-submission-instructions.html","id":"submission-steps","chapter":"3 GitHub submission instructions","heading":"3.3 Submission steps","text":"submit work, following “Workflow #4” – submitting pull request someone else’s repository write access. Instructions available lecture slides topic well tutorial. repeated abbreviated form, specific instructions naming conventions, content information, important details.Fork cc22mw repo (repo) GitHub account.Fork cc22mw repo (repo) GitHub account.Clone/download forked repo local computer.Clone/download forked repo local computer.Create new branch name project name, case sample_project. skip step. merge PR doesn’t come branch. already forgot , check tutorial fix .Create new branch name project name, case sample_project. skip step. merge PR doesn’t come branch. already forgot , check tutorial fix .Copy modified .Rmd file name root directory branch. example, sample_project.Rmd.Copy modified .Rmd file name root directory branch. example, sample_project.Rmd.include .html file. (order bookdown package work, .Rmd files rendered behind scenes.)include .html file. (order bookdown package work, .Rmd files rendered behind scenes.)[OPTIONAL] resources (images) included project, create folder resources/. example, resources/sample_project/. Put resources files . sure change links .Rmd include resources/.../, example:\n![Test Photo](resources/sample_project/pumpkins.jpg)[OPTIONAL] resources (images) included project, create folder resources/. example, resources/sample_project/. Put resources files . sure change links .Rmd include resources/.../, example:![Test Photo](resources/sample_project/pumpkins.jpg)ready submit project, push branch remote repo. Follow tutorial create pull request.ready submit project, push branch remote repo. Follow tutorial create pull request.point back forth begin team managing pull requests. asked make changes, simply make changes local branch, save, commit, push GitHub. new commits added pull request; need , , create new pull request. (, based circumstances, make sense close pull request start new one, tell .)point back forth begin team managing pull requests. asked make changes, simply make changes local branch, save, commit, push GitHub. new commits added pull request; need , , create new pull request. (, based circumstances, make sense close pull request start new one, tell .)pull request merged, ’s fine delete local clone (folder) well forked repository GitHub account.pull request merged, ’s fine delete local clone (folder) well forked repository GitHub account.","code":""},{"path":"github-submission-instructions.html","id":"optional-tweaks","chapter":"3 GitHub submission instructions","heading":"3.4 Optional tweaks","text":"prefer links chapter open new tabs, add {target=\"_blank\"} link, :\n[edav.info](edav.info){target=\"_blank\"}prefer links chapter open new tabs, add {target=\"_blank\"} link, :[edav.info](edav.info){target=\"_blank\"}Note headers (##, ###, etc.) converted numbered headings : ## –> 3.1 ### –> 3.1.1  headings appear chapter subheadings sub-subheadings navigation panel left. Think logical structure users navigate chapter. recommend using ## ### headings since “sub-sub-subheadings” 4.1.3.4 generally unnecessary look messy.Note headers (##, ###, etc.) converted numbered headings : ## –> 3.1 ### –> 3.1.1  headings appear chapter subheadings sub-subheadings navigation panel left. Think logical structure users navigate chapter. recommend using ## ### headings since “sub-sub-subheadings” 4.1.3.4 generally unnecessary look messy.Unfortunately, ’s simple way preview chapter ’s actually merged project. (bookdown preview_chapter() option works entire book rendered least become complex require packages project grows.) really want preview , fork clone minimal bookdown repo, add .Rmd file, click “Build book” button Build tab (next Git), open .html files _book folder web browser see rendered book.  ’re interested bookdown options, see official reference book.  useful tweaks share? Submit issue PR.Unfortunately, ’s simple way preview chapter ’s actually merged project. (bookdown preview_chapter() option works entire book rendered least become complex require packages project grows.) really want preview , fork clone minimal bookdown repo, add .Rmd file, click “Build book” button Build tab (next Git), open .html files _book folder web browser see rendered book.  ’re interested bookdown options, see official reference book.  useful tweaks share? Submit issue PR.","code":""},{"path":"github-submission-instructions.html","id":"faq","chapter":"3 GitHub submission instructions","heading":"3.5 FAQ","text":"","code":""},{"path":"github-submission-instructions.html","id":"what-should-i-expect-after-creating-a-pull-request","chapter":"3 GitHub submission instructions","heading":"3.5.1 What should I expect after creating a pull request?","text":"Within week create pull request, apply label assign classmate “PR merger” review files submit see meet requirements.Within week create pull request, apply label assign classmate “PR merger” review files submit see meet requirements.take time can process pull requests, long see pull request repo, don’t worry.take time can process pull requests, long see pull request repo, don’t worry.PR merger contacts regarding pull request, usually means files fail meet requirements. explain wrong, please fix soon possible.PR merger contacts regarding pull request, usually means files fail meet requirements. explain wrong, please fix soon possible.","code":""},{"path":"github-submission-instructions.html","id":"what-if-i-catch-mistakes-before-my-pull-request-is-merged","chapter":"3 GitHub submission instructions","heading":"3.5.2 What if I catch mistakes before my pull request is merged?","text":"Just make changes branch, commit push GitHub. automatically added pull request.","code":""},{"path":"github-submission-instructions.html","id":"what-if-i-catch-mistakes-after-my-pull-request-is-merged","chapter":"3 GitHub submission instructions","heading":"3.5.3 What if I catch mistakes after my pull request is merged?","text":"may submit additional pull requests fix material site. edits small, fixing typos, easiest make edits directly GitHub, following instructions. merge first pull requests edits, please patient.","code":""},{"path":"github-submission-instructions.html","id":"other-questions","chapter":"3 GitHub submission instructions","heading":"3.5.4 Other questions","text":"additional questions, please ask Discussions section respond.Thank contributions!","code":""},{"path":"sample-project.html","id":"sample-project","chapter":"4 Sample project","heading":"4 Sample project","text":"Joe Biden Donald TrumpThis chapter gives sample layout Rmd file.Test Photo","code":""},{"path":"geographic-visualization-by-ggmap.html","id":"geographic-visualization-by-ggmap","chapter":"5 Geographic visualization by ggmap","heading":"5 Geographic visualization by ggmap","text":"Yuta AdachiAs community contribution EDAV class, created cheat sheet geographic visualization using ggmap.link cheat sheet .","code":""},{"path":"geographic-visualization-by-ggmap.html","id":"motivation-for-this-project","chapter":"5 Geographic visualization by ggmap","heading":"5.1 Motivation for this project","text":"sometimes want describe fact using geographic visualization. example, ’m looking shortest path Columbia University Central Park, like see route background road map can understand street walk. However, seems difficult create route map geographic visualizations original ggplot2 packages, far know.R package, “ggmap”, makes easy download choose various kinds map tiles Google Maps Stamen Maps. addition, might feel easy plot data since can deal ggplot2 framework familiar .’s ’m eager learn use ggmap package create cheat sheet everyone.","code":""},{"path":"geographic-visualization-by-ggmap.html","id":"my-own-evaluationroom-for-improvement","chapter":"5 Geographic visualization by ggmap","heading":"5.2 My own evaluation/Room for improvement","text":"creating cheat sheet, learned utilize ggmap package, also type plots can choose geographic visualization. Specifically, order introduce three examples readers can learn use package practical way, researched implemented several types plots related geographic visualization route map scatter plot map.Though learned many things project, can improve cheat sheet adding examples types data visualization. example, may create another density plot using continuous variable, also add flow map describe transitions several locations opportunity create next time.","code":""},{"path":"googlevis.html","id":"googlevis","chapter":"6 googleVis","heading":"6 googleVis","text":"Wenqi SunThe googleVis package provides interface R Google’s charts tools. allows users create web pages interactive charts based R data frames. Charts displayed locally via R HTTP help server. modern browser Internet connection required. data remains local uploaded Google.created cheat sheet googleVis. covers charts options.Link: https://github.com/Nntraveler/googleVis_cheatsheet/blob/main/googleVis.pdf","code":""},{"path":"googlevis.html","id":"motivation-for-this-project-1","chapter":"6 googleVis","heading":"6.1 Motivation for this project","text":"Google Charts powerful tool visualization HTML. provides easy quick way generate interactive charts.advantages include following:variety chartsA variety chartsExtensive set options customizationExtensive set options customizationCross-browser compatibilityCross-browser compatibilityDashboard Controls user interactionDashboard Controls user interactionSupport dynamic dataSupport dynamic dataThe googleVis package provides way use Google charts R conveniently. Although detailed documentation, users may need clarification chart options work cases since cheat sheet.Therefore, creating cheat sheet googleVis, everyone can get easier use googleVis.","code":""},{"path":"googlevis.html","id":"my-own-evaluation-of-the-project","chapter":"6 googleVis","heading":"6.2 My own evaluation of the project","text":"creating cheatsheet, Ihave better understanding Google charts googleVis packagehave better understanding Google charts googleVis packageexperienced happiness contributing something open source projectsexperienced happiness contributing something open source projectsexplored variety cheatsheets found ideal layout projectexplored variety cheatsheets found ideal layout projectWhat’s , think space improvement:options part, better way show use options vividly. Due limited space, just put table .options part, better way show use options vividly. Due limited space, just put table .compressed charts look bad charts like Anno, Cal, Timeline charts. assign space adjust data.compressed charts look bad charts like Anno, Cal, Timeline charts. assign space adjust data.","code":""},{"path":"text-data-visualization-by-tidytext.html","id":"text-data-visualization-by-tidytext","chapter":"7 Text data visualization by tidytext","heading":"7 Text data visualization by tidytext","text":"Xiaolin Sima Yanni ChenAs community contribution, created cheatsheet text data visualization tidytext.\ncheatsheet can found ","code":""},{"path":"text-data-visualization-by-tidytext.html","id":"motivation-for-the-project-and-need-it-addrressed","chapter":"7 Text data visualization by tidytext","heading":"7.1 Motivation for the project and need it addrressed","text":"Text mining natural language processing essential complicated field lot tools ways analyze. However, found tidytext useful door helping us open world text mining. meet text data, using tidytext package can make many text analysis tasks easier effective. Much infrastructure needed text mining tidy data frames already exists widely used packages like dplyr, tidyr ggplot2. way created cheatsheet, providing functions examples allow use tidytext package combined existing infrastructure basic text analysis works.","code":""},{"path":"text-data-visualization-by-tidytext.html","id":"own-evaluation-of-the-project","chapter":"7 Text data visualization by tidytext","heading":"7.2 Own evaluation of the project","text":"creating cheatsheet, learned use tidytext package text frequency sentiment analysis, also got familiar combine tidytext package data visualization tools, example ggplot wordcloud. cheatsheet generally useful someone wants visualize text data analysis, specifically word frequency sentiment analysis using R.However, also places need improve. Adding example limited wine tasting review might one place make cheatsheet generalized. Also, deeper sentiment analysis regarding category can listed analysis room allowed.","code":""},{"path":"cheatsheet-of-ggally-including-ggcoef_model-and-ggpairs.html","id":"cheatsheet-of-ggally-including-ggcoef_model-and-ggpairs","chapter":"8 Cheatsheet of GGally (including ggcoef_model and ggpairs)","heading":"8 Cheatsheet of GGally (including ggcoef_model and ggpairs)","text":"Xinhao Dai","code":""},{"path":"cheatsheet-of-ggally-including-ggcoef_model-and-ggpairs.html","id":"introductions-of-ggally","chapter":"8 Cheatsheet of GGally (including ggcoef_model and ggpairs)","heading":"8.0.1 Introductions of GGally","text":"ggplot2 R package plotting based grammar graphics. GGally extension ggplot2. adds several helpful functions reduce difficulties combining different geoms. enable novices quickly start using packet, create cheatsheet GGally.cheatsheet includes several essential efficient plots explorary data analysis visualization. First, ’s ggcoef_model function, helps visualize coefficients fitted model. ’s intuitive clear. Moreover, enables us compare several models plot can choose best model among . Second, ’s ggpairs() function, shows relationships every two variables dataset. helps us indentify ’s relevent variable response variable. Moreover, cheatsheet display several high-level plots can used ggpairs order help users clear intuiation.project, learned quickly read documents packet distinguish functions essential helpful ones. Moreover, learned create tidy beautiful cheatsheet users. another chance, try create templeate rather use rstudio templeate.can find pdf version cheetsheet https://github.com/Russell-/cheatsheet--ggally. enclosed image cheatsheet.Reference: https://ggobi.github.io/ggally/index.html.","code":""},{"path":"map-plots-with-highcharts.html","id":"map-plots-with-highcharts","chapter":"9 Map Plots with Highcharts","heading":"9 Map Plots with Highcharts","text":"Hugo GinouxHighcharts originally extremely complete Javascript library data visualization. R wrapper version library “highcharter”. difficult understand ggplot2 provides interactivity satisfying.chapter, explore possibility create map charts, say heatmaps colored cells shape countries, regions states. raw example, showing GDP state US (random data):Spectacular, isn’t ? Let’s dive different parts code another example plotting proportion Christians 2020 different European countries.","code":"\nlibrary(highcharter)\nlibrary(dplyr)\nlibrary(readxl)\nmapdata <- get_data_from_map(download_map_data(\"custom/usa-and-canada\"))\n\nfake_gdp <- data.frame(code=mapdata$`hc-a2`) %>%\n  mutate(value = 1e5 * abs(rt(nrow(mapdata), df = 10)))\n\nhcmap(\n  \"custom/usa-and-canada\",\n  data = fake_gdp,\n  value = \"value\",\n  joinBy = c(\"hc-a2\", \"code\"),\n  dataLabels = list(enabled = TRUE, format = \"{point.name}\"),\n  borderColor = \"#FAFAFA\",\n  borderWidth = 0.1,\n  tooltip = list(\n    valueDecimals = 2,\n    valuePrefix = \"$\",\n    valueSuffix = \"USD\"\n  )\n) %>%\n  hc_title(text = \"Fake GDP per State\") %>%\n  hc_add_theme(hc_theme_ffx())"},{"path":"map-plots-with-highcharts.html","id":"collect-data","chapter":"9 Map Plots with Highcharts","heading":"9.0.1 Collect data","text":"need dataframe containing least name contry value plot heatmap. example, data comes https://www.worldreligiondatabase.org/. downloaded form xlsx file, stored personal server.","code":"\ndata = read_excel(\"resources/mapcharts/religions.xlsx\") \ndata = data[data[['Religion 1']]=='Christians', c('Country Name','Religion 1','Pct_2020')]\n\nhead(data)## # A tibble: 6 × 3\n##   `Country Name` `Religion 1` Pct_2020\n##   <chr>          <chr>           <dbl>\n## 1 Afghanistan    Christians   0.000194\n## 2 Albania        Christians   0.376   \n## 3 Algeria        Christians   0.00295 \n## 4 American Samoa Christians   0.980   \n## 5 Andorra        Christians   0.908   \n## 6 Angola         Christians   0.929"},{"path":"map-plots-with-highcharts.html","id":"download-the-map-data-and-filter","chapter":"9 Map Plots with Highcharts","heading":"9.0.2 Download the map data and filter","text":", need download map info get_data_from_map(download_map_data(name_of_geography)). list available geographies examples : https://code.highcharts.com/mapdata/ (lot!). example, need map Europe., keep rows country Europe : filter data mapdata.","code":"\nmapdata = get_data_from_map(download_map_data(\"custom/europe\"))\n\nmapdata## # A tibble: 50 × 14\n##    hc-gr…¹ hc-mi…² hc-mi…³ hc-ke…⁴ `hc-a2` name  label…⁵ count…⁶ subre…⁷ regio…⁸\n##    <chr>     <dbl>   <dbl> <chr>   <chr>   <chr> <chr>   <chr>   <chr>   <chr>  \n##  1 admin0     0.19    0.44 dk      DK      Denm… 4       Den.    Northe… Europe…\n##  2 admin0     0.56    0.16 fo      FO      Faro… 6       Faeroe… Northe… Europe…\n##  3 admin0     0.09    0.39 hr      HR      Croa… 6       Cro.    Southe… Europe…\n##  4 admin0     0.34    0.59 nl      NL      Neth… 5       Neth.   Wester… Europe…\n##  5 admin0     0.6     0.53 ee      EE      Esto… 6       Est.    Northe… Europe…\n##  6 admin0     0.54    0.49 bg      BG      Bulg… 4       Bulg.   Easter… Europe…\n##  7 admin0     0.38    0.53 es      ES      Spain 2       Sp.     Southe… Europe…\n##  8 admin0     0.44    0.38 it      IT      Italy 2       Italy   Southe… Europe…\n##  9 admin0     0.68    0.41 sm      SM      San … 6       S.M.    Southe… Europe…\n## 10 admin0     0.62    0.44 va      VA      Vati… 6       Vat.    Southe… Europe…\n## # … with 40 more rows, 4 more variables: `iso-a3` <chr>, `iso-a2` <chr>,\n## #   `woe-id` <chr>, continent <chr>, and abbreviated variable names\n## #   ¹​`hc-group`, ²​`hc-middle-x`, ³​`hc-middle-y`, ⁴​`hc-key`, ⁵​labelrank,\n## #   ⁶​`country-abbrev`, ⁷​subregion, ⁸​`region-wb`\ndata = data[data[['Country Name']]%in%mapdata$name,]"},{"path":"map-plots-with-highcharts.html","id":"plot-the-map","chapter":"9 Map Plots with Highcharts","heading":"9.0.3 Plot the map","text":"now ready plot first version map! simply call function hcmap arguments:map use : case, “custom/europe” (argument inside download_map_data())data : dataframe containing names countries value plotvalue : name column used heatmap : case, “Pct_2020”joinBy : names columns 2 dataframes corresponding names countries. names must correspond : “UK” first one “United Kingdom” workThe result already interesting. parameters can added make chart even impressive.","code":"\nhcmap(\n  \"custom/europe\",\n  data = data,\n  value = \"Pct_2020\",\n  joinBy = c(\"name\", \"Country Name\")\n)"},{"path":"map-plots-with-highcharts.html","id":"parameters","chapter":"9 Map Plots with Highcharts","heading":"9.0.4 Parameters","text":"","code":""},{"path":"map-plots-with-highcharts.html","id":"add-labels","chapter":"9 Map Plots with Highcharts","heading":"9.0.4.1 Add labels","text":"parameter “datalabels” can display names countries.","code":"\nhcmap(\n  \"custom/europe\",\n  data = data,\n  value = \"Pct_2020\",\n  joinBy = c(\"name\", \"Country Name\"),\n  dataLabels = list(enabled = TRUE, format = \"{point.name}\")\n)"},{"path":"map-plots-with-highcharts.html","id":"plot-in","chapter":"9 Map Plots with Highcharts","heading":"9.0.4.2 Plot in %","text":"parameter “tooltip” allows us modify displayed mouse hovers country. , plotted proportion %, rounded 1 decimal added suffix “%”.","code":"\ndata['Pct_2020_%'] = data['Pct_2020']*100\n\nhcmap(\n  \"custom/europe\",\n  data = data,\n  value = \"Pct_2020_%\",\n  joinBy = c(\"name\", \"Country Name\"),\n  dataLabels = list(enabled = TRUE, format = \"{point.name}\"),\n  tooltip = list(\n    valueDecimals = 1,\n    valueSuffix = '%'\n  )\n)"},{"path":"map-plots-with-highcharts.html","id":"add-title-theme-colors","chapter":"9 Map Plots with Highcharts","heading":"9.0.4.3 Add title, theme, colors","text":"can add title function “hc_title”. also possible add subtitles. function “hc_add_theme” adds theme. Finally, can change min max colors heatmap giving hexadecimal codes function “hc_colorAxis”. missing values always appear white.","code":"\nhcmap(\n  \"custom/europe\",\n  data = data,\n  value = \"Pct_2020_%\",\n  joinBy = c(\"name\", \"Country Name\"),\n  dataLabels = list(enabled = TRUE, format = \"{point.name}\"),\n  tooltip = list(\n    valueDecimals = 1,\n    valueSuffix = '%'\n  )\n) %>%\n  hc_title(text = \"Proportion of Christian per country in 2020\") %>%\n  hc_add_theme(hc_theme_ffx()) %>% \n  hc_colorAxis(minColor = \"#4242f5\", maxColor = \"#f54242\")"},{"path":"introduction-of-machine-learning-in-r.html","id":"introduction-of-machine-learning-in-r","chapter":"10 Introduction of machine learning in R","heading":"10 Introduction of machine learning in R","text":"Feifan Li","code":"\nlibrary(caret)\nlibrary(mlbench)\nlibrary(naivebayes)\nlibrary(rpart)\nlibrary(randomForest)\nlibrary(ggplot2)\nlibrary(lattice)\nlibrary(recipes)\nlibrary(dplyr)\nlibrary(AppliedPredictiveModeling)\nlibrary(gridExtra)\nlibrary(caTools)"},{"path":"introduction-of-machine-learning-in-r.html","id":"introduction","chapter":"10 Introduction of machine learning in R","heading":"10.1 Introduction","text":"Nowadays, Machine learning useful tool data-driven world. Social applications like Facebook WhatsApp made data accessible, companies can use data magic things like customer classification, fraud detection, decision making, advertising strategy. data helps companies serve customers effective way. one important tool process interpret data machine learning. help reveal many hidden patterns behind numbers. Hence, tutorial help get basic understanding use machine learning R. Since R efficient data processing data visualization, machine learning can incorporated easy way.","code":""},{"path":"introduction-of-machine-learning-in-r.html","id":"required-packages","chapter":"10 Introduction of machine learning in R","heading":"10.2 Required Packages:","text":"tutorial, need import packages. depend others.Packages required:\n1.caret\n2.mlbench\n3.naivebayes\n4.rpart\n5.randomForest\n6.ggplot2\n7.lattice\n8.recipes\n9.dplyr\n10.AppliedPredictiveModeling\n11.gridExtra\n12.caTools","code":""},{"path":"introduction-of-machine-learning-in-r.html","id":"data-preprocessing","chapter":"10 Introduction of machine learning in R","heading":"10.3 Data Preprocessing","text":"","code":""},{"path":"introduction-of-machine-learning-in-r.html","id":"load-dataset","chapter":"10 Introduction of machine learning in R","heading":"10.3.1 Load DataSet","text":"tutorial, just import built-dataset R library, iris. several different ways read dataset R. First , file csv file, can use “read_csv” read . file R file, can use “load” command import dataset. file txt file, can use “read.delim”: specifying separator, can break lines chunks.","code":"\n#load data and name it as iris\n#iris <- read.csv(\"iris.csv\", header=FALSE)\n\n#set header\ncolnames(iris) <- c(\"Sepal.Length\",\"Sepal.Width\",\"Petal.Length\",\"Petal.Width\",\"Species\")"},{"path":"introduction-of-machine-learning-in-r.html","id":"split-the-dataset","chapter":"10 Introduction of machine learning in R","heading":"10.3.2 Split the Dataset","text":"preprocess data, need split dataset train set test set. train set, train model set test model’s accuracy test set. split ensures independency train test stes.ratio, usually assume 80% versus 20%, means 80% data training set, remaining 20% test set. can adjust ratio based actual dataset. However, set ratio large, assign dataset train set, leaves little data tests. hand, ratio low, model receive sufficient training, influencing accuracy.","code":"\ntrainIndex <- createDataPartition(iris$Species, p = 0.8, \n                                  list = FALSE, \n                                  times = 1)\n\ntrain_set <- iris[trainIndex,]\ntest_set <- iris[-trainIndex,]\n\n#check size\nnrow(train_set)## [1] 120\nnrow(test_set)## [1] 30"},{"path":"introduction-of-machine-learning-in-r.html","id":"scaling","chapter":"10 Introduction of machine learning in R","heading":"10.3.3 Scaling","text":"two different ways adjust scale data: Scaling Centering. scaling, basically calculates Z score datapoint, formula \\(X-u/\\sigma\\). Moreover, another way centering, just subtracts data mean.graph , can see standardizing datapoints shifts mean 0 change overall distribution","code":"\nScaled_values <- preProcess(iris, method = c(\"center\", \"scale\"))\ntrain_scaled <- predict(Scaled_values, train_set)\ntest_scaled <- predict(Scaled_values, test_set)\n\nggplot(train_set, aes(x=Species, y=Sepal.Length))+\n  geom_point() +\n  ggtitle(\"Distribution of datapoint before scailing\")\nggplot(train_scaled, aes(x=Species, y=Sepal.Length))+\n  geom_point() +\n  ggtitle(\"Distribution of datapoint after scailing\")"},{"path":"introduction-of-machine-learning-in-r.html","id":"missing-value","chapter":"10 Introduction of machine learning in R","heading":"10.3.4 Missing Value","text":"datasets, usually contains missing values. case, need impute values, several ways achieve goal, including mean, KNN, Random Forest, special symbols. tutorial, briefly discuss common two methods: KNN mean.Mean\nOne easy way fill missing value using mean. example, one column feature contains several missing values, can compute average non-missing values fill value missing positions. advantage method efficient easy implement; however, filing mean accurately predict value, influences accuracy.KNNAnother common way use K nearest neighbor. specific, datapoint, can compute K nearest neighbor. using average neighbors’ values fill missing positions. One advantage method accuracy usually higher filing mean. However, KNN imputation take much longer time compute results, especially datasets high dimensions, called “curse dimensions”.","code":""},{"path":"introduction-of-machine-learning-in-r.html","id":"dimension-reduction","chapter":"10 Introduction of machine learning in R","heading":"10.3.5 Dimension Reduction","text":"datasets, include 50 100 features, directly training model original dataset consume huge amount time. Therefore, need reduce dimensions dataset make training efficient. Common methods like PCA (Principle Component Analysis) LDA (Linear Discriminant Analysis) useful dimension reductions. tutorial, talk PCA.PCA, Principle Component Analysis, effective method reducing dimensions. main mechanism PCA keeps data largest variance, preserves information.","code":"\npc <- prcomp(train_set[,c(1,2,3,4)],\n             center = TRUE,\n             scale. = TRUE)\n\n#print resutls after PCA\nprint(pc)## Standard deviations (1, .., p=4):\n## [1] 1.7102692 0.9489550 0.3953923 0.1346422\n## \n## Rotation (n x k) = (4 x 4):\n##                     PC1        PC2        PC3        PC4\n## Sepal.Length  0.5109847 0.41819189 -0.7042724  0.2607883\n## Sepal.Width  -0.2915540 0.90588239  0.2778236 -0.1311007\n## Petal.Length  0.5801762 0.02761653  0.1404367 -0.8018170\n## Petal.Width   0.5632818 0.06107341  0.6380376  0.5214323"},{"path":"introduction-of-machine-learning-in-r.html","id":"feature-selection","chapter":"10 Introduction of machine learning in R","heading":"10.3.6 Feature Selection","text":"Besides PCA, another way reduce dimension feature selection. Specifically, can use metrics filter unimportant features, keeping important ones. common metric use Pearson Coefficient. calculating pearson coefficient, can measure strong dependent variable related independent variable. , can drop features low coefficient.","code":"\ntarget = iris$Sepal.Length\n\ncor(iris$Sepal.Width,target)## [1] -0.1175698\ncor(iris$Petal.Length,target)## [1] 0.8717538\ncor(iris$Petal.Width,target)## [1] 0.8179411"},{"path":"introduction-of-machine-learning-in-r.html","id":"categorical-features","chapter":"10 Introduction of machine learning in R","heading":"10.3.7 Categorical Features","text":"categorical features, machine learning models directly process like numerical features. case, need convert categorical features numerical ones. One method called One hot Encoding. example, strings “red”,“green”, “yellow”. , “red” can represented 100, green 010, yellow 001. Even though one hot encoding can convert categorical features, obvious disadvantage: significantly increase dimensions dataset, slow efficiency model.","code":""},{"path":"introduction-of-machine-learning-in-r.html","id":"exploratory-data-analysis","chapter":"10 Introduction of machine learning in R","heading":"10.4 Exploratory Data Analysis","text":"train fit model dataset, can firstly exploratory analysis visualize dataset clear way.First , can use box-plot display overall distribution feature related target (Species). graph, can see species “Iris-Virginica” highest value nearly four features, “Iris-Setosa” lowest.showing distribution, can visualize number kind dataset. pie chart , can see three classes equal proportions: occupy 1/3 total data points.Lastly, can explore colinearity features. scatter plot , can see exist strong positive relationship Petal length Petal width.","code":"\np1 <- ggplot(data=train_set,aes(x=Species,y=Sepal.Length))+\n  geom_boxplot(fill=\"red\")\n\np2 <- ggplot(data=train_set,aes(x=Species,y=Sepal.Width))+\n  geom_boxplot(fill=\"blue\")\n\np3 <- ggplot(data=train_set,aes(x=Species,y=Petal.Length))+\n  geom_boxplot(fill=\"green\")\n\np4 <- ggplot(data=train_set,aes(x=Species,y=Petal.Width))+\n  geom_boxplot(fill=\"gray\")\n\ngrid.arrange(p1,p2,p3,p4,nrow=2)\nggplot(data=train_set,aes(x=Species,fill=Species))+\n  geom_histogram(stat=\"count\",width=1)+\n  coord_polar(\"x\",start=0) +\n  ggtitle(\"Proportion of three classes\")\ng1 <- ggplot(data=train_set,aes(x=Sepal.Length,y=Sepal.Width))+\n  geom_point()+\n  geom_smooth()\n\ng2 <- ggplot(data=train_set,aes(x=Sepal.Length,y=Petal.Length))+\n  geom_point()+\n  geom_smooth()\n\ng3 <- ggplot(data=train_set,aes(x=Sepal.Length,y=Petal.Width))+\n  geom_point()+\n  geom_smooth()\n\ng4 <- ggplot(data=train_set,aes(x=Sepal.Width,y=Petal.Length))+\n  geom_point()+\n  geom_smooth()\n\ng5 <- ggplot(data=train_set,aes(x=Sepal.Width,y=Petal.Width))+\n  geom_point()+\n  geom_smooth()\n\ng6 <- ggplot(data=train_set,aes(x=Petal.Length,y=Petal.Width))+\n  geom_point()+\n  geom_smooth()\n\ngrid.arrange(g1,g2,g3,g4,g5,g6,nrow=3)"},{"path":"introduction-of-machine-learning-in-r.html","id":"training-model","chapter":"10 Introduction of machine learning in R","heading":"10.5 Training Model","text":"previous part, can get basic understanding overall patterns dataset. section, start train fit machine learning models . First , train evaluate model efficient way, can use K-fold cross validation. general procedure firstly shuffle data random way split data several groups. iteration, test model one group, train remaining groups. graph illustrate process clear way.K Fold Cross Validation Process","code":"\nr_cv <- trainControl(method=\"repeatedcv\", \n                        number=10,\n                        repeats=5)"},{"path":"introduction-of-machine-learning-in-r.html","id":"knn","chapter":"10 Introduction of machine learning in R","heading":"10.5.1 KNN","text":"One intuitive machine learning model KNN, K nearest neighbor. idea firstly compute closest K neighbors; , can use majority voting derive result. example, k=5, three five neighbors label 1, two label 0, result 1. One advantage algorithm training process. small datasets, can complete prediction short amount time. However, dimension dataset increases, algorithm suffer curse dimensionK Fold Cross Validation ProcessAdvantage:\n1. easy implement, nearly training process\n2. can deal non-linear problems\n3. efficient accurate small datasetDisadvantage:1. Extremely slow large dataset\n2. Require feature scaling. Inappropriate scales significantly influence accuracy\n3. Suffer curse dimensions. data large number features, algorithm work well.","code":"\nset.seed(10)\nKNN <- train(Species~., \n             data=train_set, \n             method=\"knn\", \n             metric=\"accuracy\", \n             trControl=r_cv)\n\nggplot(KNN)"},{"path":"introduction-of-machine-learning-in-r.html","id":"random-forest","chapter":"10 Introduction of machine learning in R","heading":"10.5.2 Random Forest","text":"Another common machine learning model Random Forest. utilizes idea bagging, bootstraps samples dataset. iteration, train decision tree based samples provided. last step, can assemble different decision trees together. final results average output trees. accuracy random Forest much better single decision tree.Advantage:\n1. higher accuracy single decision tree\n2. can deal classification problems regression problems\n3. low variance due baggingDisadvantage: 1. number trees large, take huge amount time train\n2. Compared normal decision tree, low interpretability. looks like black box, visualize process easily.\n3. Still likely overfit","code":"\nset.seed(10)\nRF <- train(Species~., \n             data=train_set, \n             method=\"rf\", \n             metric=\"accuracy\", \n             trControl=r_cv)\n\nggplot(RF)"},{"path":"introduction-of-machine-learning-in-r.html","id":"svm","chapter":"10 Introduction of machine learning in R","heading":"10.5.3 SVM","text":"powerful machine learning model called SVM, Support Vector Machine. idea behind algorithm tries find hyperplane can separate two classes way maximize margin, can regarded optimal classification. Another key feature SVM called kernel trick. allows SVM deal datasets high dimensions. kernel function can compute inner product original space, project high dimensions, saves huge amounts computation. trick also helps us deal non-linear problems: data linear-separable low dimension separable higher dimension., besides radial basis kernel function, actually many kernel function. example, linear kernel function can useful linear-separable problems. polynominal kernel function can project datapoints higher dimensional space, making easier classify. reality, need try different kernel functions see one works better.Advantage:\n1. effective data high dimensions\n2. can deal linear non-linear separable problems\n3. highly accurate influenced outliersDisadvantage:\n1. size dataset large, take long time train\n2. low Interpretability, like black box\n3. many parameters need tune, hard choose best kernel function.","code":"\nset.seed(10)\nSVM <- train(Species~., \n             data=train_set, \n             method=\"svmRadial\", \n             metric=\"accuracy\", \n             trControl=r_cv)\n\nggplot(SVM)"},{"path":"introduction-of-machine-learning-in-r.html","id":"gradient-boosting","chapter":"10 Introduction of machine learning in R","heading":"10.5.4 Gradient Boosting","text":"Gradient boosting receives attention recent years, especially XGBoost. machine learning model widely used many competitions projects. main idea gradient boosting train series weak learning. Unlike bagging, generation model can completed last model fully trained. iteration, weak learner trained fit residual. several iterations, add weak learners together, constituting strong learner. many variations Gradient Boosting like AdaBoost, XGBoost, LightGBM.Advantage:\n1. results highly accurate\n2. need data scailing preprocessing. can handle numerical categorical features\n3. can deal missing valuesDisadvantage:\n1. dataset large, become computationally expensive\n2. low Interpretability, like black box\n3. many parameters need tune, taking long time find best set parameter.","code":"\nset.seed(10)\nGBM <- train(Species~., \n             data=train_set, \n             method=\"gbm\", \n             metric=\"accuracy\", \n             trControl=r_cv,\n             verbose = FALSE)\n\nggplot(GBM)"},{"path":"introduction-of-machine-learning-in-r.html","id":"naive-bayes","chapter":"10 Introduction of machine learning in R","heading":"10.5.5 Naive Bayes","text":"Naive Bayes one famous algorithm family supervised learning. algorithm founded based Bayes’ theorem, theorem showed picture attached . many types Naive Bayes Classifier, Bernoulli Naive Bayes, Gaussian Naive Bayes, Laplace Naive Bayes. need take closer look actual dataset order determine type use.Bayes TheoremAdvantage:\n1. Algorithm straightforward, easy implement\n2. Training process fast computations probabilities can completely instantly\n3. memory efficientDisadvantage:\n1. algorithm founded basis variable conditionally independent, assume independence real life\n2. accurate many cases\n3. Hard determine type Naive Bayes use maximize accuracy.","code":"\nset.seed(10)\nNaive_Bayes <- train(Species~., \n             data=train_set, \n             method=\"naive_bayes\", \n             metric=\"accuracy\", \n             trControl=r_cv)\n\nNaive_Bayes## Naive Bayes \n## \n## 120 samples\n##   4 predictor\n##   3 classes: 'setosa', 'versicolor', 'virginica' \n## \n## No pre-processing\n## Resampling: Cross-Validated (10 fold, repeated 5 times) \n## Summary of sample sizes: 108, 108, 108, 108, 108, 108, ... \n## Resampling results across tuning parameters:\n## \n##   usekernel  Accuracy   Kappa \n##   FALSE      0.9483333  0.9225\n##    TRUE      0.9500000  0.9250\n## \n## Tuning parameter 'laplace' was held constant at a value of 0\n## Tuning\n##  parameter 'adjust' was held constant at a value of 1\n## Accuracy was used to select the optimal model using the largest value.\n## The final values used for the model were laplace = 0, usekernel = TRUE\n##  and adjust = 1."},{"path":"introduction-of-machine-learning-in-r.html","id":"compare-models","chapter":"10 Introduction of machine learning in R","heading":"10.5.6 Compare Models","text":"can compare five models togetherFrom statistic , can see KNN best performance dataset.","code":"\nresults <- resamples(list(Naive_bayes=Naive_Bayes, GBM=GBM, KNN=KNN, SVM=SVM, RF=RF))\nsummary(results)## \n## Call:\n## summary.resamples(object = results)\n## \n## Models: Naive_bayes, GBM, KNN, SVM, RF \n## Number of resamples: 50 \n## \n## Accuracy \n##                  Min.   1st Qu.    Median      Mean 3rd Qu. Max. NA's\n## Naive_bayes 0.8333333 0.9166667 0.9166667 0.9500000       1    1    0\n## GBM         0.7500000 0.9166667 0.9166667 0.9466667       1    1    0\n## KNN         0.9166667 0.9166667 1.0000000 0.9683333       1    1    0\n## SVM         0.8333333 0.9166667 0.9166667 0.9533333       1    1    0\n## RF          0.7500000 0.9166667 0.9583333 0.9516667       1    1    0\n## \n## Kappa \n##              Min. 1st Qu. Median   Mean 3rd Qu. Max. NA's\n## Naive_bayes 0.750   0.875 0.8750 0.9250       1    1    0\n## GBM         0.625   0.875 0.8750 0.9200       1    1    0\n## KNN         0.875   0.875 1.0000 0.9525       1    1    0\n## SVM         0.750   0.875 0.8750 0.9300       1    1    0\n## RF          0.625   0.875 0.9375 0.9275       1    1    0"},{"path":"introduction-of-machine-learning-in-r.html","id":"metric-evaluation","chapter":"10 Introduction of machine learning in R","heading":"10.6 Metric & Evaluation","text":"order evaluate performance machine learning models, need use several metrics. different kinds problems, adopt different metrics. example, regression problems, can use R-squared measure strength regression. classification problems, can use confusion matrix ROC curve. section, talk metrics details","code":""},{"path":"introduction-of-machine-learning-in-r.html","id":"regression","chapter":"10 Introduction of machine learning in R","heading":"10.6.1 Regression","text":"regression problems, common metric use R-squared. \\(R^2\\) measures proportion dependent variable explained independent variable. range \\(R^2\\) 0 1. value 1.0, means every datapoint perfectly fitted; however, value 0.0, means datapoint fitted correctly. One problem metric number variables increases, \\(R^2\\) increases well. Hence, order negate effect, Adjusted R-Squared introduced, divided degree freedom.R-Squared","code":""},{"path":"introduction-of-machine-learning-in-r.html","id":"classifcation","chapter":"10 Introduction of machine learning in R","heading":"10.6.2 Classifcation","text":"Confusion Matrix\nclassification problems, confusion matrix can regarded intuitive way visualize performance. confusion matrix, correct results True Positive (TP) TN (True Negative), incorrect ones False Negative (FN) False Positive (FP). Based four values, can compute precision recall. Precision measure accurately model predict, recall indicate whether relevant cases retrieved. reality, precision recall usually negative related. case, F1 score introduced, combines precision recall, representative metric model’s performance.Confusion MatrixROC curve\nAnother nice metric often use ROC curve. graph drawn basis True positive rate (TPR) False positive rate (FPR). area curve called Area Curve (AUC). area equal 1, means machine learning model predicts perfectly every datapoint. area 0.5, model behaves like fair coin. 0, means model makes false predictions every time.ROC Curve","code":"\nresults <- predict(KNN, test_set)\nconfusionMatrix(results, as.factor(test_set$Species))## Confusion Matrix and Statistics\n## \n##             Reference\n## Prediction   setosa versicolor virginica\n##   setosa         10          0         0\n##   versicolor      0          9         0\n##   virginica       0          1        10\n## \n## Overall Statistics\n##                                           \n##                Accuracy : 0.9667          \n##                  95% CI : (0.8278, 0.9992)\n##     No Information Rate : 0.3333          \n##     P-Value [Acc > NIR] : 2.963e-13       \n##                                           \n##                   Kappa : 0.95            \n##                                           \n##  Mcnemar's Test P-Value : NA              \n## \n## Statistics by Class:\n## \n##                      Class: setosa Class: versicolor Class: virginica\n## Sensitivity                 1.0000            0.9000           1.0000\n## Specificity                 1.0000            1.0000           0.9500\n## Pos Pred Value              1.0000            1.0000           0.9091\n## Neg Pred Value              1.0000            0.9524           1.0000\n## Prevalence                  0.3333            0.3333           0.3333\n## Detection Rate              0.3333            0.3000           0.3333\n## Detection Prevalence        0.3333            0.3000           0.3667\n## Balanced Accuracy           1.0000            0.9500           0.9750"},{"path":"introduction-of-machine-learning-in-r.html","id":"conclusion","chapter":"10 Introduction of machine learning in R","heading":"10.7 Conclusion","text":"tutorial, can grasp basic understanding general procedures machine learning model training. First , start train model, preprocess data, significantly improve efficiency model training. numerical features, can use standardization centering adjust scale, prevents data distortions. categorical features, may use one-hot encoding convert categorical features numerical ones. , reduce dimension dataset, can use PCA transform data simplified form. Furthermore, second step EDA, gives audiences insight overall patterns data going train. part can easily done using R R language suitable data visualization data analysis. fourth step, start train machine learning model. various types machine learning model choose: KNN, Random Forest, SVM, Gradient Boost, Naive Bayes, etc. one choose, depends actual dataset user’s experience. last step, order assess performance model, need use several metrics. regression, can use R-squared Adjusted R-squared; classification, can use confusion matrix ROC curve. general, tutorial introduction machine learning, many complicated algorithms data processing procedures, leaving space users explore.","code":""},{"path":"introduction-of-machine-learning-in-r.html","id":"sources","chapter":"10 Introduction of machine learning in R","heading":"10.8 Sources","text":"https://www.rdocumentation.org/packages/caret/versions/6.0-92https://scikit-learn.org/stable/https://dhirajkumarblog.medium.com/top-4-advantages--disadvantages--support-vector-machine--svm-a3c06a2b107","code":""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"quantmod-tidyquant-tutorials-and-comparison","chapter":"11 Quantmod & Tidyquant Tutorials and Comparison","heading":"11 Quantmod & Tidyquant Tutorials and Comparison","text":"Mildred Ouyang Peishan Lyu","code":"\n#install.packages(“quantmod”) \n#install.packages(\"tidyverse\")\n#install.packages(\"tidyquant\")\nlibrary(\"quantmod\")\nlibrary(\"tidyverse\")\nlibrary(\"tidyquant\")"},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"motivation","chapter":"11 Quantmod & Tidyquant Tutorials and Comparison","heading":"11.1 Motivation:","text":"Quantmod tutorials documentations found provide quick starter guide beginners R people new using Quantmod. goal tutorial Quantmod teach starters use essential exploratory data analysis tools commonly used functions Quantmod. also hope tutorial can serve bridge users explore advanced features Quantmod future.feel tutorial nice job telling users tasks can completed cores functions Quantmod Tidyquant. make improvements, might create additional cheatsheet illustrate required arguments function users can conveniently make flexible advanced adjustments based needs.","code":""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"quantmod","chapter":"11 Quantmod & Tidyquant Tutorials and Comparison","heading":"11.2 Quantmod","text":"","code":""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"getting-data","chapter":"11 Quantmod & Tidyquant Tutorials and Comparison","heading":"11.2.1 Getting Data:","text":"function used load data : getSymbols(). return object stores data.specifying source (src=“source_name”) getSymbols(), Quantmod use default source Yahoo Finance. common data sources download data :Yahoo, Federal Reserve Economic Data (FRED), local database source using MySQL, csv files, .(Note: Google Finance longer data source. stopped providing data March, 2018.)getting data local database using MySQL, username password access database can stored using wrapper function: setDefaults(getSymbols.MySQL, user=‘____’, password=‘____’, dbname=‘_____’). setting , user can get data using getSymbols() change src=‘MySQL’.Data range can specified passing range start end dates, end date optional. end date, latest available data shown.Example:","code":"\ngetSymbols(\"META\", src=\"yahoo\", from=\"2022-01-01\", to=\"2022-6-30\")## [1] \"META\"\ngetSymbols(\"TSLA;AAPL;UBER\", src=\"yahoo\", from=\"2022-01-01\", to=\"2022-6-30\")## [1] \"TSLA\" \"AAPL\" \"UBER\""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"data-visualization","chapter":"11 Quantmod & Tidyquant Tutorials and Comparison","heading":"11.2.2 Data Visualization:","text":"three primary chart types Quantmod: bar chart, candle chart, line chart.\nPrimary function create charts: chartSeries() - default, open-high-low-close chart volume data shown.Wrapper functions: barChart(), candleChart(), lineChart()Modify original chart: reChart() - can dynamically change chart specifying changing argument(s). can used can log-scale y-axis, subset data show specific time period, set ticks, range y-axis, chart title, colors, .Examples:shows open-high-low-close chart volume data. orange color signifies closing price lower opening price day. green color signifies opposite.Users can also add stock indicators chart analysis. 26 indicators available Quantmod. commonly used stock indicators : Bollinger Bands - addBBands(), Moving Average Convergence Divergence - addMACD(), Commodity Channel Index - addCCI(), Volume - addVo(), Williams %R - addWPR(), Simple Moving Average - addSMA(), Rate Change - addROC(), Momentum - addMomentum(), Parabolic Stop Reverse - addSAR(), .Example:\nexample adds Moving Average Convergence Divergence (MACD) indicator original graph. method output two graphs, one original one MACD. Later, introduce way output one graph. MACD following arguments: fast, slow, signal, type, histogram, col. fast slow address length fast slow periods. signal addresses length signal period. type indicates type moving average use. histogram takes boolean values either output histogram. Lastly, col optional. changes color lines. second graph drawn default values MACD (fast = 12, slow = 26, signal = 9, type = “EMA”, histogram = TRUE).indicator can also passed directly argument chartSeries function. way, one graph drawn.Example:\nchart shows Bollinger Bands drawn default argument values. default sets moving average period (n) 20, standard deviation (sd) 2, moving average type (maType) simple moving average (can also changed weighted moving avarage ), also indicator draw (draw) ‘bands’ (can also changed percent width).chart shows moving average period 20 days.chart shows moving average period 40 days.Multiple indicators can passed together reflect graph.\ngraph shows Bollinger Bands Moving Average Convergence Divergence indicator (default argument values).line chart plots opening data stock.bar chart plots highest, lowest, opening(right horizontal line), closing (left horizontal line) prices stock.want show highest, lowest, closing price one day, user can following:candle chart graphs OHLC data.Customization chart’s color can done passing arguments multi.col theme.multi.col - changes color bars\ntheme - changes color backgroundExamples:Moreover, Quantmod also allows graphing portion data. subset argument can used select specific range data graph.Example:\ngraph plots first two months data.Subset can also take value like “first 3 months” “last 6 weeks”.Furthermore, Qauntmod allows modifications original graph without restating original arguments .Example:","code":"\nchartSeries(META)\nchartSeries(META)\naddMACD()\nchartSeries(META, TA = \"addBBands(n=20, sd=2, maType = 'SMA', draw = 'bands')\")\nchartSeries(META, TA = \"addSMA(n=20)\")\nchartSeries(META, TA = \"addSMA(n=40)\")\nchartSeries(META, TA = \"addBBands();addMACD()\")\nlineChart(META)\nbarChart(META)\nbarChart(META, bar.type='hlc')\ncandleChart(META)\nchartSeries(META, multi.col = TRUE)\nchartSeries(META, theme = \"white\")\nchartSeries(META, multi.col = TRUE, theme = \"white\", subset = \"2022-1::2022-2\")\nchartSeries(META, subset = \"last 6 weeks\")\nchartSeries(META, multi.col = TRUE)\nreChart(major.ticks = \"months\") # change the tick mark to months"},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"tidyquant","chapter":"11 Quantmod & Tidyquant Tutorials and Comparison","heading":"11.3 Tidyquant","text":"Tidyquant integrates quantmod, xts, zoo, TTR, PerformanceAnalytics packages, can use generate tidier graphs using Quantmod . general, can use Tidyquant compare stock prices, evaluate stock performance, evaluate portfolio performance. can easily perform financial analysis using core tidyquant functions get stock indexes/exchange, get quantitative data various web-sources, transmute mutate quantitative data, analyze performance assets portfolios.major functions introduced originally adapted documentation:https://cran.r-project.org/web/packages/tidyquant/contains Vignettes introducing core functions charting Tidyquant.feel original documentation core functions tidy useful, authors derive different datasets using different tools, makes little hard compare similarities differences among tools deriving data. attempted use different tools achieve data four companies included details new tips. tutorial provides basic ideas get data, clean data, chart Tidyquant.","code":""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"before-getting-data","chapter":"11 Quantmod & Tidyquant Tutorials and Comparison","heading":"11.3.1 Before Getting Data","text":"getting quantitative data, want check list stock index possibly retrieve. eighteen available (5 shown ). measure performance assets different perspectives.three stock exchanges (exhange securities happen) available.browsing specific data sources accessible tq_get, can get daily stock data Yahoo Finance, economic data FRED Quandl, well financial data Quandl, Tiingo, Alpha Vantage, Bloomberg’s Financial API (though paid account required Bloomberg).“stock.prices” - Yahoo Finance“stock.prices” - Yahoo Finance“economic.data” - FRED“economic.data” - FRED“quandl” “quandl.datatable” - Nasdaq API“quandl” “quandl.datatable” - Nasdaq API“tiingo”, “tiingo.iex”, “tiingo.crypto” - Tiingo API“tiingo”, “tiingo.iex”, “tiingo.crypto” - Tiingo API“alphavantager”, “alphavantage” - Alpha Vantage API“alphavantager”, “alphavantage” - Alpha Vantage API“rblpapi” - Bloomberg“rblpapi” - Bloomberg","code":"\ntq_index_options()## [1] \"DOW\"       \"DOWGLOBAL\" \"SP400\"     \"SP500\"     \"SP600\"\ntq_exchange_options()## [1] \"AMEX\"   \"NASDAQ\" \"NYSE\"\ntq_get_options()##  [1] \"stock.prices\"       \"stock.prices.japan\" \"dividends\"         \n##  [4] \"splits\"             \"economic.data\"      \"quandl\"            \n##  [7] \"quandl.datatable\"   \"tiingo\"             \"tiingo.iex\"        \n## [10] \"tiingo.crypto\"      \"alphavantager\"      \"alphavantage\"      \n## [13] \"rblpapi\""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"getting-data-1","chapter":"11 Quantmod & Tidyquant Tutorials and Comparison","heading":"11.3.2 Getting Data","text":"Example calling tq_index(“INDEXNAME”) functionSP500 provides dataset 8 columns capitalization-weighted index companies higher market cap receives higher weighting index.Examples calling tq_get() function(1). Getting data Yahoo!Finance - set tq_get(…get = “stock.prices”…)want get stock prices companies, Yahoo!Finance great choice.Assume want stock prices Apple, Meta, Tesla, Uber:(2). Getting data FRED Economic data - tq_get() function - set tq_get(…get = “economic.data”…)considering want retrieve data FRED, consider covers major areas macroeconoc analysis, including major indicators:Growth: GDP, real GDP, real potential GDPGrowth: GDP, real GDP, real potential GDPPrices inflation: CPI urban consumers items/items less food & energy, GDP: implicit price deflaterPrices inflation: CPI urban consumers items/items less food & energy, GDP: implicit price deflaterMoney Supply: St.Louise adjusted monetary, M1 money stock, M2 money stock, velocity M1 money stock, velocity M2 money stockMoney Supply: St.Louise adjusted monetary, M1 money stock, M2 money stock, velocity M1 money stock, velocity M2 money stockInterest rates: effective federal funds rate, 3-month treasury bill, 5/10/30 year treasury constant maturity rate, 5/10 year breakeven inflation rate, 5 year forward inflation expectation rate, TED Spread, bank prime loan rateInterest rates: effective federal funds rate, 3-month treasury bill, 5/10/30 year treasury constant maturity rate, 5/10 year breakeven inflation rate, 5 year forward inflation expectation rate, TED Spread, bank prime loan rateEmployment: Civilian Unemployment Rate, Natural Long-Term/Short-Term Rate Unemployment, Civilian Labor Force Participation Rate, Civilian Employment-Population Ratio, Unemployed, Employees: Total nonfarm, Employees: Manufacturing, Initial Claims, 4-Week Moving Average Initial ClaimsEmployment: Civilian Unemployment Rate, Natural Long-Term/Short-Term Rate Unemployment, Civilian Labor Force Participation Rate, Civilian Employment-Population Ratio, Unemployed, Employees: Total nonfarm, Employees: Manufacturing, Initial Claims, 4-Week Moving Average Initial ClaimsIncome expenditure: Real Median Household Income United States, Real Disposable Personal Income, Personal Consumption Expenditures, Personal Consumption Expenditures: Durable Goods, Personal Saving Rate, Real Retail Food Services Sales, Disposable personal income.Income expenditure: Real Median Household Income United States, Real Disposable Personal Income, Personal Consumption Expenditures, Personal Consumption Expenditures: Durable Goods, Personal Saving Rate, Real Retail Food Services Sales, Disposable personal income.economic indicators: Industrial Production Index, Capacity Utilization: Total Industry, Housing Starts: Total: New Privately Owned Housing Units Started, Gross Private Domestic Investment, Corporate Profits Tax (without IVA CCAdj), St. Louis Fed Financial Stress Index, Crude Oil Prices: West Texas Intermediate (WTI) - Cushing, Oklahoma, Leading Index United States, Trade Weighted U.S. Dollar Index: Major Currencies, Trade Weighted U.S. Dollar Index: Broad.economic indicators: Industrial Production Index, Capacity Utilization: Total Industry, Housing Starts: Total: New Privately Owned Housing Units Started, Gross Private Domestic Investment, Corporate Profits Tax (without IVA CCAdj), St. Louis Fed Financial Stress Index, Crude Oil Prices: West Texas Intermediate (WTI) - Cushing, Oklahoma, Leading Index United States, Trade Weighted U.S. Dollar Index: Major Currencies, Trade Weighted U.S. Dollar Index: Broad.Debt: Federal Debt: Total Public Debt, Federal Debt: Total Public Debt Percent Gross Domestic Product, Excess Reserves Depository Institutions, Commercial Industrial Loans, Commercial BanksDebt: Federal Debt: Total Public Debt, Federal Debt: Total Public Debt Percent Gross Domestic Product, Excess Reserves Depository Institutions, Commercial Industrial Loans, Commercial Banks(code indicators can accessed website:\nhttps://data.nasdaq.com/data/FRED-federal-reserve-economic-data/documentation)Assume want inspect GDP within given tiem window, found period data available.(3). Getting data Nasdaq Data Link (Quandl) API - set tq_get(…get = “quandl”…)quandl_search(… query = “KEY DATASET”…)\nuseful deciding dataset want use. can get info newest oldest available date well frequency data. want look datasets “GDP” part name, set query = “GDP”.\ncan also set database_code = “CODENAME” already know code dataset. can also set number returns per page.Datasets available : https://data.nasdaq.com/searchtq_get(…get = “quandl”…) - get Quandl time series free data using API key.code can run successfully users uncomment code insert api key “my_api_key” argument.Types free datasets Quandl:Wiki Continuous Futures, curated Quandl community built top raw data ICE, CME, LIFFE, etc.Wiki Continuous Futures, curated Quandl community built top raw data ICE, CME, LIFFE, etc.Zillow Real Estate Data, provides real estate rental marketplace information.Zillow Real Estate Data, provides real estate rental marketplace information.FRED Economic Data, including indicators macroeconomic analysis mentioned section.\nprovides additional info dividends split ratio well adjusted measures Yahoo!Finance, data available Meta Uber, apple tesla, can get 4 years call. new data available 2018-03-27.FRED Economic Data, including indicators macroeconomic analysis mentioned section.\nprovides additional info dividends split ratio well adjusted measures Yahoo!Finance, data available Meta Uber, apple tesla, can get 4 years call. new data available 2018-03-27.tq_get(…get = “quandl.datatable”, datatable_code = “CODENAME”…) get larger datasets time series, note argument “datatable_code” required filled getting data.(4). Getting data Tiingo API - tq_get() - set tq_get(…get = “tiingo”/“tiingo.iex”…)\nfirst step get tiingo api key.kind combined benefits Yahoo!Finance Quandl API way info adjusted measures data available four companies desired time window single call.can continue look data hour within specific day/multiple days.(5). Getting data Alpha Vantage - set tq_get(…get = “alphavantage”…)Also, first step get tiingo api key.Like former tools, can get daily stock prices adjusted info. downside allows setting intervals instead “” date.Like using Tiingo api, can also easily inspect data hour setting interval, also setting start end time concern.(6). BloombergBloomberg charges, might best choice beginners. still want use , steps take:create Bloomberg Terminal account.create Bloomberg Terminal account.run blpConnect()run blpConnect()set tq_get(…get = “Rblpapi”…)set tq_get(…get = “Rblpapi”…)details found original Tidyquant documentation.","code":"\ntq_index(\"SP500\")## # A tibble: 503 × 8\n##    symbol company                    ident…¹ sedol weight sector share…² local…³\n##    <chr>  <chr>                      <chr>   <chr>  <dbl> <chr>    <dbl> <chr>  \n##  1 AAPL   Apple Inc.                 037833… 2046… 0.0667 Infor…  1.69e8 USD    \n##  2 MSFT   Microsoft Corporation      594918… 2588… 0.0545 Infor…  8.33e7 USD    \n##  3 AMZN   Amazon.com Inc.            023135… 2000… 0.0258 Consu…  9.90e7 USD    \n##  4 GOOGL  Alphabet Inc. Class A      02079K… BYVY… 0.0169 Commu…  6.70e7 USD    \n##  5 BRK-B  Berkshire Hathaway Inc. C… 084670… 2073… 0.0165 Finan…  2.02e7 USD    \n##  6 UNH    UnitedHealth Group Incorp… 91324P… 2917… 0.0153 Healt…  1.05e7 USD    \n##  7 TSLA   Tesla Inc                  88160R… B616… 0.0153 Consu…  2.98e7 USD    \n##  8 GOOG   Alphabet Inc. Class C      02079K… BYY8… 0.0152 Commu…  5.99e7 USD    \n##  9 XOM    Exxon Mobil Corporation    30231G… 2326… 0.0139 Energy  4.66e7 USD    \n## 10 JNJ    Johnson & Johnson          478160… 2475… 0.0138 Healt…  2.94e7 USD    \n## # … with 493 more rows, and abbreviated variable names ¹​identifier,\n## #   ²​shares_held, ³​local_currency\naapl_price_yahoo  <- tq_get(\"AAPL\", get = \"stock.prices\", from = \"2022-01-01\", to = \"2022-06-30\")\naapl_price_yahoo## # A tibble: 123 × 8\n##    symbol date        open  high   low close    volume adjusted\n##    <chr>  <date>     <dbl> <dbl> <dbl> <dbl>     <dbl>    <dbl>\n##  1 AAPL   2022-01-03  178.  183.  178.  182. 104487900     181.\n##  2 AAPL   2022-01-04  183.  183.  179.  180.  99310400     179.\n##  3 AAPL   2022-01-05  180.  180.  175.  175.  94537600     174.\n##  4 AAPL   2022-01-06  173.  175.  172.  172   96904000     171.\n##  5 AAPL   2022-01-07  173.  174.  171.  172.  86709100     171.\n##  6 AAPL   2022-01-10  169.  172.  168.  172. 106765600     171.\n##  7 AAPL   2022-01-11  172.  175.  171.  175.  76138300     174.\n##  8 AAPL   2022-01-12  176.  177.  175.  176.  74805200     175.\n##  9 AAPL   2022-01-13  176.  177.  172.  172.  84505800     171.\n## 10 AAPL   2022-01-14  171.  174.  171.  173.  80440800     172.\n## # … with 113 more rows\nmeta_price_yahoo  <- tq_get(\"META\", get = \"stock.prices\", from = \"2022-01-01\", to = \"2022-06-30\")\nmeta_price_yahoo ## # A tibble: 123 × 8\n##    symbol date        open  high   low close   volume adjusted\n##    <chr>  <date>     <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n##  1 META   2022-01-03  338.  341.  337.  339. 14537900     339.\n##  2 META   2022-01-04  340.  343.  332.  337. 15998000     337.\n##  3 META   2022-01-05  333.  336.  324.  324. 20564500     324.\n##  4 META   2022-01-06  323.  339.  323.  332. 27962800     332.\n##  5 META   2022-01-07  333.  337   329.  332. 14722000     332.\n##  6 META   2022-01-10  325.  328.  315.  328. 24942400     328.\n##  7 META   2022-01-11  327.  335.  325.  334. 16226800     334.\n##  8 META   2022-01-12  335.  336.  330.  333. 14104900     333.\n##  9 META   2022-01-13  335.  336.  326.  326. 14797100     326.\n## 10 META   2022-01-14  322.  333.  321.  332. 16868500     332.\n## # … with 113 more rows\ntsla_price_yahoo  <- tq_get(\"TSLA\", get = \"stock.prices\", from = \"2022-01-01\", to = \"2022-06-30\")\ntsla_price_yahoo## # A tibble: 123 × 8\n##    symbol date        open  high   low close    volume adjusted\n##    <chr>  <date>     <dbl> <dbl> <dbl> <dbl>     <dbl>    <dbl>\n##  1 TSLA   2022-01-03  383.  400.  379.  400. 103931400     400.\n##  2 TSLA   2022-01-04  397.  403.  374.  383. 100248300     383.\n##  3 TSLA   2022-01-05  382.  390.  360.  363.  80119800     363.\n##  4 TSLA   2022-01-06  359   363.  340.  355.  90336600     355.\n##  5 TSLA   2022-01-07  360.  360.  337.  342.  84164700     342.\n##  6 TSLA   2022-01-10  333.  353.  327.  353.  91815000     353.\n##  7 TSLA   2022-01-11  351.  359.  346.  355.  66063300     355.\n##  8 TSLA   2022-01-12  360.  372.  358.  369.  83739000     369.\n##  9 TSLA   2022-01-13  370.  372.  342.  344.  97209900     344.\n## 10 TSLA   2022-01-14  340.  351.  338.  350.  72924300     350.\n## # … with 113 more rows\nuber_price_yahoo  <- tq_get(\"UBER\", get = \"stock.prices\", from = \"2022-01-01\", to = \"2022-06-30\")\nuber_price_yahoo## # A tibble: 123 × 8\n##    symbol date        open  high   low close   volume adjusted\n##    <chr>  <date>     <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n##  1 UBER   2022-01-03  42.5  44.4  41.9  44.0 26089000     44.0\n##  2 UBER   2022-01-04  44.2  44.8  42.6  44.4 30845300     44.4\n##  3 UBER   2022-01-05  44.3  45.9  42.9  43.2 28498700     43.2\n##  4 UBER   2022-01-06  43.1  44.1  41.0  42.0 32434300     42.0\n##  5 UBER   2022-01-07  42    42.7  41.2  41.5 24875800     41.5\n##  6 UBER   2022-01-10  41.5  42.8  40.2  42.6 29783800     42.6\n##  7 UBER   2022-01-11  42.4  44.2  42.2  43.6 22161000     43.6\n##  8 UBER   2022-01-12  44.0  44.1  42.5  43.0 18993900     43.0\n##  9 UBER   2022-01-13  43.3  43.9  42.7  42.9 17190100     42.9\n## 10 UBER   2022-01-14  42.4  42.7  40.4  41.5 25817800     41.5\n## # … with 113 more rows\ngdp_fred <- tq_get(\"GDP\", get = \"economic.data\", from = \"2010-01-01\", to = \"2022-01-01\")\ngdp_fred ## # A tibble: 49 × 3\n##    symbol date        price\n##    <chr>  <date>      <dbl>\n##  1 GDP    2010-01-01 14765.\n##  2 GDP    2010-04-01 14980.\n##  3 GDP    2010-07-01 15142.\n##  4 GDP    2010-10-01 15309.\n##  5 GDP    2011-01-01 15351.\n##  6 GDP    2011-04-01 15558.\n##  7 GDP    2011-07-01 15648.\n##  8 GDP    2011-10-01 15842.\n##  9 GDP    2012-01-01 16069.\n## 10 GDP    2012-04-01 16207.\n## # … with 39 more rows\nquandl_search(query = \"GDP\", page = 1)## Gross Domestic Product\n## Code: FRED/GDP\n## Desc: Units: Billions of Dollars\n## Seasonal Adjustment: Seasonally Adjusted Annual Rate\n## Notes: A Guide to the National Income and Product Accounts of the United States (NIPA) - (http://www.bea.gov/national/pdf/nipaguid.pdf)\n## Freq: quarterly\n## Cols: Date | Value\n## \n## (GDPS) Adjusted Stock Prices\n## Code: OTCB/GDPS\n## Desc:  <b>Ticker<\/b>: GDPS <br> <br> <b>Exchange<\/b>: OTCB <br> <br> Columns: <br> <br> Open,High,Low,Close,Volume are adjusted and shown in USD currency. <br> <br> Adjustment Factor shows the factor by which prices are adjusted on days which adjustments take place <br> <br> Adjustment Type is a number representing the type of adjustment. Refer to documentation for more information on these codes.\n## Freq: daily\n## Cols: Date | Open | High | Low | Close | Volume | Adjustment Factor | Adjustment Type\n## \n## Goldplat Plc (GDP) Adjusted Stock Prices\n## Code: XLON/GDP\n## Desc:  <b>Ticker<\/b>: GDP <br> <br> <b>Exchange<\/b>: XLON <br> <br> Columns: <br> <br> Open,High,Low,Close,Volume are adjusted and shown in GBX currency. <br> <br> Adjustment Factor shows the factor by which prices are adjusted on days which adjustments take place <br> <br> Adjustment Type is a number representing the type of adjustment. Refer to documentation for more information on these codes.\n## Freq: daily\n## Cols: Date | Open | High | Low | Close | Volume | Adjustment Factor | Adjustment Type\n## \n## GDP Volatility & Option Implied Surface\n## Code: OPT/GDP\n## Desc: <p><p>Implied volatility surface for GDP.<\/p><p>For more information please view <a href='https://www.quandl.com/data/OPT/documentation'>OPT Documentation<\/a>.<\/p>\n## Freq: daily\n## Cols: date | stockpx | iv30 | iv60 | iv90 | m1atmiv | m1dtex | m2atmiv | m2dtex | m3atmiv | m3dtex | m4atmiv | m4dtex | slope | deriv | slope_inf | deriv_inf | 10dclsHV | 20dclsHV | 60dclsHV | 120dclsHV | 252dclsHV | 10dORHV | 20dORHV | 60dORHV | 120dORHV | 252dORHV\n## \n## Goodrich Petroleum Corp. (GDP) Adjusted Stock Prices\n## Code: XNAS/GDP\n## Desc:  <b>Ticker<\/b>: GDP <br> <br> <b>Exchange<\/b>: XNAS <br> <br> Columns: <br> <br> Open,High,Low,Close,Volume are adjusted and shown in USD currency. <br> <br> Adjustment Factor shows the factor by which prices are adjusted on days which adjustments take place <br> <br> Adjustment Type is a number representing the type of adjustment. Refer to documentation for more information on these codes.\n## Freq: daily\n## Cols: Date | Open | High | Low | Close | Volume | Adjustment Factor | Adjustment Type\n## \n## Goodrich Petroleum Corp. (GDP) Adjusted Stock Prices\n## Code: XNYS/GDP\n## Desc:  <b>Ticker<\/b>: GDP <br> <br> <b>Exchange<\/b>: XNYS <br> <br> Columns: <br> <br> Open,High,Low,Close,Volume are adjusted and shown in USD currency. <br> <br> Adjustment Factor shows the factor by which prices are adjusted on days which adjustments take place <br> <br> Adjustment Type is a number representing the type of adjustment. Refer to documentation for more information on these codes.\n## Freq: daily\n## Cols: Date | Open | High | Low | Close | Volume | Adjustment Factor | Adjustment Type\n## \n## Goodrich Petroleum Corp. (GDP) Adjusted Stock Prices\n## Code: XASE/GDP\n## Desc:  <b>Ticker<\/b>: GDP <br> <br> <b>Exchange<\/b>: XASE <br> <br> Columns: <br> <br> Open,High,Low,Close,Volume are adjusted and shown in USD currency. <br> <br> Adjustment Factor shows the factor by which prices are adjusted on days which adjustments take place <br> <br> Adjustment Type is a number representing the type of adjustment. Refer to documentation for more information on these codes.\n## Freq: daily\n## Cols: Date | Open | High | Low | Close | Volume | Adjustment Factor | Adjustment Type\n## \n## Goodrich Petroleum Corporation (GDP) Market Betas, Correlations, and Risks\n## Code: QRM/GDP\n## Desc: Market Betas, Correlations, and Systematic and Unsystematic Risks for Goodrich Petroleum Corporation (GDP). All time periods are measured in calendar days. See documentation for methodology.\n## Freq: daily\n## Cols: Date | Beta30 | Cor30 | Srisk30 | Urisk30 | Beta60 | Cor60 | Srisk60 | Urisk60 | Beta90 | Cor90 | Srisk90 | Urisk90 | Beta360 | Cor360 | Srisk360 | Urisk360\n## \n## Golden Pursuit Resources Ltd. (GDP) Adjusted Stock Prices\n## Code: XTSX/GDP\n## Desc:  <b>Ticker<\/b>: GDP <br> <br> <b>Exchange<\/b>: XTSX <br> <br> Columns: <br> <br> Open,High,Low,Close,Volume are adjusted and shown in CAD currency. <br> <br> Adjustment Factor shows the factor by which prices are adjusted on days which adjustments take place <br> <br> Adjustment Type is a number representing the type of adjustment. Refer to documentation for more information on these codes.\n## Freq: daily\n## Cols: Date | Open | High | Low | Close | Volume | Adjustment Factor | Adjustment Type\n## \n## Daily Active Analyst Ratings for GDP — Goodrich Petroleum Corp.\n## Code: CBARH/GDP\n## Desc: <p>Daily active analyst ratings for GDP — Goodrich Petroleum Corp.<\/p>\n## Freq: daily\n## Cols: Date | Total | Average Rating | Rating Count Strong Sell | Rating Count Moderate Sell | Rating Count Hold | Rating Count Moderate Buy | Rating Count Strong Buy | Action Count Initiated | Action Count Upgraded | Action Count Downgraded | Action Count Reiterated | Action Ratio Upgraded | Action Ratio Downgraded## # A tibble: 10 × 13\n##         id datas…¹ datab…² name  descr…³ refre…⁴ newes…⁵ oldes…⁶ colum…⁷ frequ…⁸\n##      <int> <chr>   <chr>   <chr> <chr>   <chr>   <chr>   <chr>   <list>  <chr>  \n##  1  1.20e5 GDP     FRED    Gros… \"Units… 2022-0… 2021-1… 1947-0… <chr>   quarte…\n##  2  3.79e7 GDPS    OTCB    (GDP… \" <b>T… 2017-0… 2006-1… 2006-1… <chr>   daily  \n##  3  3.78e7 GDP     XLON    Gold… \" <b>T… 2022-1… 2022-1… 2007-0… <chr>   daily  \n##  4  2.35e7 GDP     OPT     GDP … \"<p><p… 2021-1… 2021-1… 2010-0… <chr>   daily  \n##  5  3.79e7 GDP     XNAS    Good… \" <b>T… 2022-0… 2021-1… 2017-0… <chr>   daily  \n##  6  4.35e7 GDP     XNYS    Good… \" <b>T… 2022-0… 2021-1… 2018-0… <chr>   daily  \n##  7  3.76e7 GDP     XASE    Good… \" <b>T… 2022-0… 2021-1… 2017-0… <chr>   daily  \n##  8  3.39e7 GDP     QRM     Good… \"Marke… 2022-0… 2021-1… 2006-0… <chr>   daily  \n##  9  3.78e7 GDP     XTSX    Gold… \" <b>T… 2022-1… 2022-1… 2006-0… <chr>   daily  \n## 10  2.60e7 GDP     CBARH   Dail… \"<p>Da… 2021-0… 2021-0… 2012-0… <chr>   daily  \n## # … with 3 more variables: type <chr>, premium <lgl>, database_id <int>, and\n## #   abbreviated variable names ¹​dataset_code, ²​database_code, ³​description,\n## #   ⁴​refreshed_at, ⁵​newest_available_date, ⁶​oldest_available_date,\n## #   ⁷​column_names, ⁸​frequency\n#my_quandl_api <- quandl_api_key(\"my_api_key\")\n#tq_get(\"WIKI/META\", get = \"quandl\")\n#tq_get(\"WIKI/AAPL\", get = \"quandl\", from = \"2017-01-01\", to = \"2020-12-31\")\n#tq_get(\"WIKI/TSLA\", get = \"quandl\", from = \"2017-01-01\", to = \"2020-12-31\")\n#tq_get(\"WIKI/UBER\", get = \"quandl\")\n#my_tiingo_api <- tiingo_api_key(\"my_api_key\")\n#tq_get(c(\"AAPL\", \"META\",\"TSLA\",\"UBER\"), get = \"tiingo\", from = \"2022-01-01\", to = \"2022-06-30\")\n#tq_get(c(\"AAPL\", \"META\",\"TSLA\",\"UBER\"), get = \"tiingo.iex\", from = \"2022-11-01\", to = \"2022-11-01\", resample_frequency = \"60min\")\n#my_vantage_key <- av_api_key(\"my_api_key\")\n#c(\"AAPL\",\"META\",\"TSLA\", \"UBER\") %>%\n    #tq_get(get = \"alphavantage\", av_fun = \"TIME_SERIES_DAILY_ADJUSTED\", interval = \"daily\")\n#c(\"AAPL\",\"META\",\"TSLA\", \"UBER\") %>%\n    #tq_get(get = \"alphavantage\", av_fun = \"TIME_SERIES_INTRADAY\", interval = \"60min\")"},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"data-handling","chapter":"11 Quantmod & Tidyquant Tutorials and Comparison","heading":"11.3.3 Data Handling","text":"TransmuteWe typically transmute want change periodicity data, tq_transmute() return new data frame new periodicity.transmuting, might explore compatible functions set tq_transmute(…mutate_fun = “CODEFROMPACKAGES”…). CODEFROMPACKAGES returned call .convenience, work data retrieved Meta Yahoo!Finance example.\ntransmute daily stock prices Meta weekly data.Tesla data converted regression next steps.MutateWe mutate weekly return data original dataset show tq_mutate() works.\ntq_mutate(mutate_fun = periodReturn, period = “weekly”) gives weekly return.might also want show mutate info computations across columns original dataset. original documentation takes rollapply zoo package example. Rollapply enables applying custom function across rolling window. may follow documentation use compute rolling regression. adapt code original documentation run rolling regression Meta Tesla dataset.prepare showing mutate rolling regressions returns Meta Tesla, mutate weekly returns Tesla original Tesla dataset Yahoo!Finance well., prepare running rolling regressions, select weekly returns columns dataset join date shown .joined_returns dataset passed regr_fun xts object.\ntimetk::tk_tbl function converts data dataframe.Notice make computations within tq_mutate() function. new dataframe created coefficients regressions attached.Also, mutate_fun may require two different inputs. case, want use tq_mutate_xy() instead tq_mutate() . example, want mutate indicator original dataset calculated two columns data original dataset, want set mutate_fun = CODENAME new indicator, input name two columns x y. Example shown original documentation.","code":"\ntq_transmute_fun_options()## $zoo\n##  [1] \"rollapply\"          \"rollapplyr\"         \"rollmax\"           \n##  [4] \"rollmax.default\"    \"rollmaxr\"           \"rollmean\"          \n##  [7] \"rollmean.default\"   \"rollmeanr\"          \"rollmedian\"        \n## [10] \"rollmedian.default\" \"rollmedianr\"        \"rollsum\"           \n## [13] \"rollsum.default\"    \"rollsumr\"          \n## \n## $xts\n##  [1] \"apply.daily\"     \"apply.monthly\"   \"apply.quarterly\" \"apply.weekly\"   \n##  [5] \"apply.yearly\"    \"diff.xts\"        \"lag.xts\"         \"period.apply\"   \n##  [9] \"period.max\"      \"period.min\"      \"period.prod\"     \"period.sum\"     \n## [13] \"periodicity\"     \"to_period\"       \"to.daily\"        \"to.hourly\"      \n## [17] \"to.minutes\"      \"to.minutes10\"    \"to.minutes15\"    \"to.minutes3\"    \n## [21] \"to.minutes30\"    \"to.minutes5\"     \"to.monthly\"      \"to.period\"      \n## [25] \"to.quarterly\"    \"to.weekly\"       \"to.yearly\"      \n## \n## $quantmod\n##  [1] \"allReturns\"      \"annualReturn\"    \"ClCl\"            \"dailyReturn\"    \n##  [5] \"Delt\"            \"HiCl\"            \"Lag\"             \"LoCl\"           \n##  [9] \"LoHi\"            \"monthlyReturn\"   \"Next\"            \"OpCl\"           \n## [13] \"OpHi\"            \"OpLo\"            \"OpOp\"            \"periodReturn\"   \n## [17] \"quarterlyReturn\" \"seriesAccel\"     \"seriesDecel\"     \"seriesDecr\"     \n## [21] \"seriesHi\"        \"seriesIncr\"      \"seriesLo\"        \"weeklyReturn\"   \n## [25] \"yearlyReturn\"   \n## \n## $TTR\n##  [1] \"adjRatios\"          \"ADX\"                \"ALMA\"              \n##  [4] \"aroon\"              \"ATR\"                \"BBands\"            \n##  [7] \"CCI\"                \"chaikinAD\"          \"chaikinVolatility\" \n## [10] \"CLV\"                \"CMF\"                \"CMO\"               \n## [13] \"CTI\"                \"DEMA\"               \"DonchianChannel\"   \n## [16] \"DPO\"                \"DVI\"                \"EMA\"               \n## [19] \"EMV\"                \"EVWMA\"              \"GMMA\"              \n## [22] \"growth\"             \"HMA\"                \"keltnerChannels\"   \n## [25] \"KST\"                \"lags\"               \"MACD\"              \n## [28] \"MFI\"                \"momentum\"           \"OBV\"               \n## [31] \"PBands\"             \"ROC\"                \"rollSFM\"           \n## [34] \"RSI\"                \"runCor\"             \"runCov\"            \n## [37] \"runMAD\"             \"runMax\"             \"runMean\"           \n## [40] \"runMedian\"          \"runMin\"             \"runPercentRank\"    \n## [43] \"runSD\"              \"runSum\"             \"runVar\"            \n## [46] \"SAR\"                \"SMA\"                \"SMI\"               \n## [49] \"SNR\"                \"stoch\"              \"TDI\"               \n## [52] \"TRIX\"               \"ultimateOscillator\" \"VHF\"               \n## [55] \"VMA\"                \"volatility\"         \"VWAP\"              \n## [58] \"VWMA\"               \"wilderSum\"          \"williamsAD\"        \n## [61] \"WMA\"                \"WPR\"                \"ZigZag\"            \n## [64] \"ZLEMA\"             \n## \n## $PerformanceAnalytics\n## [1] \"Return.annualized\"        \"Return.annualized.excess\"\n## [3] \"Return.clean\"             \"Return.cumulative\"       \n## [5] \"Return.excess\"            \"Return.Geltner\"          \n## [7] \"zerofill\"\nmeta_price_yahoo_weekly <- meta_price_yahoo %>%\n  # No need to group at this point, but it allows the \"META\" name to show. can be deleted. \n  group_by(symbol) %>%\n  # set indexAt allow the date to be the last day of each week. \n  tq_transmute(select = adjusted, mutate_fun = to.weekly, indexAt = \"lastof\")\nmeta_price_yahoo_weekly## # A tibble: 26 × 3\n## # Groups:   symbol [1]\n##    symbol date       adjusted\n##    <chr>  <date>        <dbl>\n##  1 META   2022-01-07     332.\n##  2 META   2022-01-14     332.\n##  3 META   2022-01-21     303.\n##  4 META   2022-01-28     302.\n##  5 META   2022-02-04     237.\n##  6 META   2022-02-11     220.\n##  7 META   2022-02-18     206.\n##  8 META   2022-02-25     210.\n##  9 META   2022-03-04     200.\n## 10 META   2022-03-11     188.\n## # … with 16 more rows\ntsla_price_yahoo_weekly <- tsla_price_yahoo %>%\n  # No need to group at this point, but it allows the \"TSLA\" name to show. can be deleted. \n  group_by(symbol) %>%\n  # set indexAt allow the date to be the last day of each week. \n  tq_transmute(select = adjusted, mutate_fun = to.weekly, indexAt = \"lastof\")\ntsla_price_yahoo_weekly## # A tibble: 26 × 3\n## # Groups:   symbol [1]\n##    symbol date       adjusted\n##    <chr>  <date>        <dbl>\n##  1 TSLA   2022-01-07     342.\n##  2 TSLA   2022-01-14     350.\n##  3 TSLA   2022-01-21     315.\n##  4 TSLA   2022-01-28     282.\n##  5 TSLA   2022-02-04     308.\n##  6 TSLA   2022-02-11     287.\n##  7 TSLA   2022-02-18     286.\n##  8 TSLA   2022-02-25     270.\n##  9 TSLA   2022-03-04     279.\n## 10 TSLA   2022-03-11     265.\n## # … with 16 more rows\nmeta_price_yahoo_weekly_returns <- meta_price_yahoo_weekly %>%\n    group_by(symbol) %>%\n    tq_mutate(mutate_fun = periodReturn, period = \"weekly\", type = \"log\")\nmeta_price_yahoo_weekly_returns## # A tibble: 26 × 4\n## # Groups:   symbol [1]\n##    symbol date       adjusted weekly.returns\n##    <chr>  <date>        <dbl>          <dbl>\n##  1 META   2022-01-07     332.       0       \n##  2 META   2022-01-14     332.       0.000331\n##  3 META   2022-01-21     303.      -0.0905  \n##  4 META   2022-01-28     302.      -0.00483 \n##  5 META   2022-02-04     237.      -0.241   \n##  6 META   2022-02-11     220.      -0.0769  \n##  7 META   2022-02-18     206.      -0.0629  \n##  8 META   2022-02-25     210.       0.0207  \n##  9 META   2022-03-04     200.      -0.0508  \n## 10 META   2022-03-11     188.      -0.0643  \n## # … with 16 more rows\ntsla_price_yahoo_weekly_returns <- tsla_price_yahoo_weekly %>%\n    group_by(symbol) %>%\n    tq_mutate( mutate_fun = periodReturn, period = \"weekly\", type = \"log\")\ntsla_price_yahoo_weekly_returns## # A tibble: 26 × 4\n## # Groups:   symbol [1]\n##    symbol date       adjusted weekly.returns\n##    <chr>  <date>        <dbl>          <dbl>\n##  1 TSLA   2022-01-07     342.        0      \n##  2 TSLA   2022-01-14     350.        0.0218 \n##  3 TSLA   2022-01-21     315.       -0.106  \n##  4 TSLA   2022-01-28     282.       -0.109  \n##  5 TSLA   2022-02-04     308.        0.0870 \n##  6 TSLA   2022-02-11     287.       -0.0710 \n##  7 TSLA   2022-02-18     286.       -0.00352\n##  8 TSLA   2022-02-25     270.       -0.0565 \n##  9 TSLA   2022-03-04     279.        0.0345 \n## 10 TSLA   2022-03-11     265.       -0.0526 \n## # … with 16 more rows\nmeta_price_yahoo_weekly_returns_only <- meta_price_yahoo_weekly_returns %>%\n  select(weekly.returns, date)\ntsla_price_yahoo_weekly_returns_only <- tsla_price_yahoo_weekly_returns %>%\n  select(weekly.returns, date)\n\njoined_returns <- left_join(meta_price_yahoo_weekly_returns_only, tsla_price_yahoo_weekly_returns_only, \n                            by =\"date\")\njoined_returns## # A tibble: 26 × 5\n##    symbol.x weekly.returns.x date       symbol.y weekly.returns.y\n##    <chr>               <dbl> <date>     <chr>               <dbl>\n##  1 META             0        2022-01-07 TSLA              0      \n##  2 META             0.000331 2022-01-14 TSLA              0.0218 \n##  3 META            -0.0905   2022-01-21 TSLA             -0.106  \n##  4 META            -0.00483  2022-01-28 TSLA             -0.109  \n##  5 META            -0.241    2022-02-04 TSLA              0.0870 \n##  6 META            -0.0769   2022-02-11 TSLA             -0.0710 \n##  7 META            -0.0629   2022-02-18 TSLA             -0.00352\n##  8 META             0.0207   2022-02-25 TSLA             -0.0565 \n##  9 META            -0.0508   2022-03-04 TSLA              0.0345 \n## 10 META            -0.0643   2022-03-11 TSLA             -0.0526 \n## # … with 16 more rows\nregr_fun <- function(data) {\n    coef(lm(weekly.returns.x ~ weekly.returns.y, data = timetk::tk_tbl(data, silent = TRUE)))\n}\njoined_returns %>%\n    tq_mutate(mutate_fun = rollapply,\n              # 2-week window. \n              width = 2,\n              FUN        = regr_fun,\n              # We need to specify by.column since we don't want the regression to run on each                 column in the dataset.\n              by.column  = FALSE)## # A tibble: 26 × 7\n##    symbol.x weekly.returns.x date       symbol.y weekly.retur…¹ X.Int…² weekly…³\n##    <chr>               <dbl> <date>     <chr>             <dbl>   <dbl>    <dbl>\n##  1 META             0        2022-01-07 TSLA            0       NA       NA     \n##  2 META             0.000331 2022-01-14 TSLA            0.0218   0        0.0152\n##  3 META            -0.0905   2022-01-21 TSLA           -0.106   -0.0152   0.710 \n##  4 META            -0.00483  2022-01-28 TSLA           -0.109   -3.19   -29.2   \n##  5 META            -0.241    2022-02-04 TSLA            0.0870  -0.136   -1.20  \n##  6 META            -0.0769   2022-02-11 TSLA           -0.0710  -0.151   -1.04  \n##  7 META            -0.0629   2022-02-18 TSLA           -0.00352 -0.0622   0.206 \n##  8 META             0.0207   2022-02-25 TSLA           -0.0565  -0.0685  -1.58  \n##  9 META            -0.0508   2022-03-04 TSLA            0.0345  -0.0237  -0.786 \n## 10 META            -0.0643   2022-03-11 TSLA           -0.0526  -0.0561   0.155 \n## # … with 16 more rows, and abbreviated variable names ¹​weekly.returns.y,\n## #   ²​X.Intercept., ³​weekly.returns.y..1"},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"charting-with-tidyquant","chapter":"11 Quantmod & Tidyquant Tutorials and Comparison","heading":"11.3.4 Charting with Tidyquant","text":"Line ChartPlotting opening price vs.time.Changing color theme, using first plot example.Additionally, scale_color_tq(theme = “green”/“dark”) scale_fill_tq(theme = “green”/“dark”) may used color fill specified aes().change themes applies types plots well.Bar ChartCandlestick ChartWe can modify candlestick chart bycolor, “color_up” “color_down” modifies color lines, fill_up fill_down modifies color rectangle fills.color, “color_up” “color_down” modifies color lines, fill_up fill_down modifies color rectangle fills.range graph, may use coord_x_date(xlim = …) zoom specific sections data.\nmay also set ylim = … zooming causes great change range y values.range graph, may use coord_x_date(xlim = …) zoom specific sections data.\nmay also set ylim = … zooming causes great change range y values.Preparing charting portion data. set range x.Reseting range y adjust plotting range x.Graphing different data different companiesInstead zooming specific sections using coord_x_date, run scale_x_date instead, removes --bounds data charting. trade distorting scale y-axis (removing little) getting moving average (removing much). may call filter() function remove appropriate number days find balance. Examples included original documentation.Visualizing Moving AveragesMoving averages help evaluate time-series trends, applied added layer chart geom_ma function. Different types moving averages available: Simple moving averages(SMA), exponential moving averages (EMA), weighted moving averages(WMA), double exponential moving averages (DEMA), zero-lag exponential moving averages (ZLEMA), volume-weighted moving averages (VWMA), elastic volume-weighted moving averages (EVWMA).adapted sample code original documentation. can set ma_fun argument equal types moving average want graph adjust appearance adjusting linetype, size, color, etc.charting moving average (SMA) - identify trend direction stock.\nGraph SMA 20/40 days:charting exponential moving average (EMA) - determine entry exit points trade.\nformula: closing price * multiplier + EMA previous day * (1-multiplier)\nmultiplier formula: [2/(number days observation+1)]charting weighted moving averages (WMA) - determine trend directions help see buy sell stockscharting double exponential moving averages (DEMA) - improved EMA, removes lag associated moving averages placing weights recent valuescharting zero-lag exponential moving averages (ZLEMA) - improved EMA, reduce lags removed inherent lag removing data lag days agocharting volume-weighted moving averages (VWMA) - weighting prices based amount trading activity within time windowelastic volume-weighted moving averages (EVWMA) - approximate average price paid per share. Large gaps price EVWMA signal overbought/soldAdding Bollinger BandsBollinger bands used visualize volatility plotting range around moving average two standard deviations . Geom_bbands works almost identically geom_ma. can use color_ma, color_bands, alpha, fill arguments change appearance bollinger bands.","code":"\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_line() +\n    labs(title = \"META Line Chart\", y = \"Opening Price\", x = \"\") + \n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = volume)) +\n    geom_line() +\n    labs(title = \"META Line Chart\", y = \"Volume\", x = \"\") + \n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_line() +\n    labs(title = \"META Line Chart\", y = \"Opening Price\", x = \"\") + \n    theme_tq_green()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_line() +\n    labs(title = \"META Line Chart\", y = \"Opening Price\", x = \"\") + \n    theme_tq_dark()\nmeta_price_yahoo %>%\n  # We can also set y = close, which is equivalent to setting y = close. \n    ggplot(aes(x = date, y = open)) +\n    geom_barchart(aes(open = open, high = high, low = low, close = close)) +\n    labs(title = \"META Bar Chart\", y = \"Price\", x = \"\") + \n    theme_tq()\nmeta_price_yahoo %>% \n  # We can also set y = close, which is equivalent to setting y = close.\n    ggplot(aes(x = date, y = open)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    labs(title = \"META Candlestick Chart\", y = \"Price\", x = \"\") +\n    theme_tq()\nstart <- as_date(\"2022-04-30\")\nend <- as_date(\"2022-06-30\")\nreset_y_range <- meta_price_yahoo %>%\n  # the last 60 lines of data. \n  tail(60) %>%\n  summarise(\n    # max value within the selected range\n    max_high = max(high),\n    # min value within the selected range\n    min_low = min(low)\n  )\nreset_y_range## # A tibble: 1 × 2\n##   max_high min_low\n##      <dbl>   <dbl>\n## 1     237.    154.\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close),                        colour_up = \"darkgreen\", colour_down = \"darkred\", \n                        fill_up  = \"darkgreen\", fill_down  = \"darkred\") +\n    labs(title = \"META Candlestick Chart\", subtitle = \"Zoomed in Version\", y = \"Price\", x = \"\") +\n    coord_x_date(xlim = c(start, end), ylim = c(reset_y_range$min_low, reset_y_range$max_high)) +\n    theme_tq()\nconcat1 <- rbind(meta_price_yahoo, aapl_price_yahoo)\nconcat2 <- rbind(tsla_price_yahoo, concat1)\nconcat3 <- rbind(uber_price_yahoo, concat2)\nconcat3## # A tibble: 492 × 8\n##    symbol date        open  high   low close   volume adjusted\n##    <chr>  <date>     <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n##  1 UBER   2022-01-03  42.5  44.4  41.9  44.0 26089000     44.0\n##  2 UBER   2022-01-04  44.2  44.8  42.6  44.4 30845300     44.4\n##  3 UBER   2022-01-05  44.3  45.9  42.9  43.2 28498700     43.2\n##  4 UBER   2022-01-06  43.1  44.1  41.0  42.0 32434300     42.0\n##  5 UBER   2022-01-07  42    42.7  41.2  41.5 24875800     41.5\n##  6 UBER   2022-01-10  41.5  42.8  40.2  42.6 29783800     42.6\n##  7 UBER   2022-01-11  42.4  44.2  42.2  43.6 22161000     43.6\n##  8 UBER   2022-01-12  44.0  44.1  42.5  43.0 18993900     43.0\n##  9 UBER   2022-01-13  43.3  43.9  42.7  42.9 17190100     42.9\n## 10 UBER   2022-01-14  42.4  42.7  40.4  41.5 25817800     41.5\n## # … with 482 more rows\nconcat3 %>%\n    ggplot(aes(x = date, y = close, group = symbol)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    labs(title = \"Multiple Candlestick Charts\",\n         y = \"Price\", x = \"\") + \n    coord_x_date(xlim = c(start, end)) +\n    facet_wrap(~ symbol, ncol = 2, scale = \"free_y\") + \n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    geom_ma(ma_fun = SMA, n = 20, linetype = 5, size = 1.25) +\n    geom_ma(ma_fun = SMA, n = 40, color = \"red\", size = 1.25) + \n    labs(title = \"META Candlestick Chart\", \n         subtitle = \"20 and 40-Day SMA\", \n         y = \"Price\", x = \"\") + \n    coord_x_date(xlim = c(start, end),\n                 c(reset_y_range$min_low, reset_y_range$max_high)) + \n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    geom_ma(ma_fun = EMA, n = 20, wilder = TRUE, linetype = 5, size = 1.25) +\n    geom_ma(ma_fun = EMA, n = 40, wilder = TRUE, color = \"red\", size = 1.25) + \n    labs(title = \"META Candlestick Chart\", \n         subtitle = \"20 and 40-Day EMA\", \n         y = \"Price\", x = \"\") + \n    coord_x_date(xlim = c(start, end),\n                 c(reset_y_range$min_low, reset_y_range$max_high)) +\n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    geom_ma(ma_fun = WMA, n = 20, wilder = TRUE, linetype = 5, size = 1.25) +\n    geom_ma(ma_fun = WMA, n = 40, wilder = TRUE, color = \"red\", size = 1.25) + \n    labs(title = \"META Candlestick Chart\", \n         subtitle = \"20 and 40-Day WMA\", \n         y = \"Price\", x = \"\") + \n    coord_x_date(xlim = c(start, end),\n                 c(reset_y_range$min_low, reset_y_range$max_high)) +\n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    geom_ma(ma_fun = DEMA, n = 20, wilder = TRUE, linetype = 5, size = 1.25) +\n    geom_ma(ma_fun = DEMA, n = 40, wilder = TRUE, color = \"red\", size = 1.25) + \n    labs(title = \"META Candlestick Chart\", \n         subtitle = \"20 and 40-Day DEMA\", \n         y = \"Price\", x = \"\") + \n    coord_x_date(xlim = c(start, end),\n                 c(reset_y_range$min_low, reset_y_range$max_high)) +\n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    geom_ma(ma_fun = ZLEMA, n = 20, wilder = TRUE, linetype = 5, size = 1.25) +\n    geom_ma(ma_fun = ZLEMA, n = 40, wilder = TRUE, color = \"red\", size = 1.25) + \n    labs(title = \"META Candlestick Chart\", \n         subtitle = \"20 and 40-Day ZLEMA\", \n         y = \"Price\", x = \"\") + \n    coord_x_date(xlim = c(start, end),\n                 c(reset_y_range$min_low, reset_y_range$max_high)) +\n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open, volume = volume)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    geom_ma(ma_fun = VWMA, n = 20, wilder = TRUE, linetype = 5, size = 1.25) +\n    geom_ma(ma_fun = VWMA, n = 40, wilder = TRUE, color = \"red\", size = 1.25) + \n    labs(title = \"META Candlestick Chart\", \n         subtitle = \"20 and 40-Day VWMA\", \n         y = \"Price\", x = \"\") + \n    coord_x_date(xlim = c(start, end),\n                 c(reset_y_range$min_low, reset_y_range$max_high)) +\n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = close, volume = volume)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    geom_ma(ma_fun = EVWMA, n = 20, wilder = TRUE, linetype = 5, size = 1.25) +\n    geom_ma(ma_fun = EVWMA, n = 40, wilder = TRUE, color = \"red\", size = 1.25) + \n    labs(title = \"META Candlestick Chart\", \n         subtitle = \"20 and 40-Day EVWMA\", \n         y = \"Price\", x = \"\") + \n    coord_x_date(xlim = c(start, end),\n                 c(reset_y_range$min_low, reset_y_range$max_high)) +\n    theme_tq()\nmeta_price_yahoo %>%\n  # high, low, and close information are required. \n    ggplot(aes(x = date, y = close, open = open, high = high, low = low, close = close)) +\n    geom_candlestick() +\n  # sd = 2 by default. \n    geom_bbands(ma_fun = SMA, sd = 2, n = 20) +\n    labs(title = \"META Candlestick Chart\", \n         subtitle = \"BBands with SMA\", \n         y = \"Closing Price\", x = \"\") + \n        coord_x_date(xlim = c(start, end),\n                       c(reset_y_range$min_low, reset_y_range$max_high)) +\n    theme_tq()"},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"quantmod-vs.-tidyquant","chapter":"11 Quantmod & Tidyquant Tutorials and Comparison","heading":"11.4 Quantmod vs. Tidyquant","text":"","code":""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"quantmod-1","chapter":"11 Quantmod & Tidyquant Tutorials and Comparison","heading":"11.4.1 Quantmod:","text":"Pros-\n1. Beginner friendly, need knowledge R libraries/packages create graphs\n2. Easy syntax\n3. Contains essential tools indicators tradersCons-\n1. flexible (example, freely edit elements chart, like caption volume number)\n2. Limited functions (example, conduct data cleaning directly create multi-facet plot)\n3. Limited data source connections, currently 3 direct online data source connections (Yahoo Finance, FRED, oanda)","code":""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"tidyquant-1","chapter":"11 Quantmod & Tidyquant Tutorials and Comparison","heading":"11.4.2 Tidyquant:","text":"Pros-\n1. Can use tidyverse ggplot packages, contains functions clean data, make tidy graphs, implement modeling scaling analysis\n2. Contain quantitative analytical functions Quantmod, xts, TTR, PerformanceAnalytics\n3. Multiple data source connections available, currently 6 connections (Yahoo Finance, FRED, Quandl, Tiingo, Alpha Vantage, Bloomberg)\n4. Flexible (since can use tidyverse ggplot)Cons-\n1. beginner friendly comparing Quantmod\n2. Syntax can complex","code":""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"sources-1","chapter":"11 Quantmod & Tidyquant Tutorials and Comparison","heading":"11.5 Sources:","text":"https://cran.r-project.org/web/packages/quantmod/quantmod.pdfhttps://www.rdocumentation.org/packages/quantmod/versions/0.4.20https://www.quantmod.com/documentation/https://rdrr.io/cran/quantmod/https://cran.r-project.org/web/packages/tidyquant/vignettes/https://data.nasdaq.com/data/FRED-federal-reserve-economic-data/documentationhttps://www.analyticsvidhya.com/blog/2017/09/comparative-stock-analysis/https://www.business-science.io/code-tools/2017/03/19/tidyquant-quandl-integration.html","code":""},{"path":"edav-survey-and-analysis.html","id":"edav-survey-and-analysis","chapter":"12 EDAV Survey and Analysis","heading":"12 EDAV Survey and Analysis","text":"Varalika Mahajan Vrinda Bhat","code":""},{"path":"edav-survey-and-analysis.html","id":"project-proposal","chapter":"12 EDAV Survey and Analysis","heading":"12.0.1 Project Proposal","text":"","code":""},{"path":"edav-survey-and-analysis.html","id":"project-group-cc5","chapter":"12 EDAV Survey and Analysis","heading":"12.0.1.1 Project Group: CC5","text":"Varalika Mahajan: vm2695Vrinda Bhat: vgb2113","code":""},{"path":"edav-survey-and-analysis.html","id":"visualization-preference-analysis","chapter":"12 EDAV Survey and Analysis","heading":"12.0.1.2 Visualization Preference Analysis","text":"","code":""},{"path":"edav-survey-and-analysis.html","id":"overview","chapter":"12 EDAV Survey and Analysis","heading":"12.0.1.2.1 Overview","text":"Form Link: https://forms.gle/SYKeS6fqGktr5qrN8No responses: 80Data Collected: https://docs.google.com/spreadsheets/d/1apWvWCVmk4donteDaWEuMjDvHc1gJZxfrbSXeILNJyE/edit?usp=sharingFull Document Link: https://docs.google.com/document/d/1RKa9HXl6icDS5ci4K7oLATZjFOp4oWNzELslTATMJL8/edit?usp=sharing","code":""},{"path":"edav-survey-and-analysis.html","id":"goals","chapter":"12 EDAV Survey and Analysis","heading":"12.0.1.2.2 Goals:","text":"understand people’s opinions different visualizations: Different views graphs visualizations help us understand importance structural necessity existing -used graphs.Validate factors like age, work experience, gender impact opinion: Usually applying learned classroom concepts real-life work-related problems gives us better understanding meaningful business insights. Thus, checked factors like experience, age, gender showed huge impact choices.","code":""},{"path":"github-initial-setup.html","id":"github-initial-setup","chapter":"13 Github initial setup","heading":"13 Github initial setup","text":"Joyce Robbins","code":""},{"path":"github-initial-setup.html","id":"create-new-repo","chapter":"13 Github initial setup","heading":"13.1 Create new repo","text":"Create new repository copying template: http://www.github.com/jtr13/cctemplate following instructions README.","code":""},{"path":"github-initial-setup.html","id":"pages-in-repo-settings","chapter":"13 Github initial setup","heading":"13.2 Pages in repo settings","text":"Change source gh-pagesMay trigger GHA get work","code":""},{"path":"github-initial-setup.html","id":"add-packages-to-description-file","chapter":"13 Github initial setup","heading":"13.3 Add packages to DESCRIPTION file","text":"Need better process…Downloaded submissions CourseWorksCreate DESCRIPTION file. Add add dependencies projthis::proj_update_deps()https://twitter.com/ijlyttle/status/1370776366585614342Add Imports real DESCRIPTION file.Found problematic packages looking reverse dependencies packages failed install:devtools::revdep()Also used pak::pkg_deps_tree()Problems:magickrJava dependency qdap","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"tutorial-for-pull-request-mergers","chapter":"14 Tutorial for pull request mergers","heading":"14 Tutorial for pull request mergers","text":"","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"general","chapter":"14 Tutorial for pull request mergers","heading":"14.1 General","text":"following checklist steps perform merging pull request. point, ’re sure , request review one PR leaders.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-branch","chapter":"14 Tutorial for pull request mergers","heading":"14.2 Check branch","text":"PR submitted non-main branch.PR submitted main branch, provide instructions fix problem:Close PR.Close PR.Follow instructions forgetting branch committed pushed GitHub: https://edav.info/github#fixing-mistakesFollow instructions forgetting branch committed pushed GitHub: https://edav.info/github#fixing-mistakesIf trouble 2., delete local folder project, delete fork GitHub, start .trouble 2., delete local folder project, delete fork GitHub, start .Open new PR.Open new PR.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"examine-files-that-were-added-or-modified","chapter":"14 Tutorial for pull request mergers","heading":"14.3 Examine files that were added or modified","text":"ONE .Rmd file.ONE .Rmd file.additional resources resources/<project_name>/ folder.additional resources resources/<project_name>/ folder.files root directory besides .Rmd file.files root directory besides .Rmd file.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-.rmd-filename","chapter":"14 Tutorial for pull request mergers","heading":"14.4 Check .Rmd filename","text":".Rmd filename words joined underscores, white space. (Update: need branch name.).Rmd filename can contain lowercase letters. (Otherwise filenames sort nicely repo home page.)","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-.rmd-file-contents","chapter":"14 Tutorial for pull request mergers","heading":"14.5 Check .Rmd file contents","text":"file contain YAML header --- line.second line blank, followed author name(s).first line start single hashtag #, followed single whitespace, title.additional single hashtag headers chapter. (, new chapters created.)hashtag headers followed numbers since hashtags create numbered subheadings. Correct: ## Subheading. Incorrect: ## 3. Subheading.file contains setup chunk .Rmd file, contain setup label. (bookdown render fail duplicate chunk labels.)\n.e. use {r, include=FALSE} instead {r setup, include=FALSE}.\nSee sample .RmdLinks internal files must contain resources/<project_name>/ path, : ![Test Photo](resources/sample_project/election.jpg)file contain install.packages(), write functions, setwd(), getwd().’s anything else looks odd ’re sure, assign jtr13 review explain issue.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"request-changes","chapter":"14 Tutorial for pull request mergers","heading":"14.6 Request changes","text":"problems checks listed , explain pull request merged request changes following steps:, add changes requested label pull request.job pull request done now. contributors fix requests, review either move forward merge explain changes still need made.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"steps-to-merge-the-pr","chapter":"14 Tutorial for pull request mergers","heading":"14.7 Steps to Merge the PR","text":"click “Merge” things .","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"update-the-branch","chapter":"14 Tutorial for pull request mergers","heading":"14.7.1 Update the branch","text":"“Update Branch” visible toward end Conversation tab pull request, click . ensure working --date versions _bookdown.yml DESCRIPTION.Next make changes files contributor’s branch.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"add-the-filename-of-the-chapter-to-_bookdown.yml","chapter":"14 Tutorial for pull request mergers","heading":"14.7.2 Add the filename of the chapter to _bookdown.yml","text":"Go “Files Changed” copy filename .Rmd file.Open branch submitted PR following steps:\naccess PR branch:\n\nMake sure PR branch checking PR branch name shown (main):\nOpen branch submitted PR following steps:access PR branch:Make sure PR branch checking PR branch name shown (main):Add name new file single quotes followed comma labelled section (eg. Cheatsheets, Tutorials etc).Add name new file single quotes followed comma labelled section (eg. Cheatsheets, Tutorials etc).Save edited version.Save edited version.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"add-part-names-to-.rmd-for-every-first-article-in-part","chapter":"14 Tutorial for pull request mergers","heading":"14.7.3 (Add part names to .Rmd for every first article in part)","text":"adding first chapter PART.One person manage , otherwise hard keep project organized.every first article part, add chapter name top .Rmd file, propose changes. example like .\n","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"add-new-libraries-to-description.","chapter":"14 Tutorial for pull request mergers","heading":"14.7.4 Add new libraries to DESCRIPTION.","text":"Check .Rmd libraries needed. missing, add DESCRIPTION file contributor’s branch, manner edited _bookdown.yml file.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"merge-the-pull-request","chapter":"14 Tutorial for pull request mergers","heading":"14.7.5 Merge the pull request","text":"’re sure things correctly, assign one maintainers @jtr13 review merge PR.Return PR main page repo www.github.com/jtr13/...Return PR main page repo www.github.com/jtr13/...necessary resolve merge conflicts clicking resolve merge conflicts button:necessary resolve merge conflicts clicking resolve merge conflicts button:delete lines <<<<<<< xxxx, ======= >>>>>>>> main edit file desired. Click “Marked resolved” button green “Commit merge” button. –>Click “Merge pull request” “Confirm merge”. Add thank note perhaps emoji :tada:.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-actions","chapter":"14 Tutorial for pull request mergers","heading":"14.7.6 Check Actions","text":"minutes, click Actions tabs check whether build successful: green dot indicates successful run, red X indicates failed run.minutes, click Actions tabs check whether build successful: green dot indicates successful run, red X indicates failed run.Check log figure went wrong, can, fix . ’re sure , problem, just open issue linking failed run others can help (important can fix problems quickly). (click revert merge).Check log figure went wrong, can, fix . ’re sure , problem, just open issue linking failed run others can help (important can fix problems quickly). (click revert merge).","code":""}]
