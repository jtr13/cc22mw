[{"path":"index.html","id":"welcome","chapter":"1 Welcome!","heading":"1 Welcome!","text":"Let’s add content welcome page.Submit pull request .construction","code":""},{"path":"community-contribution.html","id":"community-contribution","chapter":"2 Community Contribution","heading":"2 Community Contribution","text":"fairly open-ended assignment provides opportunity receive credit contributing collective learning class, perhaps beyond. reflect minimum 3 hours work. complete assignment must submit short description contribution. appropriate, attach relevant files.many ways can contribute:organize lead workshop particular topic (date may assignment due date need schedule )help students find final project partnersgive well-rehearsed 5 minute lightning talk class datavis topic (theory tool) (email set date – may assignment due date need schedule )create video tutorial (length)create cheatsheet resourcewrite tutorial tool ’s well documentedbuild viz product (ex. htmlwidget RStudio add-) class usedesign home page (images, text /artwork) web site[idea](Note: translations allowed)may draw expand existing resources. , critical cite sources.","code":""},{"path":"community-contribution.html","id":"important-logistics","chapter":"2 Community Contribution","heading":"2.1 IMPORTANT LOGISTICS","text":"","code":""},{"path":"community-contribution.html","id":"groups","chapter":"2 Community Contribution","heading":"2.1.1 Groups","text":"may work partner choosing. work alone, need join group 1, simply submit work CourseWorks solo assignment.work partner, add group CC page People tab. Ed Discussion can used find partners similar interests.","code":""},{"path":"community-contribution.html","id":"what-to-submit","chapter":"2 Community Contribution","heading":"2.1.2 What to submit","text":"cases something tangible upload, tutorial, cheatsheet, etc. Alternatively may submit link material online (YouTube video, etc.) ’s nothing tangible include longer description (see 2.).cases something tangible upload, tutorial, cheatsheet, etc. Alternatively may submit link material online (YouTube video, etc.) ’s nothing tangible include longer description (see 2.).explanation motivation project, need addresses, evaluation project including learned / might differently next time. (1/2 page)explanation motivation project, need addresses, evaluation project including learned / might differently next time. (1/2 page)","code":""},{"path":"community-contribution.html","id":"submitting-your-assignment","chapter":"2 Community Contribution","heading":"2.1.3 Submitting your assignment","text":"must submit assignment twice: CourseWorks (can graded) class, details follow.CourseWorks submission (assignment): submit work .Rmd rendered .pdf .html file, just problem sets. work lend format, write assignment text box .CourseWorks submission (assignment): submit work .Rmd rendered .pdf .html file, just problem sets. work lend format, write assignment text box .Class (GitHub) submission: detail provided separate assignment.Class (GitHub) submission: detail provided separate assignment.","code":""},{"path":"community-contribution.html","id":"grading","chapter":"2 Community Contribution","heading":"2.1.4 Grading","text":"graded quality work, originality, effort invested. sources used must cited. looking value-added existing resources. example, excellent cheatsheet already exists ggplot2 creating new one useful unless represents significant improvement.","code":""},{"path":"github-submission-instructions.html","id":"github-submission-instructions","chapter":"3 GitHub submission instructions","heading":"3 GitHub submission instructions","text":"chapter gives information need upload community contribution. Please read entire document carefully making submission. particular note fact bookdown requires different .Rmd format ’re used , must make changes beginning file described submitting.","code":""},{"path":"github-submission-instructions.html","id":"background","chapter":"3 GitHub submission instructions","heading":"3.1 Background","text":"web site makes use bookdown package render collection .Rmd files nicely formatted online book chapters subchapters. job submit slightly modified version community contribution .Rmd file GitHub repository source files web site stored. backend, admins divide chapters book sections order .community contribution different format, create short .Rmd file explains , includes links relevant files, slides, etc. can post GitHub repo (another online site.)","code":""},{"path":"github-submission-instructions.html","id":"preparing-your-.rmd-file","chapter":"3 GitHub submission instructions","heading":"3.2 Preparing your .Rmd file","text":"submit ONE Rmd file.completing modifications, .Rmd look like sample .Rmd.Create concise, descriptive name project. instance, name base_r_ggplot_graph something similar work contrasting/working base R graphics ggplot2 graphics. Check .Rmd filenames file make sure name isn’t already taken. project name words joined underscores, white space. Use .Rmd .rmd. addition, letters must lowercase. Create copy .Rmd file new name.Create concise, descriptive name project. instance, name base_r_ggplot_graph something similar work contrasting/working base R graphics ggplot2 graphics. Check .Rmd filenames file make sure name isn’t already taken. project name words joined underscores, white space. Use .Rmd .rmd. addition, letters must lowercase. Create copy .Rmd file new name.Completely delete YAML header (section top .Rmd includes name, title, date, output, etc.) including --- line.Completely delete YAML header (section top .Rmd includes name, title, date, output, etc.) including --- line.Choose short, descriptive, human readable title project title show table contents – look examples panel left. Capitalize first letter (“sentence case”). first line document, enter single hashtag, followed single whitespace, title. important follow format bookdown renders title header. use single # headers anywhere else document.Choose short, descriptive, human readable title project title show table contents – look examples panel left. Capitalize first letter (“sentence case”). first line document, enter single hashtag, followed single whitespace, title. important follow format bookdown renders title header. use single # headers anywhere else document.second line blank, followed name(s):\n# Base R vs. ggplot2\n\nAaron Burr Alexander Hamilton\n\ncontent starts . second line blank, followed name(s):project requires data, please use built-dataset read directly URL, :\ndf <- readr::read_csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\")  absolutely must include data file, please use small one, many reasons desirable keep repository size small possible.project requires data, please use built-dataset read directly URL, :df <- readr::read_csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/addresses.csv\")  absolutely must include data file, please use small one, many reasons desirable keep repository size small possible.included setup chunk .Rmd file, please remember remove label setup chunk, .e., use:\n{r, include=FALSE}\ninstead :\n{r setup, include=FALSE}included setup chunk .Rmd file, please remember remove label setup chunk, .e., use:instead :project requires libraries installed included document, please adhere following conventions. evaluate install.packages() statements document. Consumers .Rmd file won’t want packages get installed knit document. Include library() statements top .Rmd file, title, name, setup, content. chapter requires installation package source (GitHub installation), please add comment identifying . Please mention well PR. example library() section install statements won’t evaluated:\n\n# remotes::install_github(\"twitter/AnomalyDetection\")\nlibrary(\"AnomalyDetection\") # must installed sourceIf project requires libraries installed included document, please adhere following conventions. evaluate install.packages() statements document. Consumers .Rmd file won’t want packages get installed knit document. Include library() statements top .Rmd file, title, name, setup, content. chapter requires installation package source (GitHub installation), please add comment identifying . Please mention well PR. example library() section install statements won’t evaluated:developed .Rmd file moving library() statements rest file content, highly recommended knit review document . may change namespace available section code development, causing function work exhibit unexpected behavior.file contain getwd() / setwd() calls (never use scripts anyway!) write statements.Want get fancy? See optional tweaks section .","code":"# Base R vs. ggplot2\n\nAaron Burr and Alexander Hamilton\n\nYour content starts here. {r, include=FALSE}{r setup, include=FALSE}\n# remotes::install_github(\"twitter/AnomalyDetection\")\nlibrary(\"AnomalyDetection\") # must be installed from source"},{"path":"github-submission-instructions.html","id":"submission-steps","chapter":"3 GitHub submission instructions","heading":"3.3 Submission steps","text":"submit work, following “Workflow #4” – submitting pull request someone else’s repository write access. Instructions available lecture slides topic well tutorial. repeated abbreviated form, specific instructions naming conventions, content information, important details.Fork cc22mw repo (repo) GitHub account.Fork cc22mw repo (repo) GitHub account.Clone/download forked repo local computer.Clone/download forked repo local computer.Create new branch name project name, case sample_project. skip step. merge PR doesn’t come branch. already forgot , check tutorial fix .Create new branch name project name, case sample_project. skip step. merge PR doesn’t come branch. already forgot , check tutorial fix .Copy modified .Rmd file name root directory branch. example, sample_project.Rmd.Copy modified .Rmd file name root directory branch. example, sample_project.Rmd.include .html file. (order bookdown package work, .Rmd files rendered behind scenes.)include .html file. (order bookdown package work, .Rmd files rendered behind scenes.)[OPTIONAL] resources (images) included project, create folder resources/. example, resources/sample_project/. Put resources files . sure change links .Rmd include resources/.../, example:\n![Test Photo](resources/sample_project/pumpkins.jpg)[OPTIONAL] resources (images) included project, create folder resources/. example, resources/sample_project/. Put resources files . sure change links .Rmd include resources/.../, example:![Test Photo](resources/sample_project/pumpkins.jpg)ready submit project, push branch remote repo. Follow tutorial create pull request.ready submit project, push branch remote repo. Follow tutorial create pull request.point back forth begin team managing pull requests. asked make changes, simply make changes local branch, save, commit, push GitHub. new commits added pull request; need , , create new pull request. (, based circumstances, make sense close pull request start new one, tell .)point back forth begin team managing pull requests. asked make changes, simply make changes local branch, save, commit, push GitHub. new commits added pull request; need , , create new pull request. (, based circumstances, make sense close pull request start new one, tell .)pull request merged, ’s fine delete local clone (folder) well forked repository GitHub account.pull request merged, ’s fine delete local clone (folder) well forked repository GitHub account.","code":""},{"path":"github-submission-instructions.html","id":"optional-tweaks","chapter":"3 GitHub submission instructions","heading":"3.4 Optional tweaks","text":"prefer links chapter open new tabs, add {target=\"_blank\"} link, :\n[edav.info](edav.info){target=\"_blank\"}prefer links chapter open new tabs, add {target=\"_blank\"} link, :[edav.info](edav.info){target=\"_blank\"}Note headers (##, ###, etc.) converted numbered headings : ## –> 3.1 ### –> 3.1.1  headings appear chapter subheadings sub-subheadings navigation panel left. Think logical structure users navigate chapter. recommend using ## ### headings since “sub-sub-subheadings” 4.1.3.4 generally unnecessary look messy.Note headers (##, ###, etc.) converted numbered headings : ## –> 3.1 ### –> 3.1.1  headings appear chapter subheadings sub-subheadings navigation panel left. Think logical structure users navigate chapter. recommend using ## ### headings since “sub-sub-subheadings” 4.1.3.4 generally unnecessary look messy.Unfortunately, ’s simple way preview chapter ’s actually merged project. (bookdown preview_chapter() option works entire book rendered least become complex require packages project grows.) really want preview , fork clone minimal bookdown repo, add .Rmd file, click “Build book” button Build tab (next Git), open .html files _book folder web browser see rendered book.  ’re interested bookdown options, see official reference book.  useful tweaks share? Submit issue PR.Unfortunately, ’s simple way preview chapter ’s actually merged project. (bookdown preview_chapter() option works entire book rendered least become complex require packages project grows.) really want preview , fork clone minimal bookdown repo, add .Rmd file, click “Build book” button Build tab (next Git), open .html files _book folder web browser see rendered book.  ’re interested bookdown options, see official reference book.  useful tweaks share? Submit issue PR.","code":""},{"path":"github-submission-instructions.html","id":"faq","chapter":"3 GitHub submission instructions","heading":"3.5 FAQ","text":"","code":""},{"path":"github-submission-instructions.html","id":"what-should-i-expect-after-creating-a-pull-request","chapter":"3 GitHub submission instructions","heading":"3.5.1 What should I expect after creating a pull request?","text":"Within week create pull request, apply label assign classmate “PR merger” review files submit see meet requirements.Within week create pull request, apply label assign classmate “PR merger” review files submit see meet requirements.take time can process pull requests, long see pull request repo, don’t worry.take time can process pull requests, long see pull request repo, don’t worry.PR merger contacts regarding pull request, usually means files fail meet requirements. explain wrong, please fix soon possible.PR merger contacts regarding pull request, usually means files fail meet requirements. explain wrong, please fix soon possible.","code":""},{"path":"github-submission-instructions.html","id":"what-if-i-catch-mistakes-before-my-pull-request-is-merged","chapter":"3 GitHub submission instructions","heading":"3.5.2 What if I catch mistakes before my pull request is merged?","text":"Just make changes branch, commit push GitHub. automatically added pull request.","code":""},{"path":"github-submission-instructions.html","id":"what-if-i-catch-mistakes-after-my-pull-request-is-merged","chapter":"3 GitHub submission instructions","heading":"3.5.3 What if I catch mistakes after my pull request is merged?","text":"may submit additional pull requests fix material site. edits small, fixing typos, easiest make edits directly GitHub, following instructions. merge first pull requests edits, please patient.","code":""},{"path":"github-submission-instructions.html","id":"other-questions","chapter":"3 GitHub submission instructions","heading":"3.5.4 Other questions","text":"additional questions, please ask Discussions section respond.Thank contributions!","code":""},{"path":"sample-project.html","id":"sample-project","chapter":"4 Sample project","heading":"4 Sample project","text":"Joe Biden Donald TrumpThis chapter gives sample layout Rmd file.Test Photo","code":""},{"path":"geographic-visualization-by-ggmap.html","id":"geographic-visualization-by-ggmap","chapter":"5 Geographic visualization by ggmap","heading":"5 Geographic visualization by ggmap","text":"Yuta AdachiAs community contribution EDAV class, created cheat sheet geographic visualization using ggmap.link cheat sheet .","code":""},{"path":"geographic-visualization-by-ggmap.html","id":"motivation-for-this-project","chapter":"5 Geographic visualization by ggmap","heading":"5.1 Motivation for this project","text":"sometimes want describe fact using geographic visualization. example, ’m looking shortest path Columbia University Central Park, like see route background road map can understand street walk. However, seems difficult create route map geographic visualizations original ggplot2 packages, far know.R package, “ggmap”, makes easy download choose various kinds map tiles Google Maps Stamen Maps. addition, might feel easy plot data since can deal ggplot2 framework familiar .’s ’m eager learn use ggmap package create cheat sheet everyone.","code":""},{"path":"geographic-visualization-by-ggmap.html","id":"my-own-evaluationroom-for-improvement","chapter":"5 Geographic visualization by ggmap","heading":"5.2 My own evaluation/Room for improvement","text":"creating cheat sheet, learned utilize ggmap package, also type plots can choose geographic visualization. Specifically, order introduce three examples readers can learn use package practical way, researched implemented several types plots related geographic visualization route map scatter plot map.Though learned many things project, can improve cheat sheet adding examples types data visualization. example, may create another density plot using continuous variable, also add flow map describe transitions several locations opportunity create next time.","code":""},{"path":"googlevis.html","id":"googlevis","chapter":"6 googleVis","heading":"6 googleVis","text":"Wenqi SunThe googleVis package provides interface R Google’s charts tools. allows users create web pages interactive charts based R data frames. Charts displayed locally via R HTTP help server. modern browser Internet connection required. data remains local uploaded Google.created cheat sheet googleVis. covers charts options.Link: https://github.com/Nntraveler/googleVis_cheatsheet/blob/main/googleVis.pdf","code":""},{"path":"googlevis.html","id":"motivation-for-this-project-1","chapter":"6 googleVis","heading":"6.1 Motivation for this project","text":"Google Charts powerful tool visualization HTML. provides easy quick way generate interactive charts.advantages include following:variety chartsA variety chartsExtensive set options customizationExtensive set options customizationCross-browser compatibilityCross-browser compatibilityDashboard Controls user interactionDashboard Controls user interactionSupport dynamic dataSupport dynamic dataThe googleVis package provides way use Google charts R conveniently. Although detailed documentation, users may need clarification chart options work cases since cheat sheet.Therefore, creating cheat sheet googleVis, everyone can get easier use googleVis.","code":""},{"path":"googlevis.html","id":"my-own-evaluation-of-the-project","chapter":"6 googleVis","heading":"6.2 My own evaluation of the project","text":"creating cheatsheet, Ihave better understanding Google charts googleVis packagehave better understanding Google charts googleVis packageexperienced happiness contributing something open source projectsexperienced happiness contributing something open source projectsexplored variety cheatsheets found ideal layout projectexplored variety cheatsheets found ideal layout projectWhat’s , think space improvement:options part, better way show use options vividly. Due limited space, just put table .options part, better way show use options vividly. Due limited space, just put table .compressed charts look bad charts like Anno, Cal, Timeline charts. assign space adjust data.compressed charts look bad charts like Anno, Cal, Timeline charts. assign space adjust data.","code":""},{"path":"text-data-visualization-by-tidytext.html","id":"text-data-visualization-by-tidytext","chapter":"7 Text data visualization by tidytext","heading":"7 Text data visualization by tidytext","text":"Xiaolin Sima Yanni ChenAs community contribution, created cheatsheet text data visualization tidytext.\ncheatsheet can found ","code":""},{"path":"text-data-visualization-by-tidytext.html","id":"motivation-for-the-project-and-need-it-addrressed","chapter":"7 Text data visualization by tidytext","heading":"7.1 Motivation for the project and need it addrressed","text":"Text mining natural language processing essential complicated field lot tools ways analyze. However, found tidytext useful door helping us open world text mining. meet text data, using tidytext package can make many text analysis tasks easier effective. Much infrastructure needed text mining tidy data frames already exists widely used packages like dplyr, tidyr ggplot2. way created cheatsheet, providing functions examples allow use tidytext package combined existing infrastructure basic text analysis works.","code":""},{"path":"text-data-visualization-by-tidytext.html","id":"own-evaluation-of-the-project","chapter":"7 Text data visualization by tidytext","heading":"7.2 Own evaluation of the project","text":"creating cheatsheet, learned use tidytext package text frequency sentiment analysis, also got familiar combine tidytext package data visualization tools, example ggplot wordcloud. cheatsheet generally useful someone wants visualize text data analysis, specifically word frequency sentiment analysis using R.However, also places need improve. Adding example limited wine tasting review might one place make cheatsheet generalized. Also, deeper sentiment analysis regarding category can listed analysis room allowed.","code":""},{"path":"cheatsheet-of-ggally-including-ggcoef_model-and-ggpairs.html","id":"cheatsheet-of-ggally-including-ggcoef_model-and-ggpairs","chapter":"8 Cheatsheet of GGally (including ggcoef_model and ggpairs)","heading":"8 Cheatsheet of GGally (including ggcoef_model and ggpairs)","text":"Xinhao Dai","code":""},{"path":"cheatsheet-of-ggally-including-ggcoef_model-and-ggpairs.html","id":"introductions-of-ggally","chapter":"8 Cheatsheet of GGally (including ggcoef_model and ggpairs)","heading":"8.0.1 Introductions of GGally","text":"ggplot2 R package plotting based grammar graphics. GGally extension ggplot2. adds several helpful functions reduce difficulties combining different geoms. enable novices quickly start using packet, create cheatsheet GGally.cheatsheet includes several essential efficient plots explorary data analysis visualization. First, ’s ggcoef_model function, helps visualize coefficients fitted model. ’s intuitive clear. Moreover, enables us compare several models plot can choose best model among . Second, ’s ggpairs() function, shows relationships every two variables dataset. helps us indentify ’s relevent variable response variable. Moreover, cheatsheet display several high-level plots can used ggpairs order help users clear intuiation.project, learned quickly read documents packet distinguish functions essential helpful ones. Moreover, learned create tidy beautiful cheatsheet users. another chance, try create templeate rather use rstudio templeate.can find pdf version cheetsheet https://github.com/Russell-/cheatsheet--ggally. enclosed image cheatsheet.Reference: https://ggobi.github.io/ggally/index.html.","code":""},{"path":"cheatsheet-for-data-science.html","id":"cheatsheet-for-data-science","chapter":"9 Cheatsheet for data science","heading":"9 Cheatsheet for data science","text":"Liri Chen Shuo Liu","code":""},{"path":"cheatsheet-for-data-science.html","id":"what-we-learned","chapter":"9 Cheatsheet for data science","heading":"9.1 What We Learned","text":"community contribution project, made data science cheatsheet, obtained overall review data science knowledge structure, applications, opportunities. motivation making cheatsheet cheatsheet help us prepare data science job interviews, well help us studying finals several courses. cheatsheet includes knowledge areas probability statistics, hypothesis testings machine learning models. statistics section, included probability functions distributions. hypothesis testing section, included knowledge sample population distribution, well ways using sample statistics confidence interval check null hypothesis rejection. machine learning section, incorporate models linear regression, logistic regression, decision tree, random forest KNN. also covered knowledge model evaluation, dimension reduction neural networks.community contribution project, organized reviewed data science concepts knowledge. future work includes expanding existing knowledge points, adding detailed descriptions, creating front-end display pages, Github pages.","code":""},{"path":"cheatsheet-for-data-science.html","id":"link","chapter":"9 Cheatsheet for data science","heading":"9.2 Link","text":"Link cheatsheet:\nhttps://drive.google.com/file/d/1gfHUbs1YxJ-_hpP4-jVsmw772312Cor4/view?usp=share_link","code":""},{"path":"cheatsheet-for-data-science.html","id":"reference","chapter":"9 Cheatsheet for data science","heading":"9.3 Reference","text":"cheatsheet cites template contents Aaron Wang: https://github.com/aaronwangy/Data-Science-Cheatsheet","code":""},{"path":"cheatsheet-for-plotly.html","id":"cheatsheet-for-plotly","chapter":"10 Cheatsheet for Plotly","heading":"10 Cheatsheet for Plotly","text":"Taichen Zhou, Yichen HuangFor community contribution EDAV class, researched created R graphing library - plotly can create integrative, publication-quality graphs. cheat sheet, provide example create basic charts, statistical charts, scientific charts etc. Plotly.\nlink cheat sheet .","code":""},{"path":"cheatsheet-for-plotly.html","id":"motivation","chapter":"10 Cheatsheet for Plotly","heading":"10.1 Motivation","text":"Data visualization crucial part data scientist. tech industry matures, demand better visualizations increases. type visualization specialty, just like line chart describes trend better bar plot. display data extraordinary fashion, Plotly insanely powerful explaining exploring data. reason .","code":""},{"path":"cheatsheet-for-plotly.html","id":"interactivity","chapter":"10 Cheatsheet for Plotly","heading":"10.1.1 Interactivity","text":"Plotly provides feature visualization library — interactivity. Plotly allows users improve visualization experience using customizable interactive tools. visualize data Plotly, can add interactive features like buttons, sliders, dropdowns display different perspectives graphs.","code":""},{"path":"cheatsheet-for-plotly.html","id":"customization-and-flexibility","chapter":"10 Cheatsheet for Plotly","heading":"10.1.2 Customization and Flexibility","text":"Plotly like piece paper, can draw whatever want . Compared traditional visualization tools like ggplot2, Plotly allows full control plotted.","code":""},{"path":"cheatsheet-for-plotly.html","id":"evaluation-and-future-improvement","chapter":"10 Cheatsheet for Plotly","heading":"10.2 Evaluation and Future Improvement","text":"making Plotly cheat sheet, learned graph talked ggplot, also graph used Machine Learning example, ROC PCA visualization. Also, got familiar writing R markdown file.\nstill things can furtherly improve, like can add types graphs cheat sheet example, alluvia plot. Moreover, introduction parameters functions plot graph can talked little bit .","code":""},{"path":"dataexplorer-cheatsheet-eda-made-easier.html","id":"dataexplorer-cheatsheet-eda-made-easier","chapter":"11 DataExplorer Cheatsheet, EDA made easier","heading":"11 DataExplorer Cheatsheet, EDA made easier","text":"Ryan McNamara Matthieu SchulzAs community contribution, created cheat sheet DataExplorer package automates process EDA.\ncheatsheet can found ","code":""},{"path":"dataexplorer-cheatsheet-eda-made-easier.html","id":"motivation-for-the-contribution","chapter":"11 DataExplorer Cheatsheet, EDA made easier","heading":"11.1 Motivation for the contribution","text":"Exploratory data analysis, EDA, initial necessary step diagnosing dataset one plans work . EDA can used standalone practice explore dataset report observations/hypotheses, can used precursor application ML algorithms. either case, crucial explore one’s data drawing conclusions. Common examples EDA, often repeated, include: visualizing variable distributions, exploring relationships variables, documenting missing values, etc. Many explorations done using graphs/charts histograms, box plots, scatter plots. EDA vital part data analysis/predictive modeling, often tedious write repetitive code required make visualizations.R package, DataExplorer, automates process EDA makes much simpler faster produce exploratory visuals. package easy learn great tool data scientist looking speed analyses. online tutorials explaining basics DataExplorer, unable find resource allows quick referencing package’s different functions. Thus, decided construct cheat sheet DataExplorer Community Contribution. believe convenient cheat sheet make easy anyone familiarize package quickly reference capabilities package.","code":""},{"path":"dataexplorer-cheatsheet-eda-made-easier.html","id":"evaluation-of-dataexplorer-and-learnings","chapter":"11 DataExplorer Cheatsheet, EDA made easier","heading":"11.2 Evaluation of DataExplorer and learnings","text":"creating cheat sheet learned lot power DataExplorer package. seen quickly create figures give us overview dataset using many plotting functions available. useful function DataExplorer package create_report function, compile HTML report plots available package. single function gives user complete overview dataset working , including information distributions, missing values, correlations. DataExplorer package essentially performs EDA user, expediting process exploring one’s data. certainly using create_report function data-driven project work future.also learned lot data.table data structure working assignment. using data.frame data structure throughout semester, however, DataExplorer package designed work data.table. data.table advantages data.frame, including speed ability rename columns, group columns, sort columns directly within data.table syntax. interested learning data.table use code moving forward.project , start exploring data.table package depth. DataExplorer package works data.frames well, however, designed work data.tables (data.table updated place data.frame ). Given advantages data.table data.frame, worth learning becoming familiar . also create cheat sheet using different software Google Docs/PowerPoint somewhat difficult create drawings/images. create another cheat sheet (.e. data.table package), create using Adobe Illustrator similar application. Overall, learned lot creation cheat sheet hope others find value well.","code":""},{"path":"dataexplorer-cheatsheet-eda-made-easier.html","id":"sources","chapter":"11 DataExplorer Cheatsheet, EDA made easier","heading":"11.3 Sources:","text":"https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html\nhttps://cran.r-project.org/web/packages/DataExplorer/DataExplorer.pdf","code":""},{"path":"data-visualization-with-ggplot2-r-and-matplotlib-python-cheat-sheet.html","id":"data-visualization-with-ggplot2-r-and-matplotlib-python-cheat-sheet","chapter":"12 Data Visualization with GGPlot2 (R) and MatPlotLib (Python) Cheat Sheet","heading":"12 Data Visualization with GGPlot2 (R) and MatPlotLib (Python) Cheat Sheet","text":"Kylie BrothersMotivationThroughout undergraduate, graduate, professional careers, two widely used statistical languages Python R. languages many similarities, can differing syntaxes coding implementations.project, important create cheat sheet individual can easily navigate languages transfer knowledge learned course Python. Therefore, created cheat sheet GGPlot2 R, learned extensively class, MatPlotLib Python, primary visualization package used undergraduate graduate careers. packages cheat sheets, respectively, formatted differently can hard parse gain exact line(s) code need making comparisons migrating code another programming language.Link cheat sheet: https://github.com/kylie-brothers/GGPlot2--MatPlotLib-Cheat-Sheet/blob/main/GGPlot2%20and%20MatPlotLib%20Cheatsheet.pdfIf Time…time, next time create cheat sheet navigate packages, include faceting, subplots, tick markers. addition, think useful also comparison GGPlot2 (R) Seaborn (Python); MatPlotLib (Python) Seaborn (Python). three packages heavily used visualization easy access cheat sheet languages packages make lot quicker easier transverse coding trying implemented.","code":""},{"path":"map-plots-with-highcharts.html","id":"map-plots-with-highcharts","chapter":"13 Map Plots with Highcharts","heading":"13 Map Plots with Highcharts","text":"Hugo GinouxHighcharts originally extremely complete Javascript library data visualization. R wrapper version library “highcharter”. difficult understand ggplot2 provides interactivity satisfying.chapter, explore possibility create map charts, say heatmaps colored cells shape countries, regions states. raw example, showing GDP state US (random data):Spectacular, isn’t ? Let’s dive different parts code another example plotting proportion Christians 2020 different European countries.","code":"\nlibrary(highcharter)\nlibrary(dplyr)\nlibrary(readxl)\nmapdata <- get_data_from_map(download_map_data(\"custom/usa-and-canada\"))\n\nfake_gdp <- data.frame(code=mapdata$`hc-a2`) %>%\n  mutate(value = 1e5 * abs(rt(nrow(mapdata), df = 10)))\n\nhcmap(\n  \"custom/usa-and-canada\",\n  data = fake_gdp,\n  value = \"value\",\n  joinBy = c(\"hc-a2\", \"code\"),\n  dataLabels = list(enabled = TRUE, format = \"{point.name}\"),\n  borderColor = \"#FAFAFA\",\n  borderWidth = 0.1,\n  tooltip = list(\n    valueDecimals = 2,\n    valuePrefix = \"$\",\n    valueSuffix = \"USD\"\n  )\n) %>%\n  hc_title(text = \"Fake GDP per State\") %>%\n  hc_add_theme(hc_theme_ffx())"},{"path":"map-plots-with-highcharts.html","id":"collect-data","chapter":"13 Map Plots with Highcharts","heading":"13.0.1 Collect data","text":"need dataframe containing least name contry value plot heatmap. example, data comes https://www.worldreligiondatabase.org/. downloaded form xlsx file, stored personal server.","code":"\ndata = read_excel(\"resources/mapcharts/religions.xlsx\") \ndata = data[data[['Religion 1']]=='Christians', c('Country Name','Religion 1','Pct_2020')]\n\nhead(data)## # A tibble: 6 × 3\n##   `Country Name` `Religion 1` Pct_2020\n##   <chr>          <chr>           <dbl>\n## 1 Afghanistan    Christians   0.000194\n## 2 Albania        Christians   0.376   \n## 3 Algeria        Christians   0.00295 \n## 4 American Samoa Christians   0.980   \n## 5 Andorra        Christians   0.908   \n## 6 Angola         Christians   0.929"},{"path":"map-plots-with-highcharts.html","id":"download-the-map-data-and-filter","chapter":"13 Map Plots with Highcharts","heading":"13.0.2 Download the map data and filter","text":", need download map info get_data_from_map(download_map_data(name_of_geography)). list available geographies examples : https://code.highcharts.com/mapdata/ (lot!). example, need map Europe., keep rows country Europe : filter data mapdata.","code":"\nmapdata = get_data_from_map(download_map_data(\"custom/europe\"))\n\nmapdata## # A tibble: 50 × 14\n##    hc-gr…¹ hc-mi…² hc-mi…³ hc-ke…⁴ `hc-a2` name  label…⁵ count…⁶ subre…⁷ regio…⁸\n##    <chr>     <dbl>   <dbl> <chr>   <chr>   <chr> <chr>   <chr>   <chr>   <chr>  \n##  1 admin0     0.19    0.44 dk      DK      Denm… 4       Den.    Northe… Europe…\n##  2 admin0     0.56    0.16 fo      FO      Faro… 6       Faeroe… Northe… Europe…\n##  3 admin0     0.09    0.39 hr      HR      Croa… 6       Cro.    Southe… Europe…\n##  4 admin0     0.34    0.59 nl      NL      Neth… 5       Neth.   Wester… Europe…\n##  5 admin0     0.6     0.53 ee      EE      Esto… 6       Est.    Northe… Europe…\n##  6 admin0     0.54    0.49 bg      BG      Bulg… 4       Bulg.   Easter… Europe…\n##  7 admin0     0.38    0.53 es      ES      Spain 2       Sp.     Southe… Europe…\n##  8 admin0     0.44    0.38 it      IT      Italy 2       Italy   Southe… Europe…\n##  9 admin0     0.68    0.41 sm      SM      San … 6       S.M.    Southe… Europe…\n## 10 admin0     0.62    0.44 va      VA      Vati… 6       Vat.    Southe… Europe…\n## # … with 40 more rows, 4 more variables: `iso-a3` <chr>, `iso-a2` <chr>,\n## #   `woe-id` <chr>, continent <chr>, and abbreviated variable names\n## #   ¹​`hc-group`, ²​`hc-middle-x`, ³​`hc-middle-y`, ⁴​`hc-key`, ⁵​labelrank,\n## #   ⁶​`country-abbrev`, ⁷​subregion, ⁸​`region-wb`\ndata = data[data[['Country Name']]%in%mapdata$name,]"},{"path":"map-plots-with-highcharts.html","id":"plot-the-map","chapter":"13 Map Plots with Highcharts","heading":"13.0.3 Plot the map","text":"now ready plot first version map! simply call function hcmap arguments:map use : case, “custom/europe” (argument inside download_map_data())data : dataframe containing names countries value plotvalue : name column used heatmap : case, “Pct_2020”joinBy : names columns 2 dataframes corresponding names countries. names must correspond : “UK” first one “United Kingdom” workThe result already interesting. parameters can added make chart even impressive.","code":"\nhcmap(\n  \"custom/europe\",\n  data = data,\n  value = \"Pct_2020\",\n  joinBy = c(\"name\", \"Country Name\")\n)"},{"path":"map-plots-with-highcharts.html","id":"parameters","chapter":"13 Map Plots with Highcharts","heading":"13.0.4 Parameters","text":"","code":""},{"path":"map-plots-with-highcharts.html","id":"add-labels","chapter":"13 Map Plots with Highcharts","heading":"13.0.4.1 Add labels","text":"parameter “datalabels” can display names countries.","code":"\nhcmap(\n  \"custom/europe\",\n  data = data,\n  value = \"Pct_2020\",\n  joinBy = c(\"name\", \"Country Name\"),\n  dataLabels = list(enabled = TRUE, format = \"{point.name}\")\n)"},{"path":"map-plots-with-highcharts.html","id":"plot-in","chapter":"13 Map Plots with Highcharts","heading":"13.0.4.2 Plot in %","text":"parameter “tooltip” allows us modify displayed mouse hovers country. , plotted proportion %, rounded 1 decimal added suffix “%”.","code":"\ndata['Pct_2020_%'] = data['Pct_2020']*100\n\nhcmap(\n  \"custom/europe\",\n  data = data,\n  value = \"Pct_2020_%\",\n  joinBy = c(\"name\", \"Country Name\"),\n  dataLabels = list(enabled = TRUE, format = \"{point.name}\"),\n  tooltip = list(\n    valueDecimals = 1,\n    valueSuffix = '%'\n  )\n)"},{"path":"map-plots-with-highcharts.html","id":"add-title-theme-colors","chapter":"13 Map Plots with Highcharts","heading":"13.0.4.3 Add title, theme, colors","text":"can add title function “hc_title”. also possible add subtitles. function “hc_add_theme” adds theme. Finally, can change min max colors heatmap giving hexadecimal codes function “hc_colorAxis”. missing values always appear white.","code":"\nhcmap(\n  \"custom/europe\",\n  data = data,\n  value = \"Pct_2020_%\",\n  joinBy = c(\"name\", \"Country Name\"),\n  dataLabels = list(enabled = TRUE, format = \"{point.name}\"),\n  tooltip = list(\n    valueDecimals = 1,\n    valueSuffix = '%'\n  )\n) %>%\n  hc_title(text = \"Proportion of Christian per country in 2020\") %>%\n  hc_add_theme(hc_theme_ffx()) %>% \n  hc_colorAxis(minColor = \"#4242f5\", maxColor = \"#f54242\")"},{"path":"introduction-of-machine-learning-in-r.html","id":"introduction-of-machine-learning-in-r","chapter":"14 Introduction of machine learning in R","heading":"14 Introduction of machine learning in R","text":"Feifan Li","code":"\nlibrary(caret)\nlibrary(mlbench)\nlibrary(naivebayes)\nlibrary(rpart)\nlibrary(randomForest)\nlibrary(ggplot2)\nlibrary(lattice)\nlibrary(recipes)\nlibrary(dplyr)\nlibrary(AppliedPredictiveModeling)\nlibrary(gridExtra)\nlibrary(caTools)"},{"path":"introduction-of-machine-learning-in-r.html","id":"introduction","chapter":"14 Introduction of machine learning in R","heading":"14.1 Introduction","text":"Nowadays, Machine learning useful tool data-driven world. Social applications like Facebook WhatsApp made data accessible, companies can use data magic things like customer classification, fraud detection, decision making, advertising strategy. data helps companies serve customers effective way. one important tool process interpret data machine learning. help reveal many hidden patterns behind numbers. Hence, tutorial help get basic understanding use machine learning R. Since R efficient data processing data visualization, machine learning can incorporated easy way.","code":""},{"path":"introduction-of-machine-learning-in-r.html","id":"required-packages","chapter":"14 Introduction of machine learning in R","heading":"14.2 Required Packages:","text":"tutorial, need import packages. depend others.Packages required:\n1.caret\n2.mlbench\n3.naivebayes\n4.rpart\n5.randomForest\n6.ggplot2\n7.lattice\n8.recipes\n9.dplyr\n10.AppliedPredictiveModeling\n11.gridExtra\n12.caTools","code":""},{"path":"introduction-of-machine-learning-in-r.html","id":"data-preprocessing","chapter":"14 Introduction of machine learning in R","heading":"14.3 Data Preprocessing","text":"","code":""},{"path":"introduction-of-machine-learning-in-r.html","id":"load-dataset","chapter":"14 Introduction of machine learning in R","heading":"14.3.1 Load DataSet","text":"tutorial, just import built-dataset R library, iris. several different ways read dataset R. First , file csv file, can use “read_csv” read . file R file, can use “load” command import dataset. file txt file, can use “read.delim”: specifying separator, can break lines chunks.","code":"\n#load data and name it as iris\n#iris <- read.csv(\"iris.csv\", header=FALSE)\n\n#set header\ncolnames(iris) <- c(\"Sepal.Length\",\"Sepal.Width\",\"Petal.Length\",\"Petal.Width\",\"Species\")"},{"path":"introduction-of-machine-learning-in-r.html","id":"split-the-dataset","chapter":"14 Introduction of machine learning in R","heading":"14.3.2 Split the Dataset","text":"preprocess data, need split dataset train set test set. train set, train model set test model’s accuracy test set. split ensures independency train test stes.ratio, usually assume 80% versus 20%, means 80% data training set, remaining 20% test set. can adjust ratio based actual dataset. However, set ratio large, assign dataset train set, leaves little data tests. hand, ratio low, model receive sufficient training, influencing accuracy.","code":"\ntrainIndex <- createDataPartition(iris$Species, p = 0.8, \n                                  list = FALSE, \n                                  times = 1)\n\ntrain_set <- iris[trainIndex,]\ntest_set <- iris[-trainIndex,]\n\n#check size\nnrow(train_set)## [1] 120\nnrow(test_set)## [1] 30"},{"path":"introduction-of-machine-learning-in-r.html","id":"scaling","chapter":"14 Introduction of machine learning in R","heading":"14.3.3 Scaling","text":"two different ways adjust scale data: Scaling Centering. scaling, basically calculates Z score datapoint, formula \\(X-u/\\sigma\\). Moreover, another way centering, just subtracts data mean.graph , can see standardizing datapoints shifts mean 0 change overall distribution","code":"\nScaled_values <- preProcess(iris, method = c(\"center\", \"scale\"))\ntrain_scaled <- predict(Scaled_values, train_set)\ntest_scaled <- predict(Scaled_values, test_set)\n\nggplot(train_set, aes(x=Species, y=Sepal.Length))+\n  geom_point() +\n  ggtitle(\"Distribution of datapoint before scailing\")\nggplot(train_scaled, aes(x=Species, y=Sepal.Length))+\n  geom_point() +\n  ggtitle(\"Distribution of datapoint after scailing\")"},{"path":"introduction-of-machine-learning-in-r.html","id":"missing-value","chapter":"14 Introduction of machine learning in R","heading":"14.3.4 Missing Value","text":"datasets, usually contains missing values. case, need impute values, several ways achieve goal, including mean, KNN, Random Forest, special symbols. tutorial, briefly discuss common two methods: KNN mean.Mean\nOne easy way fill missing value using mean. example, one column feature contains several missing values, can compute average non-missing values fill value missing positions. advantage method efficient easy implement; however, filing mean accurately predict value, influences accuracy.KNNAnother common way use K nearest neighbor. specific, datapoint, can compute K nearest neighbor. using average neighbors’ values fill missing positions. One advantage method accuracy usually higher filing mean. However, KNN imputation take much longer time compute results, especially datasets high dimensions, called “curse dimensions”.","code":""},{"path":"introduction-of-machine-learning-in-r.html","id":"dimension-reduction","chapter":"14 Introduction of machine learning in R","heading":"14.3.5 Dimension Reduction","text":"datasets, include 50 100 features, directly training model original dataset consume huge amount time. Therefore, need reduce dimensions dataset make training efficient. Common methods like PCA (Principle Component Analysis) LDA (Linear Discriminant Analysis) useful dimension reductions. tutorial, talk PCA.PCA, Principle Component Analysis, effective method reducing dimensions. main mechanism PCA keeps data largest variance, preserves information.","code":"\npc <- prcomp(train_set[,c(1,2,3,4)],\n             center = TRUE,\n             scale. = TRUE)\n\n#print resutls after PCA\nprint(pc)## Standard deviations (1, .., p=4):\n## [1] 1.7102692 0.9489550 0.3953923 0.1346422\n## \n## Rotation (n x k) = (4 x 4):\n##                     PC1        PC2        PC3        PC4\n## Sepal.Length  0.5109847 0.41819189 -0.7042724  0.2607883\n## Sepal.Width  -0.2915540 0.90588239  0.2778236 -0.1311007\n## Petal.Length  0.5801762 0.02761653  0.1404367 -0.8018170\n## Petal.Width   0.5632818 0.06107341  0.6380376  0.5214323"},{"path":"introduction-of-machine-learning-in-r.html","id":"feature-selection","chapter":"14 Introduction of machine learning in R","heading":"14.3.6 Feature Selection","text":"Besides PCA, another way reduce dimension feature selection. Specifically, can use metrics filter unimportant features, keeping important ones. common metric use Pearson Coefficient. calculating pearson coefficient, can measure strong dependent variable related independent variable. , can drop features low coefficient.","code":"\ntarget = iris$Sepal.Length\n\ncor(iris$Sepal.Width,target)## [1] -0.1175698\ncor(iris$Petal.Length,target)## [1] 0.8717538\ncor(iris$Petal.Width,target)## [1] 0.8179411"},{"path":"introduction-of-machine-learning-in-r.html","id":"categorical-features","chapter":"14 Introduction of machine learning in R","heading":"14.3.7 Categorical Features","text":"categorical features, machine learning models directly process like numerical features. case, need convert categorical features numerical ones. One method called One hot Encoding. example, strings “red”,“green”, “yellow”. , “red” can represented 100, green 010, yellow 001. Even though one hot encoding can convert categorical features, obvious disadvantage: significantly increase dimensions dataset, slow efficiency model.","code":""},{"path":"introduction-of-machine-learning-in-r.html","id":"exploratory-data-analysis","chapter":"14 Introduction of machine learning in R","heading":"14.4 Exploratory Data Analysis","text":"train fit model dataset, can firstly exploratory analysis visualize dataset clear way.First , can use box-plot display overall distribution feature related target (Species). graph, can see species “Iris-Virginica” highest value nearly four features, “Iris-Setosa” lowest.showing distribution, can visualize number kind dataset. pie chart , can see three classes equal proportions: occupy 1/3 total data points.Lastly, can explore colinearity features. scatter plot , can see exist strong positive relationship Petal length Petal width.","code":"\np1 <- ggplot(data=train_set,aes(x=Species,y=Sepal.Length))+\n  geom_boxplot(fill=\"red\")\n\np2 <- ggplot(data=train_set,aes(x=Species,y=Sepal.Width))+\n  geom_boxplot(fill=\"blue\")\n\np3 <- ggplot(data=train_set,aes(x=Species,y=Petal.Length))+\n  geom_boxplot(fill=\"green\")\n\np4 <- ggplot(data=train_set,aes(x=Species,y=Petal.Width))+\n  geom_boxplot(fill=\"gray\")\n\ngrid.arrange(p1,p2,p3,p4,nrow=2)\nggplot(data=train_set,aes(x=Species,fill=Species))+\n  geom_histogram(stat=\"count\",width=1)+\n  coord_polar(\"x\",start=0) +\n  ggtitle(\"Proportion of three classes\")\ng1 <- ggplot(data=train_set,aes(x=Sepal.Length,y=Sepal.Width))+\n  geom_point()+\n  geom_smooth()\n\ng2 <- ggplot(data=train_set,aes(x=Sepal.Length,y=Petal.Length))+\n  geom_point()+\n  geom_smooth()\n\ng3 <- ggplot(data=train_set,aes(x=Sepal.Length,y=Petal.Width))+\n  geom_point()+\n  geom_smooth()\n\ng4 <- ggplot(data=train_set,aes(x=Sepal.Width,y=Petal.Length))+\n  geom_point()+\n  geom_smooth()\n\ng5 <- ggplot(data=train_set,aes(x=Sepal.Width,y=Petal.Width))+\n  geom_point()+\n  geom_smooth()\n\ng6 <- ggplot(data=train_set,aes(x=Petal.Length,y=Petal.Width))+\n  geom_point()+\n  geom_smooth()\n\ngrid.arrange(g1,g2,g3,g4,g5,g6,nrow=3)"},{"path":"introduction-of-machine-learning-in-r.html","id":"training-model","chapter":"14 Introduction of machine learning in R","heading":"14.5 Training Model","text":"previous part, can get basic understanding overall patterns dataset. section, start train fit machine learning models . First , train evaluate model efficient way, can use K-fold cross validation. general procedure firstly shuffle data random way split data several groups. iteration, test model one group, train remaining groups. graph illustrate process clear way.K Fold Cross Validation Process","code":"\nr_cv <- trainControl(method=\"repeatedcv\", \n                        number=10,\n                        repeats=5)"},{"path":"introduction-of-machine-learning-in-r.html","id":"knn","chapter":"14 Introduction of machine learning in R","heading":"14.5.1 KNN","text":"One intuitive machine learning model KNN, K nearest neighbor. idea firstly compute closest K neighbors; , can use majority voting derive result. example, k=5, three five neighbors label 1, two label 0, result 1. One advantage algorithm training process. small datasets, can complete prediction short amount time. However, dimension dataset increases, algorithm suffer curse dimensionK Fold Cross Validation ProcessAdvantage:\n1. easy implement, nearly training process\n2. can deal non-linear problems\n3. efficient accurate small datasetDisadvantage:1. Extremely slow large dataset\n2. Require feature scaling. Inappropriate scales significantly influence accuracy\n3. Suffer curse dimensions. data large number features, algorithm work well.","code":"\nset.seed(10)\nKNN <- train(Species~., \n             data=train_set, \n             method=\"knn\", \n             metric=\"accuracy\", \n             trControl=r_cv)\n\nggplot(KNN)"},{"path":"introduction-of-machine-learning-in-r.html","id":"random-forest","chapter":"14 Introduction of machine learning in R","heading":"14.5.2 Random Forest","text":"Another common machine learning model Random Forest. utilizes idea bagging, bootstraps samples dataset. iteration, train decision tree based samples provided. last step, can assemble different decision trees together. final results average output trees. accuracy random Forest much better single decision tree.Advantage:\n1. higher accuracy single decision tree\n2. can deal classification problems regression problems\n3. low variance due baggingDisadvantage: 1. number trees large, take huge amount time train\n2. Compared normal decision tree, low interpretability. looks like black box, visualize process easily.\n3. Still likely overfit","code":"\nset.seed(10)\nRF <- train(Species~., \n             data=train_set, \n             method=\"rf\", \n             metric=\"accuracy\", \n             trControl=r_cv)\n\nggplot(RF)"},{"path":"introduction-of-machine-learning-in-r.html","id":"svm","chapter":"14 Introduction of machine learning in R","heading":"14.5.3 SVM","text":"powerful machine learning model called SVM, Support Vector Machine. idea behind algorithm tries find hyperplane can separate two classes way maximize margin, can regarded optimal classification. Another key feature SVM called kernel trick. allows SVM deal datasets high dimensions. kernel function can compute inner product original space, project high dimensions, saves huge amounts computation. trick also helps us deal non-linear problems: data linear-separable low dimension separable higher dimension., besides radial basis kernel function, actually many kernel function. example, linear kernel function can useful linear-separable problems. polynominal kernel function can project datapoints higher dimensional space, making easier classify. reality, need try different kernel functions see one works better.Advantage:\n1. effective data high dimensions\n2. can deal linear non-linear separable problems\n3. highly accurate influenced outliersDisadvantage:\n1. size dataset large, take long time train\n2. low Interpretability, like black box\n3. many parameters need tune, hard choose best kernel function.","code":"\nset.seed(10)\nSVM <- train(Species~., \n             data=train_set, \n             method=\"svmRadial\", \n             metric=\"accuracy\", \n             trControl=r_cv)\n\nggplot(SVM)"},{"path":"introduction-of-machine-learning-in-r.html","id":"gradient-boosting","chapter":"14 Introduction of machine learning in R","heading":"14.5.4 Gradient Boosting","text":"Gradient boosting receives attention recent years, especially XGBoost. machine learning model widely used many competitions projects. main idea gradient boosting train series weak learning. Unlike bagging, generation model can completed last model fully trained. iteration, weak learner trained fit residual. several iterations, add weak learners together, constituting strong learner. many variations Gradient Boosting like AdaBoost, XGBoost, LightGBM.Advantage:\n1. results highly accurate\n2. need data scailing preprocessing. can handle numerical categorical features\n3. can deal missing valuesDisadvantage:\n1. dataset large, become computationally expensive\n2. low Interpretability, like black box\n3. many parameters need tune, taking long time find best set parameter.","code":"\nset.seed(10)\nGBM <- train(Species~., \n             data=train_set, \n             method=\"gbm\", \n             metric=\"accuracy\", \n             trControl=r_cv,\n             verbose = FALSE)\n\nggplot(GBM)"},{"path":"introduction-of-machine-learning-in-r.html","id":"naive-bayes","chapter":"14 Introduction of machine learning in R","heading":"14.5.5 Naive Bayes","text":"Naive Bayes one famous algorithm family supervised learning. algorithm founded based Bayes’ theorem, theorem showed picture attached . many types Naive Bayes Classifier, Bernoulli Naive Bayes, Gaussian Naive Bayes, Laplace Naive Bayes. need take closer look actual dataset order determine type use.Bayes TheoremAdvantage:\n1. Algorithm straightforward, easy implement\n2. Training process fast computations probabilities can completely instantly\n3. memory efficientDisadvantage:\n1. algorithm founded basis variable conditionally independent, assume independence real life\n2. accurate many cases\n3. Hard determine type Naive Bayes use maximize accuracy.","code":"\nset.seed(10)\nNaive_Bayes <- train(Species~., \n             data=train_set, \n             method=\"naive_bayes\", \n             metric=\"accuracy\", \n             trControl=r_cv)\n\nNaive_Bayes## Naive Bayes \n## \n## 120 samples\n##   4 predictor\n##   3 classes: 'setosa', 'versicolor', 'virginica' \n## \n## No pre-processing\n## Resampling: Cross-Validated (10 fold, repeated 5 times) \n## Summary of sample sizes: 108, 108, 108, 108, 108, 108, ... \n## Resampling results across tuning parameters:\n## \n##   usekernel  Accuracy   Kappa \n##   FALSE      0.9483333  0.9225\n##    TRUE      0.9500000  0.9250\n## \n## Tuning parameter 'laplace' was held constant at a value of 0\n## Tuning\n##  parameter 'adjust' was held constant at a value of 1\n## Accuracy was used to select the optimal model using the largest value.\n## The final values used for the model were laplace = 0, usekernel = TRUE\n##  and adjust = 1."},{"path":"introduction-of-machine-learning-in-r.html","id":"compare-models","chapter":"14 Introduction of machine learning in R","heading":"14.5.6 Compare Models","text":"can compare five models togetherFrom statistic , can see KNN best performance dataset.","code":"\nresults <- resamples(list(Naive_bayes=Naive_Bayes, GBM=GBM, KNN=KNN, SVM=SVM, RF=RF))\nsummary(results)## \n## Call:\n## summary.resamples(object = results)\n## \n## Models: Naive_bayes, GBM, KNN, SVM, RF \n## Number of resamples: 50 \n## \n## Accuracy \n##                  Min.   1st Qu.    Median      Mean 3rd Qu. Max. NA's\n## Naive_bayes 0.8333333 0.9166667 0.9166667 0.9500000       1    1    0\n## GBM         0.7500000 0.9166667 0.9166667 0.9466667       1    1    0\n## KNN         0.9166667 0.9166667 1.0000000 0.9683333       1    1    0\n## SVM         0.8333333 0.9166667 0.9166667 0.9533333       1    1    0\n## RF          0.7500000 0.9166667 0.9583333 0.9516667       1    1    0\n## \n## Kappa \n##              Min. 1st Qu. Median   Mean 3rd Qu. Max. NA's\n## Naive_bayes 0.750   0.875 0.8750 0.9250       1    1    0\n## GBM         0.625   0.875 0.8750 0.9200       1    1    0\n## KNN         0.875   0.875 1.0000 0.9525       1    1    0\n## SVM         0.750   0.875 0.8750 0.9300       1    1    0\n## RF          0.625   0.875 0.9375 0.9275       1    1    0"},{"path":"introduction-of-machine-learning-in-r.html","id":"metric-evaluation","chapter":"14 Introduction of machine learning in R","heading":"14.6 Metric & Evaluation","text":"order evaluate performance machine learning models, need use several metrics. different kinds problems, adopt different metrics. example, regression problems, can use R-squared measure strength regression. classification problems, can use confusion matrix ROC curve. section, talk metrics details","code":""},{"path":"introduction-of-machine-learning-in-r.html","id":"regression","chapter":"14 Introduction of machine learning in R","heading":"14.6.1 Regression","text":"regression problems, common metric use R-squared. \\(R^2\\) measures proportion dependent variable explained independent variable. range \\(R^2\\) 0 1. value 1.0, means every datapoint perfectly fitted; however, value 0.0, means datapoint fitted correctly. One problem metric number variables increases, \\(R^2\\) increases well. Hence, order negate effect, Adjusted R-Squared introduced, divided degree freedom.R-Squared","code":""},{"path":"introduction-of-machine-learning-in-r.html","id":"classifcation","chapter":"14 Introduction of machine learning in R","heading":"14.6.2 Classifcation","text":"Confusion Matrix\nclassification problems, confusion matrix can regarded intuitive way visualize performance. confusion matrix, correct results True Positive (TP) TN (True Negative), incorrect ones False Negative (FN) False Positive (FP). Based four values, can compute precision recall. Precision measure accurately model predict, recall indicate whether relevant cases retrieved. reality, precision recall usually negative related. case, F1 score introduced, combines precision recall, representative metric model’s performance.Confusion MatrixROC curve\nAnother nice metric often use ROC curve. graph drawn basis True positive rate (TPR) False positive rate (FPR). area curve called Area Curve (AUC). area equal 1, means machine learning model predicts perfectly every datapoint. area 0.5, model behaves like fair coin. 0, means model makes false predictions every time.ROC Curve","code":"\nresults <- predict(KNN, test_set)\nconfusionMatrix(results, as.factor(test_set$Species))## Confusion Matrix and Statistics\n## \n##             Reference\n## Prediction   setosa versicolor virginica\n##   setosa         10          0         0\n##   versicolor      0          9         0\n##   virginica       0          1        10\n## \n## Overall Statistics\n##                                           \n##                Accuracy : 0.9667          \n##                  95% CI : (0.8278, 0.9992)\n##     No Information Rate : 0.3333          \n##     P-Value [Acc > NIR] : 2.963e-13       \n##                                           \n##                   Kappa : 0.95            \n##                                           \n##  Mcnemar's Test P-Value : NA              \n## \n## Statistics by Class:\n## \n##                      Class: setosa Class: versicolor Class: virginica\n## Sensitivity                 1.0000            0.9000           1.0000\n## Specificity                 1.0000            1.0000           0.9500\n## Pos Pred Value              1.0000            1.0000           0.9091\n## Neg Pred Value              1.0000            0.9524           1.0000\n## Prevalence                  0.3333            0.3333           0.3333\n## Detection Rate              0.3333            0.3000           0.3333\n## Detection Prevalence        0.3333            0.3000           0.3667\n## Balanced Accuracy           1.0000            0.9500           0.9750"},{"path":"introduction-of-machine-learning-in-r.html","id":"conclusion","chapter":"14 Introduction of machine learning in R","heading":"14.7 Conclusion","text":"tutorial, can grasp basic understanding general procedures machine learning model training. First , start train model, preprocess data, significantly improve efficiency model training. numerical features, can use standardization centering adjust scale, prevents data distortions. categorical features, may use one-hot encoding convert categorical features numerical ones. , reduce dimension dataset, can use PCA transform data simplified form. Furthermore, second step EDA, gives audiences insight overall patterns data going train. part can easily done using R R language suitable data visualization data analysis. fourth step, start train machine learning model. various types machine learning model choose: KNN, Random Forest, SVM, Gradient Boost, Naive Bayes, etc. one choose, depends actual dataset user’s experience. last step, order assess performance model, need use several metrics. regression, can use R-squared Adjusted R-squared; classification, can use confusion matrix ROC curve. general, tutorial introduction machine learning, many complicated algorithms data processing procedures, leaving space users explore.","code":""},{"path":"introduction-of-machine-learning-in-r.html","id":"sources-1","chapter":"14 Introduction of machine learning in R","heading":"14.8 Sources","text":"https://www.rdocumentation.org/packages/caret/versions/6.0-92https://scikit-learn.org/stable/https://dhirajkumarblog.medium.com/top-4-advantages--disadvantages--support-vector-machine--svm-a3c06a2b107","code":""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"quantmod-tidyquant-tutorials-and-comparison","chapter":"15 Quantmod & Tidyquant Tutorials and Comparison","heading":"15 Quantmod & Tidyquant Tutorials and Comparison","text":"Mildred Ouyang Peishan Lyu","code":"\n#install.packages(“quantmod”) \n#install.packages(\"tidyverse\")\n#install.packages(\"tidyquant\")\nlibrary(\"quantmod\")\nlibrary(\"tidyverse\")\nlibrary(\"tidyquant\")"},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"motivation-1","chapter":"15 Quantmod & Tidyquant Tutorials and Comparison","heading":"15.1 Motivation:","text":"Quantmod tutorials documentations found provide quick starter guide beginners R people new using Quantmod. goal tutorial Quantmod teach starters use essential exploratory data analysis tools commonly used functions Quantmod. also hope tutorial can serve bridge users explore advanced features Quantmod future.feel tutorial nice job telling users tasks can completed cores functions Quantmod Tidyquant. make improvements, might create additional cheatsheet illustrate required arguments function users can conveniently make flexible advanced adjustments based needs.","code":""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"quantmod","chapter":"15 Quantmod & Tidyquant Tutorials and Comparison","heading":"15.2 Quantmod","text":"","code":""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"getting-data","chapter":"15 Quantmod & Tidyquant Tutorials and Comparison","heading":"15.2.1 Getting Data:","text":"function used load data : getSymbols(). return object stores data.specifying source (src=“source_name”) getSymbols(), Quantmod use default source Yahoo Finance. common data sources download data :Yahoo, Federal Reserve Economic Data (FRED), local database source using MySQL, csv files, .(Note: Google Finance longer data source. stopped providing data March, 2018.)getting data local database using MySQL, username password access database can stored using wrapper function: setDefaults(getSymbols.MySQL, user=‘____’, password=‘____’, dbname=‘_____’). setting , user can get data using getSymbols() change src=‘MySQL’.Data range can specified passing range start end dates, end date optional. end date, latest available data shown.Example:","code":"\ngetSymbols(\"META\", src=\"yahoo\", from=\"2022-01-01\", to=\"2022-6-30\")## [1] \"META\"\ngetSymbols(\"TSLA;AAPL;UBER\", src=\"yahoo\", from=\"2022-01-01\", to=\"2022-6-30\")## [1] \"TSLA\" \"AAPL\" \"UBER\""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"data-visualization","chapter":"15 Quantmod & Tidyquant Tutorials and Comparison","heading":"15.2.2 Data Visualization:","text":"three primary chart types Quantmod: bar chart, candle chart, line chart.\nPrimary function create charts: chartSeries() - default, open-high-low-close chart volume data shown.Wrapper functions: barChart(), candleChart(), lineChart()Modify original chart: reChart() - can dynamically change chart specifying changing argument(s). can used can log-scale y-axis, subset data show specific time period, set ticks, range y-axis, chart title, colors, .Examples:shows open-high-low-close chart volume data. orange color signifies closing price lower opening price day. green color signifies opposite.Users can also add stock indicators chart analysis. 26 indicators available Quantmod. commonly used stock indicators : Bollinger Bands - addBBands(), Moving Average Convergence Divergence - addMACD(), Commodity Channel Index - addCCI(), Volume - addVo(), Williams %R - addWPR(), Simple Moving Average - addSMA(), Rate Change - addROC(), Momentum - addMomentum(), Parabolic Stop Reverse - addSAR(), .Example:\nexample adds Moving Average Convergence Divergence (MACD) indicator original graph. method output two graphs, one original one MACD. Later, introduce way output one graph. MACD following arguments: fast, slow, signal, type, histogram, col. fast slow address length fast slow periods. signal addresses length signal period. type indicates type moving average use. histogram takes boolean values either output histogram. Lastly, col optional. changes color lines. second graph drawn default values MACD (fast = 12, slow = 26, signal = 9, type = “EMA”, histogram = TRUE).indicator can also passed directly argument chartSeries function. way, one graph drawn.Example:\nchart shows Bollinger Bands drawn default argument values. default sets moving average period (n) 20, standard deviation (sd) 2, moving average type (maType) simple moving average (can also changed weighted moving avarage ), also indicator draw (draw) ‘bands’ (can also changed percent width).chart shows moving average period 20 days.chart shows moving average period 40 days.Multiple indicators can passed together reflect graph.\ngraph shows Bollinger Bands Moving Average Convergence Divergence indicator (default argument values).line chart plots opening data stock.bar chart plots highest, lowest, opening(right horizontal line), closing (left horizontal line) prices stock.want show highest, lowest, closing price one day, user can following:candle chart graphs OHLC data.Customization chart’s color can done passing arguments multi.col theme.multi.col - changes color bars\ntheme - changes color backgroundExamples:Moreover, Quantmod also allows graphing portion data. subset argument can used select specific range data graph.Example:\ngraph plots first two months data.Subset can also take value like “first 3 months” “last 6 weeks”.Furthermore, Qauntmod allows modifications original graph without restating original arguments .Example:","code":"\nchartSeries(META)\nchartSeries(META)\naddMACD()\nchartSeries(META, TA = \"addBBands(n=20, sd=2, maType = 'SMA', draw = 'bands')\")\nchartSeries(META, TA = \"addSMA(n=20)\")\nchartSeries(META, TA = \"addSMA(n=40)\")\nchartSeries(META, TA = \"addBBands();addMACD()\")\nlineChart(META)\nbarChart(META)\nbarChart(META, bar.type='hlc')\ncandleChart(META)\nchartSeries(META, multi.col = TRUE)\nchartSeries(META, theme = \"white\")\nchartSeries(META, multi.col = TRUE, theme = \"white\", subset = \"2022-1::2022-2\")\nchartSeries(META, subset = \"last 6 weeks\")\nchartSeries(META, multi.col = TRUE)\nreChart(major.ticks = \"months\") # change the tick mark to months"},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"tidyquant","chapter":"15 Quantmod & Tidyquant Tutorials and Comparison","heading":"15.3 Tidyquant","text":"Tidyquant integrates quantmod, xts, zoo, TTR, PerformanceAnalytics packages, can use generate tidier graphs using Quantmod . general, can use Tidyquant compare stock prices, evaluate stock performance, evaluate portfolio performance. can easily perform financial analysis using core tidyquant functions get stock indexes/exchange, get quantitative data various web-sources, transmute mutate quantitative data, analyze performance assets portfolios.major functions introduced originally adapted documentation:https://cran.r-project.org/web/packages/tidyquant/contains Vignettes introducing core functions charting Tidyquant.feel original documentation core functions tidy useful, authors derive different datasets using different tools, makes little hard compare similarities differences among tools deriving data. attempted use different tools achieve data four companies included details new tips. tutorial provides basic ideas get data, clean data, chart Tidyquant.","code":""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"before-getting-data","chapter":"15 Quantmod & Tidyquant Tutorials and Comparison","heading":"15.3.1 Before Getting Data","text":"getting quantitative data, want check list stock index possibly retrieve. eighteen available (5 shown ). measure performance assets different perspectives.three stock exchanges (exhange securities happen) available.browsing specific data sources accessible tq_get, can get daily stock data Yahoo Finance, economic data FRED Quandl, well financial data Quandl, Tiingo, Alpha Vantage, Bloomberg’s Financial API (though paid account required Bloomberg).“stock.prices” - Yahoo Finance“stock.prices” - Yahoo Finance“economic.data” - FRED“economic.data” - FRED“quandl” “quandl.datatable” - Nasdaq API“quandl” “quandl.datatable” - Nasdaq API“tiingo”, “tiingo.iex”, “tiingo.crypto” - Tiingo API“tiingo”, “tiingo.iex”, “tiingo.crypto” - Tiingo API“alphavantager”, “alphavantage” - Alpha Vantage API“alphavantager”, “alphavantage” - Alpha Vantage API“rblpapi” - Bloomberg“rblpapi” - Bloomberg","code":"\ntq_index_options()## [1] \"DOW\"       \"DOWGLOBAL\" \"SP400\"     \"SP500\"     \"SP600\"\ntq_exchange_options()## [1] \"AMEX\"   \"NASDAQ\" \"NYSE\"\ntq_get_options()##  [1] \"stock.prices\"       \"stock.prices.japan\" \"dividends\"         \n##  [4] \"splits\"             \"economic.data\"      \"quandl\"            \n##  [7] \"quandl.datatable\"   \"tiingo\"             \"tiingo.iex\"        \n## [10] \"tiingo.crypto\"      \"alphavantager\"      \"alphavantage\"      \n## [13] \"rblpapi\""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"getting-data-1","chapter":"15 Quantmod & Tidyquant Tutorials and Comparison","heading":"15.3.2 Getting Data","text":"Example calling tq_index(“INDEXNAME”) functionSP500 provides dataset 8 columns capitalization-weighted index companies higher market cap receives higher weighting index.Examples calling tq_get() function(1). Getting data Yahoo!Finance - set tq_get(…get = “stock.prices”…)want get stock prices companies, Yahoo!Finance great choice.Assume want stock prices Apple, Meta, Tesla, Uber:(2). Getting data FRED Economic data - tq_get() function - set tq_get(…get = “economic.data”…)considering want retrieve data FRED, consider covers major areas macroeconoc analysis, including major indicators:Growth: GDP, real GDP, real potential GDPGrowth: GDP, real GDP, real potential GDPPrices inflation: CPI urban consumers items/items less food & energy, GDP: implicit price deflaterPrices inflation: CPI urban consumers items/items less food & energy, GDP: implicit price deflaterMoney Supply: St.Louise adjusted monetary, M1 money stock, M2 money stock, velocity M1 money stock, velocity M2 money stockMoney Supply: St.Louise adjusted monetary, M1 money stock, M2 money stock, velocity M1 money stock, velocity M2 money stockInterest rates: effective federal funds rate, 3-month treasury bill, 5/10/30 year treasury constant maturity rate, 5/10 year breakeven inflation rate, 5 year forward inflation expectation rate, TED Spread, bank prime loan rateInterest rates: effective federal funds rate, 3-month treasury bill, 5/10/30 year treasury constant maturity rate, 5/10 year breakeven inflation rate, 5 year forward inflation expectation rate, TED Spread, bank prime loan rateEmployment: Civilian Unemployment Rate, Natural Long-Term/Short-Term Rate Unemployment, Civilian Labor Force Participation Rate, Civilian Employment-Population Ratio, Unemployed, Employees: Total nonfarm, Employees: Manufacturing, Initial Claims, 4-Week Moving Average Initial ClaimsEmployment: Civilian Unemployment Rate, Natural Long-Term/Short-Term Rate Unemployment, Civilian Labor Force Participation Rate, Civilian Employment-Population Ratio, Unemployed, Employees: Total nonfarm, Employees: Manufacturing, Initial Claims, 4-Week Moving Average Initial ClaimsIncome expenditure: Real Median Household Income United States, Real Disposable Personal Income, Personal Consumption Expenditures, Personal Consumption Expenditures: Durable Goods, Personal Saving Rate, Real Retail Food Services Sales, Disposable personal income.Income expenditure: Real Median Household Income United States, Real Disposable Personal Income, Personal Consumption Expenditures, Personal Consumption Expenditures: Durable Goods, Personal Saving Rate, Real Retail Food Services Sales, Disposable personal income.economic indicators: Industrial Production Index, Capacity Utilization: Total Industry, Housing Starts: Total: New Privately Owned Housing Units Started, Gross Private Domestic Investment, Corporate Profits Tax (without IVA CCAdj), St. Louis Fed Financial Stress Index, Crude Oil Prices: West Texas Intermediate (WTI) - Cushing, Oklahoma, Leading Index United States, Trade Weighted U.S. Dollar Index: Major Currencies, Trade Weighted U.S. Dollar Index: Broad.economic indicators: Industrial Production Index, Capacity Utilization: Total Industry, Housing Starts: Total: New Privately Owned Housing Units Started, Gross Private Domestic Investment, Corporate Profits Tax (without IVA CCAdj), St. Louis Fed Financial Stress Index, Crude Oil Prices: West Texas Intermediate (WTI) - Cushing, Oklahoma, Leading Index United States, Trade Weighted U.S. Dollar Index: Major Currencies, Trade Weighted U.S. Dollar Index: Broad.Debt: Federal Debt: Total Public Debt, Federal Debt: Total Public Debt Percent Gross Domestic Product, Excess Reserves Depository Institutions, Commercial Industrial Loans, Commercial BanksDebt: Federal Debt: Total Public Debt, Federal Debt: Total Public Debt Percent Gross Domestic Product, Excess Reserves Depository Institutions, Commercial Industrial Loans, Commercial Banks(code indicators can accessed website:\nhttps://data.nasdaq.com/data/FRED-federal-reserve-economic-data/documentation)Assume want inspect GDP within given tiem window, found period data available.(3). Getting data Nasdaq Data Link (Quandl) API - set tq_get(…get = “quandl”…)quandl_search(… query = “KEY DATASET”…)\nuseful deciding dataset want use. can get info newest oldest available date well frequency data. want look datasets “GDP” part name, set query = “GDP”.\ncan also set database_code = “CODENAME” already know code dataset. can also set number returns per page.Datasets available : https://data.nasdaq.com/searchtq_get(…get = “quandl”…) - get Quandl time series free data using API key.code can run successfully users uncomment code insert api key “my_api_key” argument.Types free datasets Quandl:Wiki Continuous Futures, curated Quandl community built top raw data ICE, CME, LIFFE, etc.Wiki Continuous Futures, curated Quandl community built top raw data ICE, CME, LIFFE, etc.Zillow Real Estate Data, provides real estate rental marketplace information.Zillow Real Estate Data, provides real estate rental marketplace information.FRED Economic Data, including indicators macroeconomic analysis mentioned section.\nprovides additional info dividends split ratio well adjusted measures Yahoo!Finance, data available Meta Uber, apple tesla, can get 4 years call. new data available 2018-03-27.FRED Economic Data, including indicators macroeconomic analysis mentioned section.\nprovides additional info dividends split ratio well adjusted measures Yahoo!Finance, data available Meta Uber, apple tesla, can get 4 years call. new data available 2018-03-27.tq_get(…get = “quandl.datatable”, datatable_code = “CODENAME”…) get larger datasets time series, note argument “datatable_code” required filled getting data.(4). Getting data Tiingo API - tq_get() - set tq_get(…get = “tiingo”/“tiingo.iex”…)\nfirst step get tiingo api key.kind combined benefits Yahoo!Finance Quandl API way info adjusted measures data available four companies desired time window single call.can continue look data hour within specific day/multiple days.(5). Getting data Alpha Vantage - set tq_get(…get = “alphavantage”…)Also, first step get tiingo api key.Like former tools, can get daily stock prices adjusted info. downside allows setting intervals instead “” date.Like using Tiingo api, can also easily inspect data hour setting interval, also setting start end time concern.(6). BloombergBloomberg charges, might best choice beginners. still want use , steps take:create Bloomberg Terminal account.create Bloomberg Terminal account.run blpConnect()run blpConnect()set tq_get(…get = “Rblpapi”…)set tq_get(…get = “Rblpapi”…)details found original Tidyquant documentation.","code":"\ntq_index(\"SP500\")## # A tibble: 503 × 8\n##    symbol company                    ident…¹ sedol weight sector share…² local…³\n##    <chr>  <chr>                      <chr>   <chr>  <dbl> <chr>    <dbl> <chr>  \n##  1 AAPL   Apple Inc.                 037833… 2046… 0.0667 Infor…  1.69e8 USD    \n##  2 MSFT   Microsoft Corporation      594918… 2588… 0.0545 Infor…  8.33e7 USD    \n##  3 AMZN   Amazon.com Inc.            023135… 2000… 0.0258 Consu…  9.90e7 USD    \n##  4 GOOGL  Alphabet Inc. Class A      02079K… BYVY… 0.0169 Commu…  6.70e7 USD    \n##  5 BRK-B  Berkshire Hathaway Inc. C… 084670… 2073… 0.0165 Finan…  2.02e7 USD    \n##  6 UNH    UnitedHealth Group Incorp… 91324P… 2917… 0.0153 Healt…  1.05e7 USD    \n##  7 TSLA   Tesla Inc                  88160R… B616… 0.0153 Consu…  2.98e7 USD    \n##  8 GOOG   Alphabet Inc. Class C      02079K… BYY8… 0.0152 Commu…  5.99e7 USD    \n##  9 XOM    Exxon Mobil Corporation    30231G… 2326… 0.0139 Energy  4.66e7 USD    \n## 10 JNJ    Johnson & Johnson          478160… 2475… 0.0138 Healt…  2.94e7 USD    \n## # … with 493 more rows, and abbreviated variable names ¹​identifier,\n## #   ²​shares_held, ³​local_currency\naapl_price_yahoo  <- tq_get(\"AAPL\", get = \"stock.prices\", from = \"2022-01-01\", to = \"2022-06-30\")\naapl_price_yahoo## # A tibble: 123 × 8\n##    symbol date        open  high   low close    volume adjusted\n##    <chr>  <date>     <dbl> <dbl> <dbl> <dbl>     <dbl>    <dbl>\n##  1 AAPL   2022-01-03  178.  183.  178.  182. 104487900     181.\n##  2 AAPL   2022-01-04  183.  183.  179.  180.  99310400     179.\n##  3 AAPL   2022-01-05  180.  180.  175.  175.  94537600     174.\n##  4 AAPL   2022-01-06  173.  175.  172.  172   96904000     171.\n##  5 AAPL   2022-01-07  173.  174.  171.  172.  86709100     171.\n##  6 AAPL   2022-01-10  169.  172.  168.  172. 106765600     171.\n##  7 AAPL   2022-01-11  172.  175.  171.  175.  76138300     174.\n##  8 AAPL   2022-01-12  176.  177.  175.  176.  74805200     175.\n##  9 AAPL   2022-01-13  176.  177.  172.  172.  84505800     171.\n## 10 AAPL   2022-01-14  171.  174.  171.  173.  80440800     172.\n## # … with 113 more rows\nmeta_price_yahoo  <- tq_get(\"META\", get = \"stock.prices\", from = \"2022-01-01\", to = \"2022-06-30\")\nmeta_price_yahoo ## # A tibble: 123 × 8\n##    symbol date        open  high   low close   volume adjusted\n##    <chr>  <date>     <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n##  1 META   2022-01-03  338.  341.  337.  339. 14537900     339.\n##  2 META   2022-01-04  340.  343.  332.  337. 15998000     337.\n##  3 META   2022-01-05  333.  336.  324.  324. 20564500     324.\n##  4 META   2022-01-06  323.  339.  323.  332. 27962800     332.\n##  5 META   2022-01-07  333.  337   329.  332. 14722000     332.\n##  6 META   2022-01-10  325.  328.  315.  328. 24942400     328.\n##  7 META   2022-01-11  327.  335.  325.  334. 16226800     334.\n##  8 META   2022-01-12  335.  336.  330.  333. 14104900     333.\n##  9 META   2022-01-13  335.  336.  326.  326. 14797100     326.\n## 10 META   2022-01-14  322.  333.  321.  332. 16868500     332.\n## # … with 113 more rows\ntsla_price_yahoo  <- tq_get(\"TSLA\", get = \"stock.prices\", from = \"2022-01-01\", to = \"2022-06-30\")\ntsla_price_yahoo## # A tibble: 123 × 8\n##    symbol date        open  high   low close    volume adjusted\n##    <chr>  <date>     <dbl> <dbl> <dbl> <dbl>     <dbl>    <dbl>\n##  1 TSLA   2022-01-03  383.  400.  379.  400. 103931400     400.\n##  2 TSLA   2022-01-04  397.  403.  374.  383. 100248300     383.\n##  3 TSLA   2022-01-05  382.  390.  360.  363.  80119800     363.\n##  4 TSLA   2022-01-06  359   363.  340.  355.  90336600     355.\n##  5 TSLA   2022-01-07  360.  360.  337.  342.  84164700     342.\n##  6 TSLA   2022-01-10  333.  353.  327.  353.  91815000     353.\n##  7 TSLA   2022-01-11  351.  359.  346.  355.  66063300     355.\n##  8 TSLA   2022-01-12  360.  372.  358.  369.  83739000     369.\n##  9 TSLA   2022-01-13  370.  372.  342.  344.  97209900     344.\n## 10 TSLA   2022-01-14  340.  351.  338.  350.  72924300     350.\n## # … with 113 more rows\nuber_price_yahoo  <- tq_get(\"UBER\", get = \"stock.prices\", from = \"2022-01-01\", to = \"2022-06-30\")\nuber_price_yahoo## # A tibble: 123 × 8\n##    symbol date        open  high   low close   volume adjusted\n##    <chr>  <date>     <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n##  1 UBER   2022-01-03  42.5  44.4  41.9  44.0 26089000     44.0\n##  2 UBER   2022-01-04  44.2  44.8  42.6  44.4 30845300     44.4\n##  3 UBER   2022-01-05  44.3  45.9  42.9  43.2 28498700     43.2\n##  4 UBER   2022-01-06  43.1  44.1  41.0  42.0 32434300     42.0\n##  5 UBER   2022-01-07  42    42.7  41.2  41.5 24875800     41.5\n##  6 UBER   2022-01-10  41.5  42.8  40.2  42.6 29783800     42.6\n##  7 UBER   2022-01-11  42.4  44.2  42.2  43.6 22161000     43.6\n##  8 UBER   2022-01-12  44.0  44.1  42.5  43.0 18993900     43.0\n##  9 UBER   2022-01-13  43.3  43.9  42.7  42.9 17190100     42.9\n## 10 UBER   2022-01-14  42.4  42.7  40.4  41.5 25817800     41.5\n## # … with 113 more rows\ngdp_fred <- tq_get(\"GDP\", get = \"economic.data\", from = \"2010-01-01\", to = \"2022-01-01\")\ngdp_fred ## # A tibble: 49 × 3\n##    symbol date        price\n##    <chr>  <date>      <dbl>\n##  1 GDP    2010-01-01 14765.\n##  2 GDP    2010-04-01 14980.\n##  3 GDP    2010-07-01 15142.\n##  4 GDP    2010-10-01 15309.\n##  5 GDP    2011-01-01 15351.\n##  6 GDP    2011-04-01 15558.\n##  7 GDP    2011-07-01 15648.\n##  8 GDP    2011-10-01 15842.\n##  9 GDP    2012-01-01 16069.\n## 10 GDP    2012-04-01 16207.\n## # … with 39 more rows\nquandl_search(query = \"GDP\", page = 1)## Gross Domestic Product\n## Code: FRED/GDP\n## Desc: Units: Billions of Dollars\n## Seasonal Adjustment: Seasonally Adjusted Annual Rate\n## Notes: A Guide to the National Income and Product Accounts of the United States (NIPA) - (http://www.bea.gov/national/pdf/nipaguid.pdf)\n## Freq: quarterly\n## Cols: Date | Value\n## \n## (GDPS) Adjusted Stock Prices\n## Code: OTCB/GDPS\n## Desc:  <b>Ticker<\/b>: GDPS <br> <br> <b>Exchange<\/b>: OTCB <br> <br> Columns: <br> <br> Open,High,Low,Close,Volume are adjusted and shown in USD currency. <br> <br> Adjustment Factor shows the factor by which prices are adjusted on days which adjustments take place <br> <br> Adjustment Type is a number representing the type of adjustment. Refer to documentation for more information on these codes.\n## Freq: daily\n## Cols: Date | Open | High | Low | Close | Volume | Adjustment Factor | Adjustment Type\n## \n## Goldplat Plc (GDP) Adjusted Stock Prices\n## Code: XLON/GDP\n## Desc:  <b>Ticker<\/b>: GDP <br> <br> <b>Exchange<\/b>: XLON <br> <br> Columns: <br> <br> Open,High,Low,Close,Volume are adjusted and shown in GBX currency. <br> <br> Adjustment Factor shows the factor by which prices are adjusted on days which adjustments take place <br> <br> Adjustment Type is a number representing the type of adjustment. Refer to documentation for more information on these codes.\n## Freq: daily\n## Cols: Date | Open | High | Low | Close | Volume | Adjustment Factor | Adjustment Type\n## \n## GDP Volatility & Option Implied Surface\n## Code: OPT/GDP\n## Desc: <p><p>Implied volatility surface for GDP.<\/p><p>For more information please view <a href='https://www.quandl.com/data/OPT/documentation'>OPT Documentation<\/a>.<\/p>\n## Freq: daily\n## Cols: date | stockpx | iv30 | iv60 | iv90 | m1atmiv | m1dtex | m2atmiv | m2dtex | m3atmiv | m3dtex | m4atmiv | m4dtex | slope | deriv | slope_inf | deriv_inf | 10dclsHV | 20dclsHV | 60dclsHV | 120dclsHV | 252dclsHV | 10dORHV | 20dORHV | 60dORHV | 120dORHV | 252dORHV\n## \n## Goodrich Petroleum Corp. (GDP) Adjusted Stock Prices\n## Code: XNAS/GDP\n## Desc:  <b>Ticker<\/b>: GDP <br> <br> <b>Exchange<\/b>: XNAS <br> <br> Columns: <br> <br> Open,High,Low,Close,Volume are adjusted and shown in USD currency. <br> <br> Adjustment Factor shows the factor by which prices are adjusted on days which adjustments take place <br> <br> Adjustment Type is a number representing the type of adjustment. Refer to documentation for more information on these codes.\n## Freq: daily\n## Cols: Date | Open | High | Low | Close | Volume | Adjustment Factor | Adjustment Type\n## \n## Goodrich Petroleum Corp. (GDP) Adjusted Stock Prices\n## Code: XNYS/GDP\n## Desc:  <b>Ticker<\/b>: GDP <br> <br> <b>Exchange<\/b>: XNYS <br> <br> Columns: <br> <br> Open,High,Low,Close,Volume are adjusted and shown in USD currency. <br> <br> Adjustment Factor shows the factor by which prices are adjusted on days which adjustments take place <br> <br> Adjustment Type is a number representing the type of adjustment. Refer to documentation for more information on these codes.\n## Freq: daily\n## Cols: Date | Open | High | Low | Close | Volume | Adjustment Factor | Adjustment Type\n## \n## Goodrich Petroleum Corp. (GDP) Adjusted Stock Prices\n## Code: XASE/GDP\n## Desc:  <b>Ticker<\/b>: GDP <br> <br> <b>Exchange<\/b>: XASE <br> <br> Columns: <br> <br> Open,High,Low,Close,Volume are adjusted and shown in USD currency. <br> <br> Adjustment Factor shows the factor by which prices are adjusted on days which adjustments take place <br> <br> Adjustment Type is a number representing the type of adjustment. Refer to documentation for more information on these codes.\n## Freq: daily\n## Cols: Date | Open | High | Low | Close | Volume | Adjustment Factor | Adjustment Type\n## \n## Goodrich Petroleum Corporation (GDP) Market Betas, Correlations, and Risks\n## Code: QRM/GDP\n## Desc: Market Betas, Correlations, and Systematic and Unsystematic Risks for Goodrich Petroleum Corporation (GDP). All time periods are measured in calendar days. See documentation for methodology.\n## Freq: daily\n## Cols: Date | Beta30 | Cor30 | Srisk30 | Urisk30 | Beta60 | Cor60 | Srisk60 | Urisk60 | Beta90 | Cor90 | Srisk90 | Urisk90 | Beta360 | Cor360 | Srisk360 | Urisk360\n## \n## Golden Pursuit Resources Ltd. (GDP) Adjusted Stock Prices\n## Code: XTSX/GDP\n## Desc:  <b>Ticker<\/b>: GDP <br> <br> <b>Exchange<\/b>: XTSX <br> <br> Columns: <br> <br> Open,High,Low,Close,Volume are adjusted and shown in CAD currency. <br> <br> Adjustment Factor shows the factor by which prices are adjusted on days which adjustments take place <br> <br> Adjustment Type is a number representing the type of adjustment. Refer to documentation for more information on these codes.\n## Freq: daily\n## Cols: Date | Open | High | Low | Close | Volume | Adjustment Factor | Adjustment Type\n## \n## Daily Active Analyst Ratings for GDP — Goodrich Petroleum Corp.\n## Code: CBARH/GDP\n## Desc: <p>Daily active analyst ratings for GDP — Goodrich Petroleum Corp.<\/p>\n## Freq: daily\n## Cols: Date | Total | Average Rating | Rating Count Strong Sell | Rating Count Moderate Sell | Rating Count Hold | Rating Count Moderate Buy | Rating Count Strong Buy | Action Count Initiated | Action Count Upgraded | Action Count Downgraded | Action Count Reiterated | Action Ratio Upgraded | Action Ratio Downgraded## # A tibble: 10 × 13\n##         id datas…¹ datab…² name  descr…³ refre…⁴ newes…⁵ oldes…⁶ colum…⁷ frequ…⁸\n##      <int> <chr>   <chr>   <chr> <chr>   <chr>   <chr>   <chr>   <list>  <chr>  \n##  1  1.20e5 GDP     FRED    Gros… \"Units… 2022-0… 2021-1… 1947-0… <chr>   quarte…\n##  2  3.79e7 GDPS    OTCB    (GDP… \" <b>T… 2017-0… 2006-1… 2006-1… <chr>   daily  \n##  3  3.78e7 GDP     XLON    Gold… \" <b>T… 2022-1… 2022-1… 2007-0… <chr>   daily  \n##  4  2.35e7 GDP     OPT     GDP … \"<p><p… 2021-1… 2021-1… 2010-0… <chr>   daily  \n##  5  3.79e7 GDP     XNAS    Good… \" <b>T… 2022-0… 2021-1… 2017-0… <chr>   daily  \n##  6  4.35e7 GDP     XNYS    Good… \" <b>T… 2022-0… 2021-1… 2018-0… <chr>   daily  \n##  7  3.76e7 GDP     XASE    Good… \" <b>T… 2022-0… 2021-1… 2017-0… <chr>   daily  \n##  8  3.39e7 GDP     QRM     Good… \"Marke… 2022-0… 2021-1… 2006-0… <chr>   daily  \n##  9  3.78e7 GDP     XTSX    Gold… \" <b>T… 2022-1… 2022-1… 2006-0… <chr>   daily  \n## 10  2.60e7 GDP     CBARH   Dail… \"<p>Da… 2021-0… 2021-0… 2012-0… <chr>   daily  \n## # … with 3 more variables: type <chr>, premium <lgl>, database_id <int>, and\n## #   abbreviated variable names ¹​dataset_code, ²​database_code, ³​description,\n## #   ⁴​refreshed_at, ⁵​newest_available_date, ⁶​oldest_available_date,\n## #   ⁷​column_names, ⁸​frequency\n#my_quandl_api <- quandl_api_key(\"my_api_key\")\n#tq_get(\"WIKI/META\", get = \"quandl\")\n#tq_get(\"WIKI/AAPL\", get = \"quandl\", from = \"2017-01-01\", to = \"2020-12-31\")\n#tq_get(\"WIKI/TSLA\", get = \"quandl\", from = \"2017-01-01\", to = \"2020-12-31\")\n#tq_get(\"WIKI/UBER\", get = \"quandl\")\n#my_tiingo_api <- tiingo_api_key(\"my_api_key\")\n#tq_get(c(\"AAPL\", \"META\",\"TSLA\",\"UBER\"), get = \"tiingo\", from = \"2022-01-01\", to = \"2022-06-30\")\n#tq_get(c(\"AAPL\", \"META\",\"TSLA\",\"UBER\"), get = \"tiingo.iex\", from = \"2022-11-01\", to = \"2022-11-01\", resample_frequency = \"60min\")\n#my_vantage_key <- av_api_key(\"my_api_key\")\n#c(\"AAPL\",\"META\",\"TSLA\", \"UBER\") %>%\n    #tq_get(get = \"alphavantage\", av_fun = \"TIME_SERIES_DAILY_ADJUSTED\", interval = \"daily\")\n#c(\"AAPL\",\"META\",\"TSLA\", \"UBER\") %>%\n    #tq_get(get = \"alphavantage\", av_fun = \"TIME_SERIES_INTRADAY\", interval = \"60min\")"},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"data-handling","chapter":"15 Quantmod & Tidyquant Tutorials and Comparison","heading":"15.3.3 Data Handling","text":"TransmuteWe typically transmute want change periodicity data, tq_transmute() return new data frame new periodicity.transmuting, might explore compatible functions set tq_transmute(…mutate_fun = “CODEFROMPACKAGES”…). CODEFROMPACKAGES returned call .convenience, work data retrieved Meta Yahoo!Finance example.\ntransmute daily stock prices Meta weekly data.Tesla data converted regression next steps.MutateWe mutate weekly return data original dataset show tq_mutate() works.\ntq_mutate(mutate_fun = periodReturn, period = “weekly”) gives weekly return.might also want show mutate info computations across columns original dataset. original documentation takes rollapply zoo package example. Rollapply enables applying custom function across rolling window. may follow documentation use compute rolling regression. adapt code original documentation run rolling regression Meta Tesla dataset.prepare showing mutate rolling regressions returns Meta Tesla, mutate weekly returns Tesla original Tesla dataset Yahoo!Finance well., prepare running rolling regressions, select weekly returns columns dataset join date shown .joined_returns dataset passed regr_fun xts object.\ntimetk::tk_tbl function converts data dataframe.Notice make computations within tq_mutate() function. new dataframe created coefficients regressions attached.Also, mutate_fun may require two different inputs. case, want use tq_mutate_xy() instead tq_mutate() . example, want mutate indicator original dataset calculated two columns data original dataset, want set mutate_fun = CODENAME new indicator, input name two columns x y. Example shown original documentation.","code":"\ntq_transmute_fun_options()## $zoo\n##  [1] \"rollapply\"          \"rollapplyr\"         \"rollmax\"           \n##  [4] \"rollmax.default\"    \"rollmaxr\"           \"rollmean\"          \n##  [7] \"rollmean.default\"   \"rollmeanr\"          \"rollmedian\"        \n## [10] \"rollmedian.default\" \"rollmedianr\"        \"rollsum\"           \n## [13] \"rollsum.default\"    \"rollsumr\"          \n## \n## $xts\n##  [1] \"apply.daily\"     \"apply.monthly\"   \"apply.quarterly\" \"apply.weekly\"   \n##  [5] \"apply.yearly\"    \"diff.xts\"        \"lag.xts\"         \"period.apply\"   \n##  [9] \"period.max\"      \"period.min\"      \"period.prod\"     \"period.sum\"     \n## [13] \"periodicity\"     \"to_period\"       \"to.daily\"        \"to.hourly\"      \n## [17] \"to.minutes\"      \"to.minutes10\"    \"to.minutes15\"    \"to.minutes3\"    \n## [21] \"to.minutes30\"    \"to.minutes5\"     \"to.monthly\"      \"to.period\"      \n## [25] \"to.quarterly\"    \"to.weekly\"       \"to.yearly\"      \n## \n## $quantmod\n##  [1] \"allReturns\"      \"annualReturn\"    \"ClCl\"            \"dailyReturn\"    \n##  [5] \"Delt\"            \"HiCl\"            \"Lag\"             \"LoCl\"           \n##  [9] \"LoHi\"            \"monthlyReturn\"   \"Next\"            \"OpCl\"           \n## [13] \"OpHi\"            \"OpLo\"            \"OpOp\"            \"periodReturn\"   \n## [17] \"quarterlyReturn\" \"seriesAccel\"     \"seriesDecel\"     \"seriesDecr\"     \n## [21] \"seriesHi\"        \"seriesIncr\"      \"seriesLo\"        \"weeklyReturn\"   \n## [25] \"yearlyReturn\"   \n## \n## $TTR\n##  [1] \"adjRatios\"          \"ADX\"                \"ALMA\"              \n##  [4] \"aroon\"              \"ATR\"                \"BBands\"            \n##  [7] \"CCI\"                \"chaikinAD\"          \"chaikinVolatility\" \n## [10] \"CLV\"                \"CMF\"                \"CMO\"               \n## [13] \"CTI\"                \"DEMA\"               \"DonchianChannel\"   \n## [16] \"DPO\"                \"DVI\"                \"EMA\"               \n## [19] \"EMV\"                \"EVWMA\"              \"GMMA\"              \n## [22] \"growth\"             \"HMA\"                \"keltnerChannels\"   \n## [25] \"KST\"                \"lags\"               \"MACD\"              \n## [28] \"MFI\"                \"momentum\"           \"OBV\"               \n## [31] \"PBands\"             \"ROC\"                \"rollSFM\"           \n## [34] \"RSI\"                \"runCor\"             \"runCov\"            \n## [37] \"runMAD\"             \"runMax\"             \"runMean\"           \n## [40] \"runMedian\"          \"runMin\"             \"runPercentRank\"    \n## [43] \"runSD\"              \"runSum\"             \"runVar\"            \n## [46] \"SAR\"                \"SMA\"                \"SMI\"               \n## [49] \"SNR\"                \"stoch\"              \"TDI\"               \n## [52] \"TRIX\"               \"ultimateOscillator\" \"VHF\"               \n## [55] \"VMA\"                \"volatility\"         \"VWAP\"              \n## [58] \"VWMA\"               \"wilderSum\"          \"williamsAD\"        \n## [61] \"WMA\"                \"WPR\"                \"ZigZag\"            \n## [64] \"ZLEMA\"             \n## \n## $PerformanceAnalytics\n## [1] \"Return.annualized\"        \"Return.annualized.excess\"\n## [3] \"Return.clean\"             \"Return.cumulative\"       \n## [5] \"Return.excess\"            \"Return.Geltner\"          \n## [7] \"zerofill\"\nmeta_price_yahoo_weekly <- meta_price_yahoo %>%\n  # No need to group at this point, but it allows the \"META\" name to show. can be deleted. \n  group_by(symbol) %>%\n  # set indexAt allow the date to be the last day of each week. \n  tq_transmute(select = adjusted, mutate_fun = to.weekly, indexAt = \"lastof\")\nmeta_price_yahoo_weekly## # A tibble: 26 × 3\n## # Groups:   symbol [1]\n##    symbol date       adjusted\n##    <chr>  <date>        <dbl>\n##  1 META   2022-01-07     332.\n##  2 META   2022-01-14     332.\n##  3 META   2022-01-21     303.\n##  4 META   2022-01-28     302.\n##  5 META   2022-02-04     237.\n##  6 META   2022-02-11     220.\n##  7 META   2022-02-18     206.\n##  8 META   2022-02-25     210.\n##  9 META   2022-03-04     200.\n## 10 META   2022-03-11     188.\n## # … with 16 more rows\ntsla_price_yahoo_weekly <- tsla_price_yahoo %>%\n  # No need to group at this point, but it allows the \"TSLA\" name to show. can be deleted. \n  group_by(symbol) %>%\n  # set indexAt allow the date to be the last day of each week. \n  tq_transmute(select = adjusted, mutate_fun = to.weekly, indexAt = \"lastof\")\ntsla_price_yahoo_weekly## # A tibble: 26 × 3\n## # Groups:   symbol [1]\n##    symbol date       adjusted\n##    <chr>  <date>        <dbl>\n##  1 TSLA   2022-01-07     342.\n##  2 TSLA   2022-01-14     350.\n##  3 TSLA   2022-01-21     315.\n##  4 TSLA   2022-01-28     282.\n##  5 TSLA   2022-02-04     308.\n##  6 TSLA   2022-02-11     287.\n##  7 TSLA   2022-02-18     286.\n##  8 TSLA   2022-02-25     270.\n##  9 TSLA   2022-03-04     279.\n## 10 TSLA   2022-03-11     265.\n## # … with 16 more rows\nmeta_price_yahoo_weekly_returns <- meta_price_yahoo_weekly %>%\n    group_by(symbol) %>%\n    tq_mutate(mutate_fun = periodReturn, period = \"weekly\", type = \"log\")\nmeta_price_yahoo_weekly_returns## # A tibble: 26 × 4\n## # Groups:   symbol [1]\n##    symbol date       adjusted weekly.returns\n##    <chr>  <date>        <dbl>          <dbl>\n##  1 META   2022-01-07     332.       0       \n##  2 META   2022-01-14     332.       0.000331\n##  3 META   2022-01-21     303.      -0.0905  \n##  4 META   2022-01-28     302.      -0.00483 \n##  5 META   2022-02-04     237.      -0.241   \n##  6 META   2022-02-11     220.      -0.0769  \n##  7 META   2022-02-18     206.      -0.0629  \n##  8 META   2022-02-25     210.       0.0207  \n##  9 META   2022-03-04     200.      -0.0508  \n## 10 META   2022-03-11     188.      -0.0643  \n## # … with 16 more rows\ntsla_price_yahoo_weekly_returns <- tsla_price_yahoo_weekly %>%\n    group_by(symbol) %>%\n    tq_mutate( mutate_fun = periodReturn, period = \"weekly\", type = \"log\")\ntsla_price_yahoo_weekly_returns## # A tibble: 26 × 4\n## # Groups:   symbol [1]\n##    symbol date       adjusted weekly.returns\n##    <chr>  <date>        <dbl>          <dbl>\n##  1 TSLA   2022-01-07     342.        0      \n##  2 TSLA   2022-01-14     350.        0.0218 \n##  3 TSLA   2022-01-21     315.       -0.106  \n##  4 TSLA   2022-01-28     282.       -0.109  \n##  5 TSLA   2022-02-04     308.        0.0870 \n##  6 TSLA   2022-02-11     287.       -0.0710 \n##  7 TSLA   2022-02-18     286.       -0.00352\n##  8 TSLA   2022-02-25     270.       -0.0565 \n##  9 TSLA   2022-03-04     279.        0.0345 \n## 10 TSLA   2022-03-11     265.       -0.0526 \n## # … with 16 more rows\nmeta_price_yahoo_weekly_returns_only <- meta_price_yahoo_weekly_returns %>%\n  select(weekly.returns, date)\ntsla_price_yahoo_weekly_returns_only <- tsla_price_yahoo_weekly_returns %>%\n  select(weekly.returns, date)\n\njoined_returns <- left_join(meta_price_yahoo_weekly_returns_only, tsla_price_yahoo_weekly_returns_only, \n                            by =\"date\")\njoined_returns## # A tibble: 26 × 5\n##    symbol.x weekly.returns.x date       symbol.y weekly.returns.y\n##    <chr>               <dbl> <date>     <chr>               <dbl>\n##  1 META             0        2022-01-07 TSLA              0      \n##  2 META             0.000331 2022-01-14 TSLA              0.0218 \n##  3 META            -0.0905   2022-01-21 TSLA             -0.106  \n##  4 META            -0.00483  2022-01-28 TSLA             -0.109  \n##  5 META            -0.241    2022-02-04 TSLA              0.0870 \n##  6 META            -0.0769   2022-02-11 TSLA             -0.0710 \n##  7 META            -0.0629   2022-02-18 TSLA             -0.00352\n##  8 META             0.0207   2022-02-25 TSLA             -0.0565 \n##  9 META            -0.0508   2022-03-04 TSLA              0.0345 \n## 10 META            -0.0643   2022-03-11 TSLA             -0.0526 \n## # … with 16 more rows\nregr_fun <- function(data) {\n    coef(lm(weekly.returns.x ~ weekly.returns.y, data = timetk::tk_tbl(data, silent = TRUE)))\n}\njoined_returns %>%\n    tq_mutate(mutate_fun = rollapply,\n              # 2-week window. \n              width = 2,\n              FUN        = regr_fun,\n              # We need to specify by.column since we don't want the regression to run on each                 column in the dataset.\n              by.column  = FALSE)## # A tibble: 26 × 7\n##    symbol.x weekly.returns.x date       symbol.y weekly.retur…¹ X.Int…² weekly…³\n##    <chr>               <dbl> <date>     <chr>             <dbl>   <dbl>    <dbl>\n##  1 META             0        2022-01-07 TSLA            0       NA       NA     \n##  2 META             0.000331 2022-01-14 TSLA            0.0218   0        0.0152\n##  3 META            -0.0905   2022-01-21 TSLA           -0.106   -0.0152   0.710 \n##  4 META            -0.00483  2022-01-28 TSLA           -0.109   -3.19   -29.2   \n##  5 META            -0.241    2022-02-04 TSLA            0.0870  -0.136   -1.20  \n##  6 META            -0.0769   2022-02-11 TSLA           -0.0710  -0.151   -1.04  \n##  7 META            -0.0629   2022-02-18 TSLA           -0.00352 -0.0622   0.206 \n##  8 META             0.0207   2022-02-25 TSLA           -0.0565  -0.0685  -1.58  \n##  9 META            -0.0508   2022-03-04 TSLA            0.0345  -0.0237  -0.786 \n## 10 META            -0.0643   2022-03-11 TSLA           -0.0526  -0.0561   0.155 \n## # … with 16 more rows, and abbreviated variable names ¹​weekly.returns.y,\n## #   ²​X.Intercept., ³​weekly.returns.y..1"},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"charting-with-tidyquant","chapter":"15 Quantmod & Tidyquant Tutorials and Comparison","heading":"15.3.4 Charting with Tidyquant","text":"Line ChartPlotting opening price vs.time.Changing color theme, using first plot example.Additionally, scale_color_tq(theme = “green”/“dark”) scale_fill_tq(theme = “green”/“dark”) may used color fill specified aes().change themes applies types plots well.Bar ChartCandlestick ChartWe can modify candlestick chart bycolor, “color_up” “color_down” modifies color lines, fill_up fill_down modifies color rectangle fills.color, “color_up” “color_down” modifies color lines, fill_up fill_down modifies color rectangle fills.range graph, may use coord_x_date(xlim = …) zoom specific sections data.\nmay also set ylim = … zooming causes great change range y values.range graph, may use coord_x_date(xlim = …) zoom specific sections data.\nmay also set ylim = … zooming causes great change range y values.Preparing charting portion data. set range x.Reseting range y adjust plotting range x.Graphing different data different companiesInstead zooming specific sections using coord_x_date, run scale_x_date instead, removes --bounds data charting. trade distorting scale y-axis (removing little) getting moving average (removing much). may call filter() function remove appropriate number days find balance. Examples included original documentation.Visualizing Moving AveragesMoving averages help evaluate time-series trends, applied added layer chart geom_ma function. Different types moving averages available: Simple moving averages(SMA), exponential moving averages (EMA), weighted moving averages(WMA), double exponential moving averages (DEMA), zero-lag exponential moving averages (ZLEMA), volume-weighted moving averages (VWMA), elastic volume-weighted moving averages (EVWMA).adapted sample code original documentation. can set ma_fun argument equal types moving average want graph adjust appearance adjusting linetype, size, color, etc.charting moving average (SMA) - identify trend direction stock.\nGraph SMA 20/40 days:charting exponential moving average (EMA) - determine entry exit points trade.\nformula: closing price * multiplier + EMA previous day * (1-multiplier)\nmultiplier formula: [2/(number days observation+1)]charting weighted moving averages (WMA) - determine trend directions help see buy sell stockscharting double exponential moving averages (DEMA) - improved EMA, removes lag associated moving averages placing weights recent valuescharting zero-lag exponential moving averages (ZLEMA) - improved EMA, reduce lags removed inherent lag removing data lag days agocharting volume-weighted moving averages (VWMA) - weighting prices based amount trading activity within time windowelastic volume-weighted moving averages (EVWMA) - approximate average price paid per share. Large gaps price EVWMA signal overbought/soldAdding Bollinger BandsBollinger bands used visualize volatility plotting range around moving average two standard deviations . Geom_bbands works almost identically geom_ma. can use color_ma, color_bands, alpha, fill arguments change appearance bollinger bands.","code":"\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_line() +\n    labs(title = \"META Line Chart\", y = \"Opening Price\", x = \"\") + \n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = volume)) +\n    geom_line() +\n    labs(title = \"META Line Chart\", y = \"Volume\", x = \"\") + \n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_line() +\n    labs(title = \"META Line Chart\", y = \"Opening Price\", x = \"\") + \n    theme_tq_green()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_line() +\n    labs(title = \"META Line Chart\", y = \"Opening Price\", x = \"\") + \n    theme_tq_dark()\nmeta_price_yahoo %>%\n  # We can also set y = close, which is equivalent to setting y = close. \n    ggplot(aes(x = date, y = open)) +\n    geom_barchart(aes(open = open, high = high, low = low, close = close)) +\n    labs(title = \"META Bar Chart\", y = \"Price\", x = \"\") + \n    theme_tq()\nmeta_price_yahoo %>% \n  # We can also set y = close, which is equivalent to setting y = close.\n    ggplot(aes(x = date, y = open)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    labs(title = \"META Candlestick Chart\", y = \"Price\", x = \"\") +\n    theme_tq()\nstart <- as_date(\"2022-04-30\")\nend <- as_date(\"2022-06-30\")\nreset_y_range <- meta_price_yahoo %>%\n  # the last 60 lines of data. \n  tail(60) %>%\n  summarise(\n    # max value within the selected range\n    max_high = max(high),\n    # min value within the selected range\n    min_low = min(low)\n  )\nreset_y_range## # A tibble: 1 × 2\n##   max_high min_low\n##      <dbl>   <dbl>\n## 1     237.    154.\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close),                        colour_up = \"darkgreen\", colour_down = \"darkred\", \n                        fill_up  = \"darkgreen\", fill_down  = \"darkred\") +\n    labs(title = \"META Candlestick Chart\", subtitle = \"Zoomed in Version\", y = \"Price\", x = \"\") +\n    coord_x_date(xlim = c(start, end), ylim = c(reset_y_range$min_low, reset_y_range$max_high)) +\n    theme_tq()\nconcat1 <- rbind(meta_price_yahoo, aapl_price_yahoo)\nconcat2 <- rbind(tsla_price_yahoo, concat1)\nconcat3 <- rbind(uber_price_yahoo, concat2)\nconcat3## # A tibble: 492 × 8\n##    symbol date        open  high   low close   volume adjusted\n##    <chr>  <date>     <dbl> <dbl> <dbl> <dbl>    <dbl>    <dbl>\n##  1 UBER   2022-01-03  42.5  44.4  41.9  44.0 26089000     44.0\n##  2 UBER   2022-01-04  44.2  44.8  42.6  44.4 30845300     44.4\n##  3 UBER   2022-01-05  44.3  45.9  42.9  43.2 28498700     43.2\n##  4 UBER   2022-01-06  43.1  44.1  41.0  42.0 32434300     42.0\n##  5 UBER   2022-01-07  42    42.7  41.2  41.5 24875800     41.5\n##  6 UBER   2022-01-10  41.5  42.8  40.2  42.6 29783800     42.6\n##  7 UBER   2022-01-11  42.4  44.2  42.2  43.6 22161000     43.6\n##  8 UBER   2022-01-12  44.0  44.1  42.5  43.0 18993900     43.0\n##  9 UBER   2022-01-13  43.3  43.9  42.7  42.9 17190100     42.9\n## 10 UBER   2022-01-14  42.4  42.7  40.4  41.5 25817800     41.5\n## # … with 482 more rows\nconcat3 %>%\n    ggplot(aes(x = date, y = close, group = symbol)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    labs(title = \"Multiple Candlestick Charts\",\n         y = \"Price\", x = \"\") + \n    coord_x_date(xlim = c(start, end)) +\n    facet_wrap(~ symbol, ncol = 2, scale = \"free_y\") + \n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    geom_ma(ma_fun = SMA, n = 20, linetype = 5, size = 1.25) +\n    geom_ma(ma_fun = SMA, n = 40, color = \"red\", size = 1.25) + \n    labs(title = \"META Candlestick Chart\", \n         subtitle = \"20 and 40-Day SMA\", \n         y = \"Price\", x = \"\") + \n    coord_x_date(xlim = c(start, end),\n                 c(reset_y_range$min_low, reset_y_range$max_high)) + \n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    geom_ma(ma_fun = EMA, n = 20, wilder = TRUE, linetype = 5, size = 1.25) +\n    geom_ma(ma_fun = EMA, n = 40, wilder = TRUE, color = \"red\", size = 1.25) + \n    labs(title = \"META Candlestick Chart\", \n         subtitle = \"20 and 40-Day EMA\", \n         y = \"Price\", x = \"\") + \n    coord_x_date(xlim = c(start, end),\n                 c(reset_y_range$min_low, reset_y_range$max_high)) +\n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    geom_ma(ma_fun = WMA, n = 20, wilder = TRUE, linetype = 5, size = 1.25) +\n    geom_ma(ma_fun = WMA, n = 40, wilder = TRUE, color = \"red\", size = 1.25) + \n    labs(title = \"META Candlestick Chart\", \n         subtitle = \"20 and 40-Day WMA\", \n         y = \"Price\", x = \"\") + \n    coord_x_date(xlim = c(start, end),\n                 c(reset_y_range$min_low, reset_y_range$max_high)) +\n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    geom_ma(ma_fun = DEMA, n = 20, wilder = TRUE, linetype = 5, size = 1.25) +\n    geom_ma(ma_fun = DEMA, n = 40, wilder = TRUE, color = \"red\", size = 1.25) + \n    labs(title = \"META Candlestick Chart\", \n         subtitle = \"20 and 40-Day DEMA\", \n         y = \"Price\", x = \"\") + \n    coord_x_date(xlim = c(start, end),\n                 c(reset_y_range$min_low, reset_y_range$max_high)) +\n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    geom_ma(ma_fun = ZLEMA, n = 20, wilder = TRUE, linetype = 5, size = 1.25) +\n    geom_ma(ma_fun = ZLEMA, n = 40, wilder = TRUE, color = \"red\", size = 1.25) + \n    labs(title = \"META Candlestick Chart\", \n         subtitle = \"20 and 40-Day ZLEMA\", \n         y = \"Price\", x = \"\") + \n    coord_x_date(xlim = c(start, end),\n                 c(reset_y_range$min_low, reset_y_range$max_high)) +\n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = open, volume = volume)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    geom_ma(ma_fun = VWMA, n = 20, wilder = TRUE, linetype = 5, size = 1.25) +\n    geom_ma(ma_fun = VWMA, n = 40, wilder = TRUE, color = \"red\", size = 1.25) + \n    labs(title = \"META Candlestick Chart\", \n         subtitle = \"20 and 40-Day VWMA\", \n         y = \"Price\", x = \"\") + \n    coord_x_date(xlim = c(start, end),\n                 c(reset_y_range$min_low, reset_y_range$max_high)) +\n    theme_tq()\nmeta_price_yahoo %>%\n    ggplot(aes(x = date, y = close, volume = volume)) +\n    geom_candlestick(aes(open = open, high = high, low = low, close = close)) +\n    geom_ma(ma_fun = EVWMA, n = 20, wilder = TRUE, linetype = 5, size = 1.25) +\n    geom_ma(ma_fun = EVWMA, n = 40, wilder = TRUE, color = \"red\", size = 1.25) + \n    labs(title = \"META Candlestick Chart\", \n         subtitle = \"20 and 40-Day EVWMA\", \n         y = \"Price\", x = \"\") + \n    coord_x_date(xlim = c(start, end),\n                 c(reset_y_range$min_low, reset_y_range$max_high)) +\n    theme_tq()\nmeta_price_yahoo %>%\n  # high, low, and close information are required. \n    ggplot(aes(x = date, y = close, open = open, high = high, low = low, close = close)) +\n    geom_candlestick() +\n  # sd = 2 by default. \n    geom_bbands(ma_fun = SMA, sd = 2, n = 20) +\n    labs(title = \"META Candlestick Chart\", \n         subtitle = \"BBands with SMA\", \n         y = \"Closing Price\", x = \"\") + \n        coord_x_date(xlim = c(start, end),\n                       c(reset_y_range$min_low, reset_y_range$max_high)) +\n    theme_tq()"},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"quantmod-vs.-tidyquant","chapter":"15 Quantmod & Tidyquant Tutorials and Comparison","heading":"15.4 Quantmod vs. Tidyquant","text":"","code":""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"quantmod-1","chapter":"15 Quantmod & Tidyquant Tutorials and Comparison","heading":"15.4.1 Quantmod:","text":"Pros-\n1. Beginner friendly, need knowledge R libraries/packages create graphs\n2. Easy syntax\n3. Contains essential tools indicators tradersCons-\n1. flexible (example, freely edit elements chart, like caption volume number)\n2. Limited functions (example, conduct data cleaning directly create multi-facet plot)\n3. Limited data source connections, currently 3 direct online data source connections (Yahoo Finance, FRED, oanda)","code":""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"tidyquant-1","chapter":"15 Quantmod & Tidyquant Tutorials and Comparison","heading":"15.4.2 Tidyquant:","text":"Pros-\n1. Can use tidyverse ggplot packages, contains functions clean data, make tidy graphs, implement modeling scaling analysis\n2. Contain quantitative analytical functions Quantmod, xts, TTR, PerformanceAnalytics\n3. Multiple data source connections available, currently 6 connections (Yahoo Finance, FRED, Quandl, Tiingo, Alpha Vantage, Bloomberg)\n4. Flexible (since can use tidyverse ggplot)Cons-\n1. beginner friendly comparing Quantmod\n2. Syntax can complex","code":""},{"path":"quantmod-tidyquant-tutorials-and-comparison.html","id":"sources-2","chapter":"15 Quantmod & Tidyquant Tutorials and Comparison","heading":"15.5 Sources:","text":"https://cran.r-project.org/web/packages/quantmod/quantmod.pdfhttps://www.rdocumentation.org/packages/quantmod/versions/0.4.20https://www.quantmod.com/documentation/https://rdrr.io/cran/quantmod/https://cran.r-project.org/web/packages/tidyquant/vignettes/https://data.nasdaq.com/data/FRED-federal-reserve-economic-data/documentationhttps://www.analyticsvidhya.com/blog/2017/09/comparative-stock-analysis/https://www.business-science.io/code-tools/2017/03/19/tidyquant-quandl-integration.html","code":""},{"path":"learning-echarts4r-with-shiny.html","id":"learning-echarts4r-with-shiny","chapter":"16 Learning echarts4r with shiny","heading":"16 Learning echarts4r with shiny","text":"Ethan EvansFor Community Contribution project, created Shiny web-app tutorial interactive visualization package called echarts4r.link tutorial site can found .","code":""},{"path":"learning-echarts4r-with-shiny.html","id":"motivations","chapter":"16 Learning echarts4r with shiny","heading":"16.1 Motivations","text":"explored package basic level past R experiences enough appreciate true value. times used interactive visualization packages like plotly htmlwidgets, encountered far coding syntax issues plot formatting issues used echarts4r. also just think echarts4r visually appealing set graphics worked across language software. Thus, felt like sharing package class new R users great opportunity classmates.tutorial addresses needs. First, using Shiny web-based platform shows\nnew R developers one ways can deploy view interactive visualizations. Second, tutorial gives simpler, manageable overview package resources. documentation vignettes online sufficiently comprehensive, assume baseline level R visualization knowledge audience class might . tutorial walks build plot start finish, draws comparisons familiar ggplot2, details breadth plots learned class. Online echarts4r tutorials might bit overwhelming well, viewers interested baseline tutorial, might go ahead check vast resources online.","code":""},{"path":"learning-echarts4r-with-shiny.html","id":"evaluation-and-improvement","chapter":"16 Learning echarts4r with shiny","heading":"16.2 Evaluation and Improvement","text":"Creating tutorial taught lot package reiterated \neasy intuitive learn. Also, deep dive research \npackage starting project, realized just powerful unique \npackage . thought everything package offer detailed\nmain package website; however, built Apache ECharts, methods functions library directly translate one echarts4r. Overall, thought tutorial covers package well gives\nviewer enough knowledge start exploring .design tutorial echarts4r , focus depth rather breadth. Overall, spent time giving better explanation fundamentals plot perform certain options plot, rather show dozen different types plots. value, learning fundamentals plot seems better beginner tutorial.","code":""},{"path":"picturing-inflation-an-exercise-in-web-scraping-plotly-and-timeseries.html","id":"picturing-inflation-an-exercise-in-web-scraping-plotly-and-timeseries","chapter":"17 Picturing Inflation: An Exercise in Web Scraping, Plotly and Timeseries","heading":"17 Picturing Inflation: An Exercise in Web Scraping, Plotly and Timeseries","text":"Kevin Taylor","code":"\n##############################################################\n## Install Necessary Packages for Web Driver, Plotting etc. ##\n##############################################################\n\n# install.packages('RSelenium')\n# install.packages('rvest')\n# install.packages('dplyr')\n# install.packages('XML')\n# install.packages('lubridate')\n# install.packages('tidyr')\n# install.packages('plotly')\n\nlibrary(RSelenium)\nlibrary(rvest)\nlibrary(dplyr)\nlibrary(XML)\nlibrary(lubridate)\nlibrary(tidyr)\nlibrary(plotly)"},{"path":"picturing-inflation-an-exercise-in-web-scraping-plotly-and-timeseries.html","id":"background-goals-motivation","chapter":"17 Picturing Inflation: An Exercise in Web Scraping, Plotly and Timeseries","heading":"17.1 Background / Goals & Motivation","text":"Inflation wake COVID-19 one today’s important issues, reflected prices almost goods services. products rapidly doubled tripled price, others remained relatively stable. many ways measure inflation, many indices reflect national averages price, perhaps well-known published Bureau Labor Statistics (BLS). Notably, Consumer Price Index (CPI) measures average price paid consumers wide variety commodities. Countless agencies use Consumer/Producer Price Index various commodities indicator nationwide inflation, collecting data can quite tedious. goal/motivation develop framework gathering Price Index data efficiently Bureau Labor Statistics picture inflation, simultaneously exploring syntax RSelenium, plotly timeseries data R.sought develop framework using web scraping interactive visualizations compare inflation among different commodities. Bureau Labor statistics offers visualizations individual commodities. However, simple way collect data multiple commodities compare relative change time . framework scrapes data price index listed, creates interactive visualization including data commodity easy comparison.","code":""},{"path":"picturing-inflation-an-exercise-in-web-scraping-plotly-and-timeseries.html","id":"methods","chapter":"17 Picturing Inflation: An Exercise in Web Scraping, Plotly and Timeseries","heading":"17.2 Methods","text":"","code":""},{"path":"picturing-inflation-an-exercise-in-web-scraping-plotly-and-timeseries.html","id":"creating-a-web-scraping-function","chapter":"17 Picturing Inflation: An Exercise in Web Scraping, Plotly and Timeseries","heading":"17.2.1 Creating a Web Scraping Function","text":"began creating function scrape data metadata single url. function takes three inputs - url string, object rD instance rsDriver object RSelenium package, integer start_year represents first year collecting data. web driver opens url, interacts page dropdowns buttons update data start year, reads HTML tables scrape data. HTML tables page include data well tables metadata detailing particular commodity name, industry, seasonal adjustment timeseries, etc. data read, data processed plotting, including removing characters preliminary measurements ie) 246.6 (P) scaling values using first value 100. Scaling data extremely important allows easy relative comparison multiple price indices. function get_index_data details process scraping processing data one Bureau Labor Statistics timeseries url.","code":"\n##########################################################\n## Function to access the input url and scrape the data ##\n##########################################################\n\n#' @title get_index_data\n#' @descrition Gathers Data and Metadata from a Price Index\n#' Timeseries URL\n#' @param url = the url string of the price index timeseries\n#' @param rD = an instance of RSelenium rsDriver with appropriate parameters\n#' @param start_year = the year(int) to use as a baseline\n#' @return df DataFrame including timeseries index values and metadata\n\nget_index_data = function(url, rD, start_year)\n{\n  # navigate to the URL\n  remDr = rD[['client']]\n  remDr$navigate(url)\n  \n  Sys.sleep(3) # Sleep to allow the webpage to load\n  \n  # find the 'Start Year' dropdown and select the start year\n  year_checkbox = remDr$findElement(using = 'id', value = 'dv-start-year')\n  year_checkbox$clickElement()\n  option = remDr$findElement(using = 'xpath',\n                             sprintf(\"//*/option[@value = '%s']\", start_year))\n  option$clickElement()\n  \n  # find the 'Update' button and click it\n  update_button = remDr$findElement(using = 'xpath', \"//input[@value='Update']\")\n  update_button$clickElement()\n  \n  Sys.sleep(1) ## Sleep to allow the webpage to update\n  \n  # read the HTML and extract the tables as a list \n  html_tables = remDr$getPageSource()[[1]] |> read_html() |> html_table()\n  \n  ###############################################################\n  ## Using the Scraped HTML Tables, Tidy the Data for Plotting ##\n  ###############################################################\n  \n  df = html_tables[[5]] # this is the table with the bulk of the data\n  names(df) = colnames(html_tables[[4]]) # Contains the column names\n  # the below table contains metadata \n  metadata = (html_tables[[3]][, c(1, 3)] |> pivot_longer(cols = -X1))\n  rownames(metadata) = metadata$X1\n  \n  # some values listed as preliminary x.x (P) - remove this and cast as numeric\n  df$Value = as.numeric(gsub('\\\\(P\\\\)', '', df$Value)) \n  # scale the value column to first value = 100\n  df$Value = (df$Value/df$Value[1])*100\n  # calculate the row-by-row percent change in the index value\n  df$percent_change_last_update = c(\n    NA,\n    (df$Value[-1]-df$Value[-nrow(df)])/df$Value[-nrow(df)]\n  )\n\n  \n  # data published quarterly - change quarters to months\n  df$Label = gsub('Qtr1', 'Mar',\n                  gsub('Qtr2', 'Jun',\n                       gsub('Qtr3', 'Sep',\n                            gsub('Qtr4', 'Dec', df$Label))))\n  \n  # data published biannually - change halves to months\n  df$Label = gsub('Half1', 'Jun',\n                  gsub('Half2', 'Dec', df$Label))\n  \n  df$dt = lubridate::ym(df$Label) # convert label to datetime year-month form\n  \n  df$url = url # add url to table\n  df$Item = metadata['Item',]$value # add item name to table\n  \n  return(df)\n}"},{"path":"picturing-inflation-an-exercise-in-web-scraping-plotly-and-timeseries.html","id":"gathering-the-data-for-some-indices","chapter":"17 Picturing Inflation: An Exercise in Web Scraping, Plotly and Timeseries","heading":"17.2.2 Gathering the Data for Some Indices","text":"function interesting uses web scraping techniques covered class, well timeseries principles scaling timeseries data (base year value 100) lubridate package functions conversion character type Date type. creating web scraping function, gathered data small set indices. Items eggs, milk gasoline often highlighted common items recently experienced inflation. created list url Consumer Price Index items U.S. cities, compiled data using web scraping function. item passed function url, RSelenium rsDriver object created, start year 2015 get picture prices COVID-19 pandemic.point, ran code . web driver used incorporated bookdown collection without launching web driver, commented code instead read data static file representing webdriver output. use webdriver Bureau Labor Statistics webpages, simply remove comments.","code":"\nurls = c(\n  'https://beta.bls.gov/dataViewer/view/timeseries/CUUR0000SEFH', # eggs\n  'https://beta.bls.gov/dataViewer/view/timeseries/CUUR0000SEFJ01', # milk\n  'https://beta.bls.gov/dataViewer/view/timeseries/CUUR0000SETB01' # gasoline\n)\nstart_year = 2015\n# create the Selenium Web Driver with the appropriate Chrome Driver\n# check Chrome version and run binman::list_versions(\"chromedriver\")\n# to see all possible chromedriver inputs\n\n########################\n## Web Scraping Block ##\n########################\n# df_total = data.frame() # aggregate dataframe\n# \n#   rD = rsDriver(\n#    verbose = TRUE,\n#    browser = 'chrome',\n#    chromever = '107.0.5304.62',\n#    port = 4545L,\n#    check = TRUE\n#   )\n#   \n#   for(url in urls)\n#   {\n#    df = get_index_data(url, rD, 2015);\n#    if(nrow(df_total) == 0)\n#    {\n#      df_total = df\n#    }\n#    else\n#      df_total = rbind(df_total, df)\n#   }\n#   df_total =  df_total[,c('dt',\n#                          'Value',\n#                          'percent_change_last_update',\n#                          'Item',\n#                          'url')]\n#  #########################\ndf_total = read.csv('./resources/inflation_web_scraping/bls_data.csv')\ndf_total$dt = as.Date(df_total$dt) # reads dates as characters\nhead(df_total)##   X         dt     Value percent_change_last_update Item\n## 1 1 2015-01-01 100.00000                         NA Eggs\n## 2 2 2015-02-01 100.94505                0.009450543 Eggs\n## 3 3 2015-03-01 100.09782               -0.008393045 Eggs\n## 4 4 2015-04-01  97.57482               -0.025205373 Eggs\n## 5 5 2015-05-01  96.18938               -0.014198645 Eggs\n## 6 6 2015-06-01 113.33988                0.178299253 Eggs\n##                                                            url\n## 1 https://beta.bls.gov/dataViewer/view/timeseries/CUUR0000SEFH\n## 2 https://beta.bls.gov/dataViewer/view/timeseries/CUUR0000SEFH\n## 3 https://beta.bls.gov/dataViewer/view/timeseries/CUUR0000SEFH\n## 4 https://beta.bls.gov/dataViewer/view/timeseries/CUUR0000SEFH\n## 5 https://beta.bls.gov/dataViewer/view/timeseries/CUUR0000SEFH\n## 6 https://beta.bls.gov/dataViewer/view/timeseries/CUUR0000SEFH"},{"path":"picturing-inflation-an-exercise-in-web-scraping-plotly-and-timeseries.html","id":"creating-interactive-visualizations","chapter":"17 Picturing Inflation: An Exercise in Web Scraping, Plotly and Timeseries","heading":"17.2.3 Creating Interactive Visualizations","text":"Plotly package allows users create interactive visualizations. comes editable layout elements tooltip displays information data user hovers graph. began creating axes adding general formatting (theme, title, font elements). commodity timeseries collected , added trace Plotly figure created, time formatting tooltip display relevant information. final output, composite figure multiple indices, allows commodities compared axis, feature included Bureau Labor Statistics data viewer. Furthermore, scaling timeseries base value 100 allows relative inflation commodity compared basis. Please note: price index value proportional particular unit price; rather, viewers gain insight relative change price index time.","code":"\n#########################################################\n## Create the Plotly Figure and add General Formatting ##\n#########################################################\n\nfig = plot_ly()\nfig = fig |> layout(\n  width = 1000,\n  template = 'seaborn', # set a general template\n  plot_bgcolor = 'white',\n  paper_bgcolor = 'white',\n  title = list(\n    text = sprintf('<b>Price Index Values (Scaled)<\/b>\n    Source:<a href=\"https://beta.bls.gov/dataQuery/find\">Bureau of Labor Statistics<\/a>\n    Baseline Jan %s', start_year),\n    font_size = 18,\n    font_family = 'Arial',\n    font_color = 'black'\n  ),\n  xaxis = list( # x-axis formatting\n    title = list(\n      text = 'Date',\n      font_size = 16,\n      font_family = 'Arial'\n    ),\n    tickfont = list(\n      size = 14,\n      family = 'Arial'\n    ),\n    showgrid = TRUE,\n    gridwidth = 0.6,\n    gridcolor = '#EFEFEF'\n  ),\n  yaxis = list( # y-axis formatting\n    title = list(\n      text = 'Price Index Value (Scaled)',\n      font_size = 16,\n      font_family = 'Arial'\n    ),\n    tickfont = list(\n      size = 14,\n      family = 'Arial'\n    ),\n    showgrid = TRUE,\n    gridwidth = 0.6,\n    gridcolor = '#EFEFEF'\n  ),\n  hovermode = 'x unified', # display settings when hovering over chart\n  hoverlabel = list(\n    font_size = 14,\n    font_family = 'Arial',\n    align = 'left'\n  )\n)\n\n#############################################################\n## Add a trace to the figure for each commodity timeseries ##\n#############################################################\n\nfor(url in unique(urls))\n{\n  data = df_total[df_total$url == url,]\n  fig = fig |> add_trace( # add a trace for a particular commodity\n    data = data,\n    customdata = ~percent_change_last_update,\n    text = ~Item,\n    x = ~dt,\n    y = ~Value,\n    type = 'scatter',\n    mode = 'markers+lines',\n    name = data$Item[1],\n    line = list(\n      width = 2.5\n    ),\n    marker = list(\n      opacity = 0.5\n    ),\n    hovertemplate = '<b>%{text}<\/b><br>Value: %{y:.1f}<br>% Change from Prev Update: %{customdata:.1%}<extra><\/extra>'\n  )\n}\n\nfig"},{"path":"picturing-inflation-an-exercise-in-web-scraping-plotly-and-timeseries.html","id":"takeaways-lessons-learned","chapter":"17 Picturing Inflation: An Exercise in Web Scraping, Plotly and Timeseries","heading":"17.3 Takeaways / Lessons Learned","text":"figure, based latest OCT-22 values published NOV-22 retrospectively, seems gasoline volatile commodity past 5 years, even doubling average price 2022 compared baseline JAN-2015. OCT-2022, Milk eggs increased price 15% 28%, respectively, JAN-2015 gasoline 83% expensive, average, JAN-2015. However, recent update, eggs experienced highest monthly inflation, increasing 10.1% last month. figure paints clearer picture inflation average consumer can customized combination commodities.Overall project interesting exercise creating reproducible web scraping visualization workflow, providing additional visualization functionality previously exist (viewing multiple scaled commodities axis compare relative inflation). learned great deal webpage layout types interactive .html elements, web scraping syntax RSelenium package, timeseries Date type, plotly syntax. reproduce workflow, simply use functions loops created file. Make sure un-comment web scraping loop change chromedriver parameter machine’s version Chrome! Hopefully exercise helps readers better understand web scraping, timeseries interactive visualization plotly, provides good resource visualizing understanding inflation.","code":""},{"path":"introcuction-to-dygraph-for-financial-analysis.html","id":"introcuction-to-dygraph-for-financial-analysis","chapter":"18 Introcuction to Dygraph for Financial Analysis","heading":"18 Introcuction to Dygraph for Financial Analysis","text":"Nathaniel Ho","code":""},{"path":"introcuction-to-dygraph-for-financial-analysis.html","id":"project-motivation","chapter":"18 Introcuction to Dygraph for Financial Analysis","heading":"18.1 Project Motivation","text":"motivation project give introduction dygraph, specifically highlighting tools within package prove useful time-series financial data. Currently, popular package financial analysis Quantmod. Quantmod useful retrieving time-series financial data set rudimentary graphs can generate, interactive component. Therefore, project utilizes data generated use Quantmod show different types graphs user can create individual/multiple stocks, well customization options visualizing data, including user interaction.","code":""},{"path":"introcuction-to-dygraph-for-financial-analysis.html","id":"gathering-data","chapter":"18 Introcuction to Dygraph for Financial Analysis","heading":"18.2 Gathering Data","text":"utilize Quantmod package get stock market data AMZN GME. cover specifics code writeup another group covers package well. simply get individual stock prices, well combination closing prices stocks choose one dataframe.","code":"\nlibrary(quantmod)\nlibrary(dygraphs)\ntickers <- c(\"AMZN\", \"GME\")\ngetSymbols(tickers)## [1] \"AMZN\" \"GME\"\nclosePrices <- do.call(merge, lapply(tickers, function(x) Cl(get(x))))\n\namzn <- getSymbols(\"AMZN\")\ngme <- getSymbols(\"GME\")"},{"path":"introcuction-to-dygraph-for-financial-analysis.html","id":"types-of-graphs","chapter":"18 Introcuction to Dygraph for Financial Analysis","heading":"18.3 Types of Graphs","text":"","code":""},{"path":"introcuction-to-dygraph-for-financial-analysis.html","id":"individual-dynamic-chart","chapter":"18 Introcuction to Dygraph for Financial Analysis","heading":"18.3.1 Individual Dynamic Chart","text":"first individual dynamic chart. useful want display summary data singular financial instrument (opening, closing, day high/low stock). , use AMZN’s closing price example.","code":"\ndygraph(AMZN[,4], main=\"AMZN Closing Price\")"},{"path":"introcuction-to-dygraph-for-financial-analysis.html","id":"multiline-dynamic-chart","chapter":"18 Introcuction to Dygraph for Financial Analysis","heading":"18.3.2 Multiline Dynamic Chart","text":"two series share x-axis (date), can compare two series putting dynamic chart directly compare . Common usages include prices percent changes two stocks, well technical aspects stock rolling alpha/beta, Sharpe’s Ratiom etc. , plot Gamestock’s Amazon’s stock prices multiline dynamic chart.proves useful multiple ways. example, can also combine different types graphs. , show AMZN’s stock price, well step chart shows total trading volume financial analysis. creates chart closely mirrors Quantmod’s generated graph, graph interactive.","code":"\nstocks <- cbind(AMZN[,4], GME[,4])\ndygraph(stocks, main = \"Closing Prices of Amazon and Gamestop\") %>% \n  dySeries(c(\"AMZN.Close\"), label = \"AMZN\") %>%\n  dySeries(c(\"GME.Close\"), label = \"GME\")\nstocks <- cbind(AMZN[1000:2000,4], AMZN[1000:2000,5]/100000000)\ndygraph(stocks, main = \"Closing Price of Amazon with Daily Trading Volume\") %>% \n  dySeries(\"AMZN.Close\", label = \"AMZN\") %>%\n  dySeries(\"AMZN.Volume\", stepPlot = TRUE, fillGraph = TRUE, color = \"grey\", label=\"Volume (In Tens of Millions)\")"},{"path":"introcuction-to-dygraph-for-financial-analysis.html","id":"moving-averagerolling","chapter":"18 Introcuction to Dygraph for Financial Analysis","heading":"18.3.3 Moving Average/Rolling","text":"wanted create moving averages stock (common ones 50 MA, 200 MA), can utilize another built-tool dygraphs package called “rollPeriod.” tool gives option choose number data points average, creating smoothed version graph (.e. graph focused trends day--day volatility). following example 50-day MA AMZN stock:","code":"\ndygraph(AMZN[,4], main = \"50-day Moving Average of AMZN\") %>% \n  dyRoller(rollPeriod = 50) %>%\n  dySeries(\"AMZN.Close\", label = \"Moving Average Price\")"},{"path":"introcuction-to-dygraph-for-financial-analysis.html","id":"candlestick","chapter":"18 Introcuction to Dygraph for Financial Analysis","heading":"18.3.4 Candlestick","text":"Finally, candlestick graph. candlestick graph useful showing daily moves stock, well multiple data points opening price, closing price, daily low, daily high, range one graph, making analysis day--day stock movement lot easier digest.","code":"\ndygraph(AMZN[3000:3050,1:4], main = \"AMZN Stock Price\") %>%\n  dyCandlestick() %>%\ndySeries(\"AMZN.Open\", label = \"Open\") %>%\ndySeries(\"AMZN.High\", label = \"High\") %>%\ndySeries(\"AMZN.Low\", label = \"Low\") %>%\ndySeries(\"AMZN.Close\", label = \"Close\")"},{"path":"introcuction-to-dygraph-for-financial-analysis.html","id":"in-graph-modifications","chapter":"18 Introcuction to Dygraph for Financial Analysis","heading":"18.4 In-Graph Modifications","text":"different graphs can modified give clearer visualization stock moves certain direction. tutorial cover shading, events, upper/lower bars.","code":""},{"path":"introcuction-to-dygraph-for-financial-analysis.html","id":"shading","chapter":"18 Introcuction to Dygraph for Financial Analysis","heading":"18.4.1 Shading","text":"Shading useful want denote particular range macroeconomic event happening. example, many analysts use technical analysis predict stock move (common examples bull/bear flags, channels, infamous “dead cat bounce”). example, highlight initial wave COVID lockdowns occured AMZN’s stock price chart better visualize movement period.","code":"\ndygraph(AMZN[,4], main=\"AMZN Closing Price w/COVID Lockdown Highlighted\") %>%\n  dyShading(from = \"2020-2-14\", to = \"2020-8-12\", color = \"#FFE6E6\")"},{"path":"introcuction-to-dygraph-for-financial-analysis.html","id":"events-and-limits","chapter":"18 Introcuction to Dygraph for Financial Analysis","heading":"18.4.2 Events and Limits","text":"factor shocks market within one day, can add event pinpoint immediate effects positive/negative shock financial instrument. example, can highlight stock market crash 2009 AMZN’s stock better visualize economic shock led steep decline stock price.Alternatively, can add limits onto graph better visualize absolute max min stock. AMZN’s stock price peaked July 8, 2021. can create limit shows limit absolute max.","code":"\ndygraph(AMZN[0:1000,4], main=\"AMZN Closing Price w/ Great Recession Crash\") %>%\n   dyEvent(\"2008-9-29\", \"Great Recession Crash\", labelLoc = \"bottom\")\ndygraph(AMZN[,4], main=\"AMZN Closing Price w/ All-Time High Limit\") %>%\n   dyLimit(as.numeric(AMZN['2021-07-08', 4]), as.numeric(AMZN['2021-07-08', 4]), color = \"black\")"},{"path":"introcuction-to-dygraph-for-financial-analysis.html","id":"upperlower-bars","chapter":"18 Introcuction to Dygraph for Financial Analysis","heading":"18.4.3 Upper/Lower Bars","text":"Another way can directly modify graph adding upper/lower bounds graph. particularly useful using prediction ML models time-series data want provide upper/lower bound. sake clarity, utilize daily low/high ranges AMZN stock visualize upper/lower bounds rather ML prediction model.","code":"\ndygraph(AMZN[2000:2050,2:4], main=\"AMZN Stock w/ Daily Low/High\") %>%\n    dySeries(c(\"AMZN.Low\", \"AMZN.Close\", \"AMZN.High\"), label = \"AMZN\")"},{"path":"introcuction-to-dygraph-for-financial-analysis.html","id":"user-interactivity","chapter":"18 Introcuction to Dygraph for Financial Analysis","heading":"18.5 User Interactivity","text":"addition modifications directly apply graph, also modules user interactivity add visualization: namely, selection highlighting range selection.","code":""},{"path":"introcuction-to-dygraph-for-financial-analysis.html","id":"selection-highlighting","chapter":"18 Introcuction to Dygraph for Financial Analysis","heading":"18.5.1 Selection Highlighting","text":"Selection Highlighting useful interaction users want clear indicator time-series following multiple ones plot. example, graph , user hovers stock tracking, line emboldened, makes easier trace trend particular stock. Additionally, add circle user hovering make easier distinguish data point interest.","code":"\nstocks <- cbind(AMZN[,4], GME[,4])\ndygraph(stocks, main = \"Closing Prices of Amazon and Gamestop w/ Selection Highlighting\") %>% \n  dySeries(c(\"AMZN.Close\"), label = \"AMZN\") %>%\n  dySeries(c(\"GME.Close\"), label = \"GME\") %>%\n  dyHighlight(highlightCircleSize = 3, \n              highlightSeriesBackgroundAlpha = 0.4,\n              hideOnMouseOut = FALSE)"},{"path":"introcuction-to-dygraph-for-financial-analysis.html","id":"range-selection","chapter":"18 Introcuction to Dygraph for Financial Analysis","heading":"18.5.2 Range Selection","text":"Additionally, can give users control time range data want view. useful want import entirety dataset, want give user analyze subset data. example seen default range 2020 2022:","code":"\ndygraph(AMZN[,4], main=\"AMZN Stock w/ Range Selection\") %>%\n  dyRangeSelector(dateWindow = c(\"2020-01-01\", \"2022-01-01\"))"},{"path":"introcuction-to-dygraph-for-financial-analysis.html","id":"project-summary-and-evaluation","chapter":"18 Introcuction to Dygraph for Financial Analysis","heading":"18.6 Project Summary and Evaluation","text":"project’s aim give brief introduction dygraph applications create interactive graphs time-series data financial instruments. tutorial covers basics needed create compelling visual story financial instrument, far extensions customization options can utilized reader can explore better tell data-driven story. time, expand dygraph’s use cases beyond financial instruments, time-series trends fields health technology.","code":""},{"path":"two-interesting-r-packages.html","id":"two-interesting-r-packages","chapter":"19 Two Interesting R packages","heading":"19 Two Interesting R packages","text":"Shiyuan Xu Ying HongAs community contribution, made demonstration two exciting R packages called “cowsay” “fortunes”.link Shiny app can found :\nhttps://shiyuan-xu.shinyapps.io/cc_xu_ying/link Rmd file can found :\nhttps://github.com/ShiyuanXu/Stats5702_CC","code":""},{"path":"two-interesting-r-packages.html","id":"motivation-2","chapter":"19 Two Interesting R packages","heading":"19.1 Motivation","text":"learned class, R powerful tool analyze visualize data. However, sometimes get bored R, started question else R can interesting packages R . Therefore, started explore fun packages R— “cowsay” “fortunes”.\nproject, included detailed explanations packages use arguments control output. Afterward, make fun interactive tool using shiny combine two packages link attached (interactive file render meaningful HTML).","code":""},{"path":"two-interesting-r-packages.html","id":"evaluation","chapter":"19 Two Interesting R packages","heading":"19.2 Evaluation","text":"project, besides contents package, learned coding can fun fascinating. Next time like introduce intriguing packages demo create interesting interactive game.","code":""},{"path":"tutorial-for-wordcloud2-package.html","id":"tutorial-for-wordcloud2-package","chapter":"20 Tutorial for wordcloud2 package","heading":"20 Tutorial for wordcloud2 package","text":"Ruoyu Chen Yitong Zhou","code":"\nlibrary(devtools)\n#devtools::install_github(\"lchiffon/wordcloud2\", force = TRUE)\nlibrary(wordcloud2) # must be installed from source\nlibrary(tidyverse)"},{"path":"tutorial-for-wordcloud2-package.html","id":"motivation-3","chapter":"20 Tutorial for wordcloud2 package","heading":"20.1 Motivation","text":"many useful packages “R” visualize data, introduce “wordcloud2” help users visually represent data related frequency. Word frequency statistics method popular today’s research life, especially text mining method. “Wordcloud2” helps visualize result word frequency statistics. word cloud shows trends, visual representation supplements section text help users better present idea. “wordcloud2” shows popularity words making words highest frequency larger bolder. Users also self-define color shape word clouds.addresses users’ need visualize data different frequencies. visualized pictures, readers directly sense data’s relative frequency.","code":""},{"path":"tutorial-for-wordcloud2-package.html","id":"wordcloud2-fuction","chapter":"20 Tutorial for wordcloud2 package","heading":"20.2 “wordcloud2” Fuction:","text":"data: data frame including word freq columnsize: Font size, default 1. larger size means bigger word.fontFamily: Font use, e.g. Times New Roman, Calibri Light,…fontWeight: Font weight use, e.g. normal, bold 600color: color text, keyword “random-dark” “random-light” can used. color vector also supported paramminSize: character string subtitlebackgroundColor: Color background.gridSize: Size grid pixels marking availability canvas larger grid size, bigger gap words.minRotation: word rotate, minimum rotation (rad) text rotate.maxRotation: word rotate, maximum rotation (rad) text rotate. Set two value equal keep text one angle.rotateRatio: Probability word rotate. Set number 1 always rotate.shape:shape “cloud” draw. Can keyword present. Available presents “circle” (default), “cardioid” (apple heart shape curve, known polar equation), “diamond” (alias square), “triangle-forward”, “triangle”, “pentagon”, “star”.ellipticity: degree “flatness” shape wordcloud2.js draw.figPath: fig used wordcloud.widgetsize: size widgets","code":"\nwordcloud2(data,size = 1, minSize = 0, gridSize =  0,\n    fontFamily = NULL, fontWeight = 'normal',\n    color = 'random-dark', backgroundColor = \"white\",\n    minRotation = -pi/4, maxRotation = pi/4, rotateRatio = 0.4,\n    shape = 'circle', ellipticity = 0.65, widgetsize = NULL)"},{"path":"tutorial-for-wordcloud2-package.html","id":"function-application","chapter":"20 Tutorial for wordcloud2 package","heading":"20.3 Function application","text":"","code":""},{"path":"tutorial-for-wordcloud2-package.html","id":"data-scource","chapter":"20 Tutorial for wordcloud2 package","heading":"20.3.1 Data scource","text":"use dataset, contains commonly used single words English language web, derived Google Web Trillion Word Corpus, show apply “wordcloud2” package draw multiple useful world clouds. Since dataset 333333 rows, use top 500 commonly used single words.","code":"\nunigram_freq <- read_csv(\"resources/wordcloud2_tutorial/unigram_freq.csv\",show_col_types = FALSE)\nunigram_freq <- unigram_freq[0:500,]"},{"path":"tutorial-for-wordcloud2-package.html","id":"color-and-backgroundcolor","chapter":"20 Tutorial for wordcloud2 package","heading":"20.3.2 Color and backgroundcolor","text":"User define color background like. output wordcloud2 HTML widget. However, since possible knitting issues, insert word cloud.Basic color backgroudcolor","code":"\nwordcloud2(unigram_freq, color = \"random-light\", backgroundColor = \"black\")"},{"path":"tutorial-for-wordcloud2-package.html","id":"rotation","chapter":"20 Tutorial for wordcloud2 package","heading":"20.3.3 Rotation","text":"set “minRotation”, “maxRotation”, “rotateRatio” rotate texts cloud. “rotateRatio” texts rotated within scope (minRotation, maxRotation). output wordcloud2 HTML widget. However, since possible knitting issues, insert word cloud.RotationIf rotateRatio = 0.5, half words rotated. minRotation \\(\\neq\\) maxRotation, words rotated minRotation maxRotation. output wordcloud2 HTML widget. However, since possible knitting issues, insert word cloud.Rotation different degree","code":"\nwordcloud2(unigram_freq, size = 1, minRotation = -pi/6, maxRotation = -pi/6,\n  rotateRatio = 1)\nwordcloud2(unigram_freq, size = 1, minRotation = -pi/3, maxRotation = -pi/6,\n  rotateRatio = 0.5)"},{"path":"tutorial-for-wordcloud2-package.html","id":"specific-shape-inside-the-package","chapter":"20 Tutorial for wordcloud2 package","heading":"20.3.4 Specific shape inside the package","text":"can chose shape cloud produced setting parameter “shape”, “wordcloud2” provide mutiple shapes users, can chose one like, “star”, “circle”, “cardioid”, “diamond”, “triangle-forward”, “triangle”, “pentagon.” output wordcloud2 HTML widget. However, since possible knitting issues, insert word cloud.Star","code":"\nwordcloud2(unigram_freq, size = 1,shape = 'star')"},{"path":"tutorial-for-wordcloud2-package.html","id":"self-defined-shape","chapter":"20 Tutorial for wordcloud2 package","heading":"20.3.5 Self-defined shape","text":"self-define picture looks like setting parameter “figPath”. Upload self-defined picture figpath, apply “worldclouds2” packages. example, use sun.jpg mask. Usually, image black white image. Since Rmarkdown problems knitting wordcloud, order show result wordcloud, download wordcloud insert image.\nFigure 20.1: wordcloud self-defined shape\n","code":"\nwordcloud2(unigram_freq, figPath = \"sun.jpg\", size = 1.9,color = \"red\")"},{"path":"tutorial-for-wordcloud2-package.html","id":"lettercloud-function","chapter":"20 Tutorial for wordcloud2 package","heading":"20.4 “letterCloud” function","text":"Instead using specific shape, can create wordcloud customizing shape word.data: data frame including word freq columnword: word create shape wordcloudwordSize: Parameter size wordletterFont: Letter font…: parameters wordcloud","code":"\nletterCloud(data, word, wordSize = 0, letterFont = NULL,...)"},{"path":"tutorial-for-wordcloud2-package.html","id":"function-application-1","chapter":"20 Tutorial for wordcloud2 package","heading":"20.5 Function Application","text":"Using data unigram_freq, let “EDAV” word. Since Rmarkdown problems knitting wordcloud, order show result wordcloud, download wordcloud insert image.wordcloud using letterCloud function","code":"\nletterCloud(unigram_freq, word = \"EDAV\",wordSize = 1, size = 3)"},{"path":"tutorial-for-wordcloud2-package.html","id":"some-tips-for-using-word-clouds","chapter":"20 Tutorial for wordcloud2 package","heading":"20.6 Some Tips for Using Word Clouds","text":"using letterCloud() function, important make sure dataset enough words. letters include shape word, words need.using letterCloud() function, important make sure dataset enough words. letters include shape word, words need.fontFamily wordcloud2() include almost fonts word document Times New Roman, Calibri Light,… However, choosing appropriate font project important.fontFamily wordcloud2() include almost fonts word document Times New Roman, Calibri Light,… However, choosing appropriate font project important.self-defined shape letterCloud() function, size wordSize need considered return desired wordcloud.self-defined shape letterCloud() function, size wordSize need considered return desired wordcloud.range words’ count large, som data preprocessing might helpful create better word cloud removing words least frequency.range words’ count large, som data preprocessing might helpful create better word cloud removing words least frequency.mentioned , chose insert word cloud order avoid possible knitting issues. However, word cloud HTML interactive. move mouse word, shows frequency word:\n\n\nHTML\n\nmentioned , chose insert word cloud order avoid possible knitting issues. However, word cloud HTML interactive. move mouse word, shows frequency word:HTML","code":""},{"path":"tutorial-for-wordcloud2-package.html","id":"common-problems","chapter":"20 Tutorial for wordcloud2 package","heading":"20.7 Common Problems","text":"issue downloading CRAN?recommended use github sources mentioned beginning tutorial.issue downloading CRAN?recommended use github sources mentioned beginning tutorial.Unable show word cloud?method solve problem otherwise refreshing window try either refresh using button top right corner open html new window. .rmd file.\n\n\nTip showing wordcloud\n\nUnable show word cloud?method solve problem otherwise refreshing window try either refresh using button top right corner open html new window. .rmd file.Tip showing wordcloudHow knit word cloud pdf?wordcloud2 returns HTML widgets. either save image insert manually using package webshotHow knit word cloud pdf?wordcloud2 returns HTML widgets. either save image insert manually using package webshotMore Problem?Github page packagre creator might helpful:\nwordcloud2 issuesMore Problem?Github page packagre creator might helpful:\nwordcloud2 issues","code":""},{"path":"tutorial-for-wordcloud2-package.html","id":"evaluation-1","chapter":"20 Tutorial for wordcloud2 package","heading":"20.8 Evaluation","text":"project aims summarize main functions “wordcloud2” package advantages disadvantages. process, learned use word cloud show frequency words, unique feature word cloud. strong visualization function word cloud visual impact bar chart visualization techniques. larger size frequently used words can catch audience’s attention immediately. Also, users can customize color word background fit application. Moreover, since functions wordcloud2 returns HTML widget, placing mouse word can see frequency word, can fit interactive web visualization.also disadvantages wordcloud2 package. Although basic wordcloud2() function can return stable HTML widget, customizing shape either using image letters lead empty result. way solve problem refresh window. cause problem knitting pdf HTML like tutorial. method chose save word cloud image insert HTML. However, lose function word cloud user interaction., change different dataset. current dataset frequently used English words interesting. However, word clouds useful analyzing audiences’ ideas public opinion certain product. Also, wordcloud2 isn’t package can generate word clouds. add comparisons different word cloud packages.","code":""},{"path":"tutorial-for-wordcloud2-package.html","id":"citation","chapter":"20 Tutorial for wordcloud2 package","heading":"20.9 Citation","text":"CRAN wordcloud2rdocumentation letterCloud","code":""},{"path":"effcient-r.html","id":"effcient-r","chapter":"21 Effcient R","heading":"21 Effcient R","text":"Ruochen Zhang, Weipeng Li","code":""},{"path":"effcient-r.html","id":"introduction-1","chapter":"21 Effcient R","heading":"21.1 Introduction","text":"R one world’s widely used statistics programming languages, can used statistical analysis, graphics representation, reporting. understanding characteristics, can make R programming efficient.R interpreted language, calls compiled C, Fortran languages behind scenes. Ususally calling complied languages efficient compared writing codes take time compile, Vectorized programming can improve efficiency little modifications codes vector matrix basic operation units R operations call compiled codes.R flexible. example, variables dynamic types content type can modified. flexible design brings extra burden operation may make programs slower. can improve efficiency paying attention flexibility memory allocation.tutorial, introduce methods improve efficiency, including efficient programming parallel computation. also introduce use profiling tools analyze program efficiency.","code":""},{"path":"effcient-r.html","id":"efficient-programming","chapter":"21 Effcient R","heading":"21.2 Efficient programming","text":"","code":""},{"path":"effcient-r.html","id":"vectorized","chapter":"21 Effcient R","heading":"21.2.1 Vectorized","text":"Accessing underlying C/Fortran routines quickly possible can make program efficient. fewer functions calls required achieve , better. Many R functions vectorised, function’s inputs /outputs naturally work vectors, reducing number function calls required.can use example calculating mean deviation median sample show vectorized functions work.caculate:\n\\(\\frac{1}{n}\\sum_{=1}^{n} abs(x_{}-m)\\),m median sample.method 1, can calculate loops.Using vectorized functions can write mean() median().second method concise, also efficient. can compare running time bench::mark, count running time multiple times.can see vectorised method almost 4 times faster first one. test run interfered tasks running time operating system, median minimum time (fastest possible) can better show efficiency rather average time.’s also important make full use R functions use vectors. Sometimes straightforward use vectors can improve efficiency many times. consider estimating integral \\(\\int_ {0}^ {1} x^2 dx\\) using Monte-Carlo method. Essentially, throw darts curve count number darts fall curve. typical way follows:version utilise vectors can shown follows:comparing running time, can see ectorized method much faster.monte_carlo_vec() function uses vectorised functions.addition,comparison(>), runif(), power operations(^) also vectorised applying whole vector rather repeatedly single elements.","code":"\nmad_f1 <- function(x){\n  n <- length(x)\n  mhat <- median(x)\n  s <- 0.0\n  for(i in 1:n){\n    s <- s + abs(x[i] - mhat)\n  }\n  s <- s/n\n  return(s)\n}\nmad_f2 <- function(x) mean( abs(x - median(x)) )\nx <- runif(10000)\nbench::mark(\n  mad_f1(x),\n  mad_f2(x)\n)## # A tibble: 2 × 6\n##   expression      min   median `itr/sec` mem_alloc `gc/sec`\n##   <bch:expr> <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n## 1 mad_f1(x)    1.58ms   1.61ms      610.     257KB     24.6\n## 2 mad_f2(x)   381.5µs  387.2µs     2438.     235KB     10.3\nmonte_carlo = function(N) {\n  hits = 0\n  for (i in seq_len(N)) {\n    u1 = runif(1)\n    u2 = runif(1)\n    if (u1 ^ 2 > u2)\n      hits = hits + 1\n  }\n  return(hits / N)\n}\nmonte_carlo_vec = function(N) sum(runif(N)^2 > runif(N)) / N\nN = 500000\nt1<-system.time(monte_carlo(N))[3]\nt2<-system.time(monte_carlo_vec(N))[3]\nsprintf('monte_carlo time consumption:%.3f',t1)## [1] \"monte_carlo time consumption:1.931\"\nsprintf('monte_carlo vectorised version time consumption:%.3f',t2)## [1] \"monte_carlo vectorised version time consumption:0.015\""},{"path":"effcient-r.html","id":"the-apply-family","chapter":"21 Effcient R","heading":"21.2.2 The Apply Family","text":"Explicit loops can slow verbose R. vectorized methods help avoiding many loops, another helpful tool apply family. functions serve nice substitutes loops execute efficiently. apply functions take least two arguments: object valid R expression. expression applied iteratively objects given orders. many apply functions base R, showing table . rarely used, introduce important ones section.Functions Apply Family","code":""},{"path":"effcient-r.html","id":"apply","chapter":"21 Effcient R","heading":"21.2.2.1 apply()","text":"apply() function applies expression margins array matrix. takes three arguments: X, MARGIN, FUN. X array apply function . MARGIN indicates directions apply expression, 1 rows, 2 columns, c(1,2) rows columns. FUN expression applied. also takes ‘simplify’ arguments, default value ‘TRUE’, indicating whether results simplified. example apply() alternative loop following.","code":"\nM1 <- matrix(C<-(1:15),nrow=5)\nM1_colsum<-apply(M1,2,sum)\nM1_colsum## [1] 15 40 65"},{"path":"effcient-r.html","id":"lapply-sapply","chapter":"21 Effcient R","heading":"21.2.2.2 lapply(), sapply()","text":"lapply() designed lists. applies function every entry input list returns list length. sapply() works similarly lapply(), permits flexible output. default returns vector matrix, also supports array output can controled ‘simplify’ argument.","code":"\nNames<-c(\"Manish\",\"Saurabh\", \"Rahul\",\"Krishna\",\"Venkat\")\nNames_lower<-lapply(Names,tolower)\nNames_lower## [[1]]\n## [1] \"manish\"\n## \n## [[2]]\n## [1] \"saurabh\"\n## \n## [[3]]\n## [1] \"rahul\"\n## \n## [[4]]\n## [1] \"krishna\"\n## \n## [[5]]\n## [1] \"venkat\"\nNames_upper<-sapply(Names,toupper)\nNames_upper##    Manish   Saurabh     Rahul   Krishna    Venkat \n##  \"MANISH\" \"SAURABH\"   \"RAHUL\" \"KRISHNA\"  \"VENKAT\""},{"path":"effcient-r.html","id":"tapply","chapter":"21 Effcient R","heading":"21.2.2.3 tapply()","text":"tapply() applies operation subset vector broken given factor variable. works similar group_by() function plus aggregated operation dplyr. Let’s use iris dataset example.","code":"\ndata(iris)\nsummary(iris)##   Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n##  Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n##  1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n##  Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n##  Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n##  3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n##  Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n##        Species  \n##  setosa    :50  \n##  versicolor:50  \n##  virginica :50  \n##                 \n##                 \n## \ntapply(iris$Sepal.Length,iris$Species,mean)##     setosa versicolor  virginica \n##      5.006      5.936      6.588"},{"path":"effcient-r.html","id":"replicate","chapter":"21 Effcient R","heading":"21.2.2.4 replicate()","text":"replicate() nice alternative writing loop random simulation. executes given program several times without introducing count variable. return multi-dimension array simulating results. takes two arguments: n expr. n indicates number repetition, expr operation executed. example, like compute mean standard deviation q sequence standard normal random variables. decide repeat simulation 8 times, time generate 100 random sample.","code":"\nset.seed(123)\nreplicate(8, {\n  x <- rnorm(100, 0, 1); \n  c(mean(x), sd(x)) })##            [,1]       [,2]      [,3]        [,4]      [,5]        [,6]\n## [1,] 0.09040591 -0.1075468 0.1204651 -0.03622291 0.1058509 -0.04229996\n## [2,] 0.91281588  0.9669866 0.9498790  1.03878122 0.9893458  0.93872815\n##            [,7]      [,8]\n## [1,] -0.1496441 0.1058735\n## [2,]  1.0282366 1.0100100"},{"path":"effcient-r.html","id":"memory-allocation","chapter":"21 Effcient R","heading":"21.2.3 Memory Allocation","text":"good habit R programming pre-allocate memory variables filling values. Make sure size list data frame grow loop. Although R supports dynamic memory allocation executing, can time-wasting big data sets. illustrate , consider different ways creating continuous sequence numbers.first method start empty list gradually grow list iteration.second way start list length \\(n\\), fill values iteration.Compare running time two methods.following table shows average running time local comupter two methods different values n. can see drastic difference \\(n\\) grows, time memory allocation can longer ignored. \\(n=10^6\\), method1 takes 36 minutes, method2 takes less 1 second.Running Time (Seconds) Different Methods Memory AllocationWhat sure vector size finishing loop? cases ’s often good practice allocate large enough size vector, delete empty part loop. Comparing reallocate memory object every time iteration, need allocate twice. example, like find number subarrays \\(k\\) number continuous ’1’s random array. two ways .Test running time two functions random sequence length \\(10^6\\), set \\(k=4\\). can find first function takes lot time second function.","code":"method1 <- function(n) {\n  vec <- c()\n  for (i in seq_len(n))\n    vec <- c(vec, i)\n  vec\n}method2 <- function(n) {\n  vec <- numeric(n)\n  for (i in seq_len(n))\n    vec[i] <- i\n  vec\n}n <- 1e5\ntmemory_1 <- system.time(method1(n))[3]\ntmemory_2 <- system.time(method2(n))[3]\n\nn <- 1e6\ntmemory_3 <- system.time(method1(n))[3]\ntmemory_4 <- system.time(method2(n))[3]\nfindones1 <- function(x,k){\n  n <- length(x)\n  runs <- NULL\n  for(i in 1:(n-k+1)){\n    if(all(x[i:(i+k-1)]==1)) runs <- c(runs,i)\n  }  \n  return(runs)\n}\nfindones2 <- function(x,k){\n  n <- length(x)\n  runs <- vector(length=n)\n  count <- 0\n  for(i in 1:(n-k+1)){\n    if(all(x[i:(i+k-1)]==1)){\n      count <- count+1\n      runs[count] <- i\n    }\n  }\n  ifelse(count > 0, runs <- runs[1:count], runs <- NULL)\n  return(runs)\n}\nset.seed(123)\nn <- round(runif(n=1e6,min=0,max=1))\nsprintf('Running time of findones1: %.3f',system.time(findones1(n,4))[3])## [1] \"Running time of findones1: 5.752\"\nsprintf('Running time of findones2: %.3f',system.time(findones2(n,4))[3])## [1] \"Running time of findones2: 0.689\""},{"path":"effcient-r.html","id":"avoid-making-copies","chapter":"21 Effcient R","heading":"21.2.4 Avoid making copies","text":"Cumulative codes like x <- c(x, y) may make copy time running, slows program amount storage large number repeated modifications large. need avoid making unnecessary copies make program efficient. avoid modifying size variables can avoid making copies. addition, need pay attention modify values variables.modify values data frame, generates copy every time. modifying values list generate copies thus efficient. compare running time modifying values two kinds data type following example.replicate() returns list simplify=FALSE. Saving data list efficient access saving data frame. data frames offer functions. need choose base needs.","code":"\nset.seed(101)\nm <- 2E4; n <- 100\nx <- as.data.frame(matrix(\n  runif(n*m), nrow=n, ncol=m))\ntime1<-system.time({\n  for(j in seq(m)){\n    x[[j]] <- x[[j]] + 1\n  }\n})\nset.seed(101)\nm <- 2E4; n <- 100\nx <- replicate(m, \n  runif(n),\n  simplify=FALSE)\ntime2<-system.time({\n  for(j in seq(m)){\n    x[[j]] <- x[[j]] + 1\n  }\n})\nx <- as.data.frame(x)\ntime1[3]## elapsed \n##  11.234\ntime2[3]## elapsed \n##   0.013"},{"path":"effcient-r.html","id":"parallel-computing","chapter":"21 Effcient R","heading":"21.3 Parallel Computing","text":"Parallel computing widely used technique dealing big datasets, uses multiple cores threads complete task time. computers multiple cores, R runs one virtual cores default.large task can divided independent subtasks, easy conduct parallel computing different cores. bottleneck lies need communicate cores. example, one time-consuming task R random simulation, like avoid using sequences different cores threads.Luckily, packages simple parallel computing R, quick glimpse functions section.","code":""},{"path":"effcient-r.html","id":"general-r-functions-for-parallel-computing","chapter":"21 Effcient R","heading":"21.3.1 General R Functions for Parallel Computing","text":"parallel package R provides simple way parallel computing. gives parallel version apply family, namely parApply(), parLapply(), parSapply(), etc. functions require temporary cluster main object.better explain use parallel package, let us consider simple task. want compute \\[S_{n,k}=\\Sigma_{=1}^{n}\\frac{1}{^k}\\] \\(n=10^6\\), \\(k\\) ranging 2 21. computation independent different \\(k\\)s, ’s safe assign task different cores.Let’s first compute task single core.Now let’s computation multiple cores step step. Firstly, use detectCores() check virtual cores computer.Next, create temporary cluster multiple cores main objects parallel computation.Conduct parallel computation parLapply() parSapply(). computing time now 0.818 seconds, reduced 48% compared single core computation. Notice parallel version, f10 defined inside f12, function runs different threads independently, make sure initialization definition done properly every thread.Another way initialization pass dependent objects every cluster clusterExport(). example, instead defining f10 inside f12, can also following.need execute operations every cluster node computation, clusterEvalQ() can helpful. example, can import certain libraries execution.computation, always remember stop cluster. ensures efficient CPU allocation future tasks.","code":"\nf10 <- function(n,k){\n  s <- 0.0\n  for(i in seq(n)) s <- s + 1/i^k\n  s\n}\nf11 <- function(n,nk){\n  v <- sapply(2:(nk+1), function(k) f10(n,k))\n  v\n}\nsprintf('Running time with a single core: %.3f',system.time(f11(n=1e6, nk=20))[3])## [1] \"Running time with a single core: 1.516\"\nnNodes <- detectCores()\nnNodes## [1] 2\ncpucl <- makeCluster(nNodes)\nf12 <- function(n,nk){\n  f10 <- function(n,k){\n    s <- 0.0\n    for(i in seq(n)) s <- s + 1/i^k\n    s\n  }\n\n  v <- parSapply(cpucl, 2:(nk+1), function(k) f10(n,k))\n  v\n}\nsprintf('Running time with multiple cores: %.3f',system.time(f12(n=1e6, nk=20))[3])## [1] \"Running time with multiple cores: 0.825\"\nclusterExport(cpucl, c(\"f10\"))\nf13 <- function(n,nk){\n  v <- parSapply(cpucl, 2:(nk+1), function(k) f10(n,nk))\n  v\n}\nsprintf('Running time with multiple cores: %.3f',system.time(f13(n=1e6, nk=20))[3])## [1] \"Running time with multiple cores: 0.831\"clusterEvalQ(cpucl, library(dplyr))\nstopCluster(cpucl)"},{"path":"effcient-r.html","id":"parallel-computing-for-random-simulations","chapter":"21 Effcient R","heading":"21.3.2 Parallel Computing for Random Simulations","text":"mentioned beginning section, challenging task parallel computation random simulation. example, want conduct simulation \\(10^7\\) times. task can divided ten simulation tasks \\(10^6\\) times, random sequences different ten tasks.L'Ecuyer popular random number generator parallel computation R. long period around \\(2^191\\). enables us use separate stream cluster node random sequences never get sync. nextRNGStream() function parallel package sets specific random seed generator, thus assigning different streams every node.example, want estimate probability Wilson confidence interval containing true value \\(p\\). Recall Wilson confidence interval defined \\[\\frac{\\hat{p}+\\frac{\\lambda^2}{2n}}{1+\\frac{\\lambda^2}{n}} \\pm \\frac{\\lambda}{\\sqrt{n}}\\frac{\\sqrt{\\hat{p}(1-\\hat{p})+\\frac{\\lambda^2}{4n}}}{1+\\frac{\\lambda^2}{n}},\\]\\(\\lambda = \\phi^{-1}(1-\\alpha)\\). want simulate probability different \\(alpha\\), \\(n\\) \\(p\\).First, let’s computation single core.Now let’s move multi-core version task. parallel computation, task takes 29.95s, reduced 43% comparing single-core version.","code":"\nwilson <- function(n, x, conf){\n  hatp <- x/n\n  lam <- qnorm((conf+1)/2)\n  lam2 <- lam^2 / n\n  p1 <- (hatp + lam2/2)/(1 + lam2)\n  delta <- lam / sqrt(n) * sqrt(hatp*(1-hatp) + lam2/4) / (1 + lam2)\n  c(p1-delta, p1+delta)\n}\n\nf20 <- function(nsim){\n  set.seed(123)\n  n <- 30; p0 <- 0.01; conf <- 0.95\n  cover <- 0\n  for(i in seq(nsim)){\n    x <- rbinom(1, n, p0)\n    cf <- wilson(n, x, conf)\n    if(p0 >= cf[1] && p0 <= cf[2]) cover <- cover+1\n  }\n  cover/nsim\n}\nsprintf('Running time with a single core: %.3f',system.time(cvg1 <- f20(nsim=1e7))[3])## [1] \"Running time with a single core: 55.641\"\nnNodes <- detectCores()\ncpucl <- makeCluster(nNodes)\neach.seed <- function(s){\n  assign(\".Random.seed\", s, envir = .GlobalEnv)\n}\nRNGkind(\"L'Ecuyer-CMRG\")\nset.seed(123)\nseed0 <- .Random.seed\nseeds <- as.list(1:nNodes)\n\n# Create different seeds for the cluster nodes\nfor(i in 1:nNodes){ \n  seed0 <- nextRNGStream(seed0)\n  seeds[[i]] <- seed0\n}\n# Assign different seed for every node\njunk <- clusterApply(cpucl, seeds, each.seed)\nf21 <- function(isim, nsimsub){\n  n <- 30; p0 <- 0.01; conf <- 0.95\n  cover <- 0\n  for(i in seq(nsimsub)){\n    x <- rbinom(1, n, p0)\n    cf <- wilson(n, x, conf)\n    if(p0 >= cf[1] && p0 <= cf[2]) cover <- cover+1\n  }\n  cover\n}\nclusterExport(cpucl, c(\"f21\", \"wilson\"))\n\nf22 <- function(nsim){\n  nbatch <- 40\n  nsimsub <- nsim / nbatch\n  cvs <- parSapply(cpucl, 1:nbatch, f21, nsimsub=nsimsub)\n  sum(cvs)/(nsim*nbatch)\n}\nsprintf('Running time with multiple cores: %.3f',system.time(cvg2 <- f22(1e7))[3])## [1] \"Running time with multiple cores: 22.137\"\nstopCluster(cpucl)"},{"path":"effcient-r.html","id":"profiling-tools-in-r","chapter":"21 Effcient R","heading":"21.4 Profiling tools in R","text":"try optimize R programs. first need decide whether necessary bottleneck lies. simple problems, can get results within reasonable time space consumption.also unnecessary optimization results minor improvements. find bottleneck necessary optimize , still need consider whether modify R codes can rewrite part using languages like C++ achieve simple improvements.analyze efficiency codes, use profiling tools R.Base R utils::rprof()can collect profiling data program runs, utils::summaryRprof() can provide profiling summaries text format. also can use profvis package provides interactive graphical interface visualising code profiling data.use example show profvis package works.can see flame graph, upper panel gives amount time spent line code. lower panel shows process whole program. R’s built-functions don’t show profvis flame graph,although functions can occupy lot time. need pay attention kind problem. discussion can found guide.complex programs,save program R source file. use source() method load function run, use profvis() call function display performance analysis results running.can store function bad_copy.R. run profvis(bad_copy())","code":"\nprofvis({\n  make_adder <- function(n) {\n    function(x) {\n      pause(0.25)\n      x + n\n    }\n  }\n\n  make_adder(1)(10)\n  adder2 <- make_adder(2)\n  adder2(10)\n})\n bad_copy <- function(){\n  M <- 1E5\n  x <- c()\n  for(i in seq(M)){\n    x <- c(x, diff(range(runif(10))))\n  }\n  mean(x)\n}"},{"path":"effcient-r.html","id":"references","chapter":"21 Effcient R","heading":"21.5 References","text":"[1] https://csgillespie.github.io/efficientR/programming.html[2] https://bookdown.org/manishpatwal/bookdown-demo/[3] https://www.math.pku.edu.cn/teachers/lidf/docs/Rbook/html/_Rbook/prog-prof.html","code":""},{"path":"color-vision-deficiency.html","id":"color-vision-deficiency","chapter":"22 Color vision deficiency","heading":"22 Color vision deficiency","text":"Margaret Reed Yaxin HuColor vision deficiency typically referred color blindness can defined inability distinguish certain colors, colors . Research shows 8% men 0,5% women suffer color blindness deficiency extent.mentioned class, color vision deficiency important issue aware creating data visualizations. red-green confusion well known several types, considered creating accessible visualizations.Problems faced color blind people comes data visualization:*able recognize series categories:\nbiggest problem occurs people suffering CVD distinguish categories. Certain colors look totally different healthy people may look almost identical color blind people.*able recognize key message glance:\nAnother problem might occur color blind people may able recognize key message glance. example might color code graph way increase colored green decrease colored red. color blind people wouldn’t notice .important design color vision deficiency friendly graph visualization.","code":"\nlibrary(tidyverse)\nlibrary(ggokabeito)"},{"path":"color-vision-deficiency.html","id":"types-of-color-vision-deficiencies","chapter":"22 Color vision deficiency","heading":"22.0.1 Types of color vision deficiencies:","text":"","code":""},{"path":"color-vision-deficiency.html","id":"red-green-color-blindness","chapter":"22 Color vision deficiency","heading":"22.0.1.1 Red-green color blindness","text":"common type color blindness makes hard tell difference red green.4 types red-green color blindness:Deuteranomaly common type red-green color blindness. makes green look red. type mild doesn’t usually get way normal activities.Protanomaly- makes red look green less bright. type mild usually doesn’t get way normal activities.Protanopia deuteranopia make unable tell difference red green .","code":""},{"path":"color-vision-deficiency.html","id":"blue-yellow-color-blindness","chapter":"22 Color vision deficiency","heading":"22.0.1.2 Blue-yellow color blindness","text":"less-common type color blindness makes hard tell difference blue green, yellow red.2 types blue-yellow color blindness:Tritanomaly- makes hard tell difference blue green, yellow red.Tritanopia- makes unable tell difference blue green, purple red, yellow pink. also makes colors look less bright.","code":""},{"path":"color-vision-deficiency.html","id":"complete-color-blindness","chapter":"22 Color vision deficiency","heading":"22.0.1.3 Complete color blindness","text":"complete color blindness, can’t see colors . also called monochromacy, ’s quite uncommon. Depending type, may also trouble seeing clearly may sensitive light.Source: https://www.nei.nih.gov/learn--eye-health/eye-conditions--diseases/color-blindness/types-color-blindness","code":""},{"path":"color-vision-deficiency.html","id":"test-your-plots","chapter":"22 Color vision deficiency","heading":"22.0.2 Test your plots","text":"exact science, great tools test visualizations may look someone conditions. one like Sim Daltonism. (Download )However, application works Macs windows linux machine, recommend program suggested class.example standard ggplot color palette looks like different color vision deficiencies.","code":""},{"path":"color-vision-deficiency.html","id":"original","chapter":"22 Color vision deficiency","heading":"22.0.2.1 Original:","text":"might plot look like conditions:Ways improve without changing color:Increase Contrast:Double Encoding:Better Palette:really like Okabe-Ito pallete designed Masataka Okabe Kei Ito(learn read : )good visual guide.easily use palette R, like ggokabeito package, can downloaded CRAN.Example new color palette:","code":"\niris %>%\n  ggplot(\n    aes(x = Sepal.Length, y = Petal.Width, color = Species)\n  ) +\n  geom_point()\niris %>%\n  ggplot(\n    aes(x = Sepal.Length, y = Petal.Width, color = Species)\n  ) +\n  geom_point() +\n  theme_minimal()\niris %>%\n  ggplot(\n    aes(x = Sepal.Length, y = Petal.Width, color = Species, shape = Species)\n  ) +\n  geom_point() +\n  theme_minimal()\niris %>%\n  ggplot(\n    aes(x = Sepal.Length, y = Petal.Width, color = Species)\n  ) +\n  geom_point() +\n  scale_color_okabe_ito(order = c(3,7,9)) +\n  theme_minimal()"},{"path":"color-vision-deficiency.html","id":"other-considerations","chapter":"22 Color vision deficiency","heading":"22.0.3 Other considerations","text":"important make sure data science visualizations accessible many people possible, considerations color extend color vision deficiencies. Often times medium present visualizations can considerably impact color distinctions come across. every visualization viewed large projector, dispersed individual viewing, others may even printed black white. Therefore important consider skills double encoding, using shapes textures, using high contrast colors creating visualizations.","code":""},{"path":"tutorials-for-ggfortify-and-autoplotly.html","id":"tutorials-for-ggfortify-and-autoplotly","chapter":"23 Tutorials for ggfortify and autoplotly","heading":"23 Tutorials for ggfortify and autoplotly","text":"Yujia Chen","code":"\nlibrary(autoplotly)\nlibrary(ggplot2)\nlibrary(ggfortify)\nlibrary(cluster)\nlibrary(changepoint)\nlibrary(KFAS)\nlibrary(strucchange)\nlibrary(splines)"},{"path":"tutorials-for-ggfortify-and-autoplotly.html","id":"motivation-4","chapter":"23 Tutorials for ggfortify and autoplotly","heading":"23.0.1 Motivation","text":"first time used ggfortify package draw time series graph similar ggplot2 style. ggfortify package easy--use uniform programming interface enables users use one line code visualize statistical results using ggplot2 building blocks. ggfortify package extends ggplot2 plotting popular R package using standardized approach, included function autoplot().autoplotly package provides functionalities automatically generate interactive visualizations many popular statistical results supported ggfortify package plotly ggplot2 style.example, can hover mouse point plot see details, principal components information species particular data point belongs . can also use interactive selector drag select area zoom , zoom double clicking anywhere plot.ggfortify autoplotly can widely used statistical analysis fields can seen powerful additions ggplot2 package.","code":""},{"path":"tutorials-for-ggfortify-and-autoplotly.html","id":"examples","chapter":"23 Tutorials for ggfortify and autoplotly","heading":"23.0.2 Examples","text":"","code":""},{"path":"tutorials-for-ggfortify-and-autoplotly.html","id":"linear-models","chapter":"23 Tutorials for ggfortify and autoplotly","heading":"23.0.2.1 Linear Models","text":"autoplotly() function able able interpret lm fitted model objects allows user \nselect subset desired plots parameter. parameter allows users specify subplots display, example:","code":"\nautoplotly(\n  lm(Petal.Width ~ Petal.Length, data = iris),\n  which = c(4, 6), colour = \"dodgerblue3\",\n  smooth.colour = \"black\", smooth.linetype = \"dashed\",\n  ad.colour = \"blue\", label.size = 3, label.n = 5,\n  label.colour = \"blue\")"},{"path":"tutorials-for-ggfortify-and-autoplotly.html","id":"principal-component-analysis","chapter":"23 Tutorials for ggfortify and autoplotly","heading":"23.0.2.2 Principal Component Analysis","text":"autoplotly() function works two essential classes objects principal component analysis (PCA) obtained stats package: stats::prcomp stats::princomp, example:","code":"\npca <- autoplotly(prcomp(iris[c(1, 2, 3, 4)]), data = iris,\n  colour = 'Species', frame = TRUE)\npca"},{"path":"tutorials-for-ggfortify-and-autoplotly.html","id":"clustering","chapter":"23 Tutorials for ggfortify and autoplotly","heading":"23.0.2.3 Clustering","text":"autoplotly package also supports cluster::clara, cluster::fanny, cluster::pam well cluster::silhouette classes. automatically infers object type generate interactive plots results packages single function call. Visualization convex cluster iris data set:specifying frame, able draw boundaries different shapes. different frame types can found ggplot2::stat_ellipse’s type keyword via frame.type option. Visualization probability ellipse iris data set:","code":"\nautoplotly(fanny(iris[-5], 3), frame = TRUE)\nautoplotly(pam(iris[-5], 3), frame = TRUE, frame.type = 'norm')"},{"path":"tutorials-for-ggfortify-and-autoplotly.html","id":"forecasting","chapter":"23 Tutorials for ggfortify and autoplotly","heading":"23.0.2.4 Forecasting","text":"Forecasting packages forecast, changepoint, strucchange, KFAS, popular choices statisticians researchers. Interactive visualizations predictions statistical results packages can generated automatically using functions provided autoplotly help ggfortify.changepoint package provides simple approach identifying shifts mean /variance time series. ggfortify supports cpt object changepoint package.Visualization change points optimal positioning AirPassengers data set found changepoint package using cpt.meanvar function:Visualization original smoothed line KFAS package:Visualization filtered result smoothed line:Visualization optimal break points possible structural changes happen regression models built strucchange::breakpoints:","code":"\nautoplotly(cpt.meanvar(AirPassengers))\nmodel <- SSModel(\n  Nile ~ SSMtrend(degree=1, Q=matrix(NA)), H=matrix(NA)\n)\n\nfit <- fitSSM(model=model, inits=c(log(var(Nile)),log(var(Nile))), method=\"BFGS\")\nsmoothed <- KFS(fit$model)\nautoplotly(smoothed)\ntrend <- signal(smoothed, states=\"trend\")\nfiltered <- KFS(fit$model, filtering=\"mean\", smoothing='none')\np <- autoplot(filtered)\nautoplotly(trend, ts.colour = 'blue', p = p)\nautoplotly(breakpoints(Nile ~ 1), ts.colour = \"blue\", ts.linetype = \"dashed\",\n           cpt.colour = \"dodgerblue3\", cpt.linetype = \"solid\")"},{"path":"tutorials-for-ggfortify-and-autoplotly.html","id":"splines","chapter":"23 Tutorials for ggfortify and autoplotly","heading":"23.0.2.5 Splines","text":"autoplotly can also automatically generate interactive plots results produced splines.B-spline basis points visualization natural cubic spline boundary knots produced splines::ns:","code":"\nautoplotly(ns(ggplot2::diamonds$price, df = 6))"},{"path":"tutorials-for-ggfortify-and-autoplotly.html","id":"extensibility-and-composability","chapter":"23 Tutorials for ggfortify and autoplotly","heading":"23.0.3 Extensibility and Composability","text":"plots generated using autoplotly() can easily extended applying additional ggplot2 elements components. example, can add title axis labels originally generated plot using ggplot2::ggtitle ggplot2::labs:Similarly, can add additional interactive components using plotly. following example adds custom plotly annotation element placed center plot arrow:can also stack multiple plots generated autoplotly() together single view using subplot(), two interactive splines visualizations different degree freedom stacked one single view following example:tutorial provides brief introduction interactive data visualization tools. can see, ggfortify autoplotly generate interactive visualizations many popular statistical results. learned build beautiful visualizations statistical results concise code. future, try plot statistical models ggfortify autoplotly.","code":"\nautoplotly(\n  prcomp(iris[c(1, 2, 3, 4)]), data = iris, colour = 'Species', frame = TRUE) +\n  ggplot2::ggtitle(\"Principal Components Analysis\") +\n  ggplot2::labs(y = \"Second Principal Component\", x = \"First Principal Component\")\np <- autoplotly(prcomp(iris[c(1, 2, 3, 4)]), data = iris,\n  colour = 'Species', frame = TRUE)\n\np %>% plotly::layout(annotations = list(\n  text = \"Example Content\",\n  font = list(\n    family = \"Courier New, monospace\",\n    size = 18,\n    color = \"black\"),\n  x = 0,\n  y = 0,\n  showarrow = TRUE))\nsubplot(\n  autoplotly(ns(ggplot2::diamonds$price, df = 6)),\n  autoplotly(ns(ggplot2::diamonds$price, df = 3)), nrows = 2, margin = 0.03)"},{"path":"tutorials-for-ggfortify-and-autoplotly.html","id":"references-1","chapter":"23 Tutorials for ggfortify and autoplotly","heading":"23.0.4 References","text":"http://www.sthda.com/english/wiki/ggfortify-extension--ggplot2--handle--popular-packages-r-software--data-visualizationhttps://github.com/sinhrks/ggfortifyhttps://terrytangyuan.github.io/2018/02/12/autoplotly-intro/https://cran.r-project.org/web/packages/ggfortify/vignettes/basics.htmlhttps://cran.r-project.org/web/packages/ggfortify/vignettes/plot_ts.htmlhttps://cran.r-project.org/web/packages/ggfortify/vignettes/plot_pca.html","code":""},{"path":"becoming-a-better-business-analyst.html","id":"becoming-a-better-business-analyst","chapter":"24 Becoming a better business analyst","heading":"24 Becoming a better business analyst","text":"Jinyu Wang Shuai YuanAs community contribution, wrote article becoming better business analyst based experience industry. full article can found : https://github.com/jw4044/article-business-analyst/blob/main/5702contribution.pdfMain Goal:main goal project give everyone advice core information business analytics data analysis. Also, include advice become better business analyst based experience. Since job market pretty bad days, think share decent advice help us improve together. included three tips detail:1. Proactive application data science methods helps productive, giving time work things matter.2. Applying data science methods can help get accurate analysis results create higher business value.3. practice coding skills, outperform job requirements, use proactive data analysis optimize daily jobs, stand interview process.Evaluation:completing article, fully summarized internship experiences rethought good bad steps took. learned helped us know individually lack current step better future planning becoming better data analysts using data analysis skills. evaluation, think better can share detail visualize project done, people can see clearly.","code":""},{"path":"cheatsheet-of-ggstatsplot-in-r.html","id":"cheatsheet-of-ggstatsplot-in-r","chapter":"25 Cheatsheet of ggstatsplot in R","heading":"25 Cheatsheet of ggstatsplot in R","text":"Shaonan Wang, Baochan JiangThis cheatsheet ggstatsplot. Use link check cheatsheet:\nhttps://github.com/anna-shaonanw/ggstatsplot-cheatsheet/blob/main/ggstatsplot-cheatsheet.pdfWhen data analysis, usually need visualize basic situation data, including mean, median, mode, etc. Based , also test analyze distribution data understand whether data presents normal distribution. two groups data, also need perform t-test detect correlation data. sometimes build model data, perform ANOVA test learn model.{ggplot} good tool visualization. However, want display statistical results graph, complicated process. perform statistical calculations, use {ggplot} draw results one one. case, found convenient R package {ggstatsplot} visualization display statistical results.{ggstatsplot} extension {ggplot2} package creating graphics details statistical tests. can easily add statistical tests graphs, support multiple tests, display P value statistical indicators among data subsets graphs.{ggstatsplot} = “data visualization” + “statistical modeling”process preparing cheatsheet, learned basic type plots multiple statistical approaches tests. {ggstatsplot} help us make data mining easy fast. visually shows relationship data sets results statistical tests helps us better understanding data, differences datasets statistical tests results datasets.package contains cheatsheet, next time, like explore deeply parameter function contributed outcome. want learn group function can show similarity difference multiple data sets, relationship.","code":""},{"path":"best-parallel-coordinates-r-package.html","id":"best-parallel-coordinates-r-package","chapter":"26 Best Parallel Coordinates R Package","heading":"26 Best Parallel Coordinates R Package","text":"Shubham Kaushal Daniel Young","code":""},{"path":"best-parallel-coordinates-r-package.html","id":"introduction-2","chapter":"26 Best Parallel Coordinates R Package","heading":"26.1 Introduction","text":"GGally ggparcoord function user charge order features go along x axis. built-functions arrange automatically propose method. find two highest correlated features, greedily continue appending next highest correlated feature ordering.","code":""},{"path":"best-parallel-coordinates-r-package.html","id":"example","chapter":"26 Best Parallel Coordinates R Package","heading":"26.2 Example","text":"","code":""},{"path":"best-parallel-coordinates-r-package.html","id":"installation","chapter":"26 Best Parallel Coordinates R Package","heading":"26.2.1 Installation","text":"install github repository","code":"\n#devtools::install_github(\"ShubhamKaushal15/bestparcoords\")\nlibrary(\"bestparcoords\") # Must be installed from source"},{"path":"best-parallel-coordinates-r-package.html","id":"data","chapter":"26 Best Parallel Coordinates R Package","heading":"26.2.2 Data","text":"demo package mtcars dataset. preprocessing must done use package example remove last column.","code":"\ndata(mtcars)\nmtcars <- mtcars[,-11]\nhead(mtcars)##                    mpg cyl disp  hp drat    wt  qsec vs am gear\n## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4\n## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4\n## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4\n## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3\n## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3\n## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3"},{"path":"best-parallel-coordinates-r-package.html","id":"default","chapter":"26 Best Parallel Coordinates R Package","heading":"26.2.3 Default","text":"default ordering shown isn’t best, just leaves columns order regardless correlation.","code":"\nGGally::ggparcoord(mtcars, splineFactor=10, alphaLines=0.5)"},{"path":"best-parallel-coordinates-r-package.html","id":"bestparcoords","chapter":"26 Best Parallel Coordinates R Package","heading":"26.2.4 bestparcoords","text":"show bestparcoords graph better default version accentuates alternating trends pairs features shows underlying pattern data much better.Best parcoords also outputs features order found, can use purposes. example, want display plot different spline factor.","code":"\ncols <- bestparcoords::bestparcoord(mtcars)\nprint(cols)##  [1] \"cyl\"  \"disp\" \"wt\"   \"mpg\"  \"hp\"   \"vs\"   \"qsec\" \"am\"   \"gear\" \"drat\"\nindices <- match(cols, colnames(mtcars))\nprint(indices)##  [1]  2  3  6  1  4  8  7  9 10  5\nGGally::ggparcoord(mtcars, columns=indices)"},{"path":"hypothesis-testing-guide-in-r.html","id":"hypothesis-testing-guide-in-r","chapter":"27 Hypothesis Testing Guide in R","heading":"27 Hypothesis Testing Guide in R","text":"Zhexin Wang","code":""},{"path":"hypothesis-testing-guide-in-r.html","id":"hypothesis-testing-in-r-cheatsheet-introductionexplanation","chapter":"27 Hypothesis Testing Guide in R","heading":"27.1 Hypothesis Testing in R Cheatsheet Introduction/Explanation","text":"cheatsheet hypothesis testing R. However, please note serves quick reminder test use corresponding code R, instead exhaustive guide data cleaning analysis. extremely important check data set meet assumptions test (normality, variance equality, large sample size, etc), even though ’s listed detail .\nmotivation behind project need grasp big picture hypothesis testing quickly determine test use different contexts. Even though ’ve learned hypothesis testing detail (either data science course statistics course), sometimes ’s still difficult take step back decide right statistical test systematic quick approach. Thus important part cheatsheet hypothesis testing roadmap, provides easy structured guide choose test. cheatsheet also covers R code performing every test mentioned roadmap users use brief reference data analysis project.\nthoroughly reviewed hypothesis testing creating cheatsheet, learned summarize assumptions tests based roadmap. Next time, include detailed assumptions statistical test instead just providing code roadmap.","code":""},{"path":"hypothesis-testing-guide-in-r.html","id":"hypothesis-testing-roadmap","chapter":"27 Hypothesis Testing Guide in R","heading":"27.2 Hypothesis Testing Roadmap","text":"basic hypothesis testing guide kind dataset.","code":""},{"path":"hypothesis-testing-guide-in-r.html","id":"chi-square-test-in-r","chapter":"27 Hypothesis Testing Guide in R","heading":"27.3 Chi-Square Test in R","text":"\ntypically use chi-square test dataset two categorical variables want test two variables related . example, chi_sq_data two variables: treatment improvement. patients either treated treated, result either improved improved. want test improvement dependent treatment patient received. Thus conduct chi-square test follows:\nImporting data (categorical variables):\n2. Creating table check number category:\n3. Conduct chi-square test:case, p-value = 0.01841, smaller 0.05. Thus reject null hypothesis two variables independent. words, reject statement condition improvement patients related treatment.\n","code":"\nchi_sq_data <- read.csv(\"https://goo.gl/j6lRXD\")\nhead(chi_sq_data)##   id   treatment  improvement\n## 1  1     treated     improved\n## 2  2     treated     improved\n## 3  3 not-treated     improved\n## 4  4     treated     improved\n## 5  5     treated not-improved\n## 6  6     treated not-improved\ntable(chi_sq_data$treatment, chi_sq_data$improvement)##              \n##               improved not-improved\n##   not-treated       26           29\n##   treated           35           15\nchisq.test(chi_sq_data$treatment, chi_sq_data$improvement, correct=FALSE)## \n##  Pearson's Chi-squared test\n## \n## data:  chi_sq_data$treatment and chi_sq_data$improvement\n## X-squared = 5.5569, df = 1, p-value = 0.01841"},{"path":"hypothesis-testing-guide-in-r.html","id":"z-test-in-r","chapter":"27 Hypothesis Testing Guide in R","heading":"27.4 Z-Test in R","text":"\nuse z-test want test whether means two samples . Notice use z-test population standard deviations (population parameters) known, ’s actually uncommon real life examples, data messy populations parameters hidden.\n1. Importing data: (data use toy example) suppose want check mean score biology exam schoolA schoolB , randomly select 30 students school record score. assume scores two schools normally distributed population standard deviation 10.\n2. Conduct z-test:case, p-value 0.06985 greater 0.05. result, reject hypothesis mean scores school school B .\n","code":"\n#Scores from schoolA:\nscoreA <- c(82,84,85,89,91,91,92,94,99,99,49,78,89,48,78,90,96,75,87,90,75,76,83,89,86,82,84,82,98,73)\n\n#Score from schoolB:\nscoreB <- c(90,91,91,91,95,95,99,99,87,89,47,68,94,89,60,79,80,97,68,84,83,82,86,98,87,72,79,83,85,96)\nlibrary(BSDA)\nz.test(x=scoreA, y=scoreB, mu=0, sigma.x=10, sigma.y=10)## \n##  Two-sample z-Test\n## \n## data:  scoreA and scoreB\n## z = -0.3873, p-value = 0.6985\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -6.060605  4.060605\n## sample estimates:\n## mean of x mean of y \n##      83.8      84.8"},{"path":"hypothesis-testing-guide-in-r.html","id":"anova-in-r","chapter":"27 Hypothesis Testing Guide in R","heading":"27.5 Anova in R","text":"\nAnova used determine whether means three populations different. words, used compare three group check significantly different one another. data numerical. cover basic form: one-way Anova.\n1. Importing data: use built-R dataset named PlantGrowth. dataset two columns: weight group. three groups general, including one control group two treatment group. goal test whether population mean three groups .\n2. Conducting ANOVA: (Please note even though don’t include data cleaning/data visualization process , proper data analysis project address important steps.)p-value smaller 0.05, indicating reject null hypothesis groups . drawback don’t know pair groups different. Thus analysis pairwise t-test kind pairwise comparisons needs done order analyze groups detail.\n","code":"\nanova_data <- PlantGrowth\nhead(anova_data)##   weight group\n## 1   4.17  ctrl\n## 2   5.58  ctrl\n## 3   5.18  ctrl\n## 4   6.11  ctrl\n## 5   4.50  ctrl\n## 6   4.61  ctrl\nres.aov <- aov(weight ~ group, data = anova_data)\nsummary(res.aov)##             Df Sum Sq Mean Sq F value Pr(>F)  \n## group        2  3.766  1.8832   4.846 0.0159 *\n## Residuals   27 10.492  0.3886                 \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"hypothesis-testing-guide-in-r.html","id":"paired-sample-t-test","chapter":"27 Hypothesis Testing Guide in R","heading":"27.6 Paired Sample T-test","text":"\nPaired sample t-test used compare means two groups samples. hypothesis mean difference two sets observations 0 (also mean difference smaller 0, greater 0.) Note different z-test population parameters known case, makes much frequently used z-test. data follow two assumptions: data paired sample large enough (n greater 30).\n1. Importing data: Let’s use toy example . Assume students received tutoring outside school. grades tutoring. want know ’s significant improvement grades receiving tutoring. Note toy example meets two assumptions, given scores group students sample size greater 30.\n2. Conduct paired sample t-test:p-value much smaller 0.05, thus reject null hypothesis. means tutoring help students improve grade.\n","code":"\n#Students grades before tutoring\nbefore <- c(80, 75, 90, 68, 79, 49, 86, 58, 79, 76, 54, 89, 50, 68, 59, 80, 75, 90, 68, 79, 49, 86, 58, 79, 76, 54, 89, 50, 68, 59)\n\n#Students grades after tutoring\nafter <- c(86, 97, 85, 76, 74, 79, 86, 89, 99, 97, 95, 86, 87, 90, 77, 86, 97, 85, 76, 74, 79, 86, 89, 99, 97, 95, 86, 87, 90, 77)\n\npaired_t_data <- data.frame( \n                group = rep(c(\"before\", \"after\"), each = 15),\n                grade = c(before,  after)\n                )\nhead(paired_t_data)##    group grade\n## 1 before    80\n## 2 before    75\n## 3 before    90\n## 4 before    68\n## 5 before    79\n## 6 before    49\nres <- t.test(before, after, paired = TRUE)\nres## \n##  Paired t-test\n## \n## data:  before and after\n## t = -5.9119, df = 29, p-value = 2.029e-06\n## alternative hypothesis: true mean difference is not equal to 0\n## 95 percent confidence interval:\n##  -21.80444 -10.59556\n## sample estimates:\n## mean difference \n##           -16.2"},{"path":"hypothesis-testing-guide-in-r.html","id":"independent-samples-t-test","chapter":"27 Hypothesis Testing Guide in R","heading":"27.7 Independent samples t-test","text":"\nindependent samples t-test used compare two sample means order determine whether population means different. assumptions : random sampling, continuous variables, independent samples, normality, variance homogeneity, outliers.\n1. Importing data: Let’s use toy dataset z-test, assuming don’t information population parameters case. addition, equal variance normality assumed.\n2. Conducting independent samples t-test: (case variables numeric equal variance assumed. Independent samples also used one variable categorical exactly two groups)p-value much greater 0.05. Thus can’t reject null hypothesis true difference means equal 0.\n","code":"\nscoreA <- c(82,84,85,89,91,91,92,94,99,99,49,78,89,48,78,90,96,75,87,90,75,76,83,89,86,82,84,82,98,73)\nscoreB <- c(90,91,91,91,95,95,99,99,87,89,47,68,94,89,60,79,80,97,68,84,83,82,86,98,87,72,79,83,85,96)\nt.test (scoreA, scoreB, var.equal=TRUE)## \n##  Two Sample t-test\n## \n## data:  scoreA and scoreB\n## t = -0.32229, df = 58, p-value = 0.7484\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -7.210851  5.210851\n## sample estimates:\n## mean of x mean of y \n##      83.8      84.8"},{"path":"hypothesis-testing-guide-in-r.html","id":"weltch-t-test","chapter":"27 Hypothesis Testing Guide in R","heading":"27.8 Weltch t-test","text":"\nWeltch t-test similar independent samples t-test except equal variance assumed.\n1. Importing data: Let’s use toy dataset independent samples t-test, assuming don’t information population parameters variance.Conducting Weltch t-test: (note variance equality assumed)Since p-value much greater 0.05, failed reject null hypothesis true difference means equal 0.\n","code":"\nscoreA <- c(82,84,85,89,91,91,92,94,99,99,49,78,89,48,78,90,96,75,87,90,75,76,83,89,86,82,84,82,98,73)\nscoreB <- c(90,91,91,91,95,95,99,99,87,89,47,68,94,89,60,79,80,97,68,84,83,82,86,98,87,72,79,83,85,96)\nt.test (scoreA, scoreB, var.equal=FALSE)## \n##  Welch Two Sample t-test\n## \n## data:  scoreA and scoreB\n## t = -0.32229, df = 57.998, p-value = 0.7484\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -7.210855  5.210855\n## sample estimates:\n## mean of x mean of y \n##      83.8      84.8"},{"path":"hypothesis-testing-guide-in-r.html","id":"mann-whitney-u-test","chapter":"27 Hypothesis Testing Guide in R","heading":"27.9 Mann Whitney U Test","text":"\nMann Whitney U Test used want compare median two independent groups. test non-parametric, meaning outcome either normally distributed small. dataset tested normal, independent samples t-test used instead.\n1. Importing data: Let’s use similar toy dataset , assuming don’t information population parameters variance. samples normally distributed.\n2. Conducting Mann Whitney U Test:Since p-value greater 0.05, fail reject null two populations shape.\n","code":"\n#costumer ratings before improvment:\nratingA_mann <- c(82,84,85,89,91,91,92,94,99,99,49,78,89,48)\n\n#costumer ratings after improvement:\nratingB_mann <- c(90,91,91,91,95,95,99,99,87,89,47,68,94,89)\nwilcox.test(ratingA_mann, ratingB_mann)## \n##  Wilcoxon rank sum test with continuity correction\n## \n## data:  ratingA_mann and ratingB_mann\n## W = 77.5, p-value = 0.3553\n## alternative hypothesis: true location shift is not equal to 0"},{"path":"hypothesis-testing-guide-in-r.html","id":"kolmogorov-smirnov-test","chapter":"27 Hypothesis Testing Guide in R","heading":"27.10 Kolmogorov-Smirnov Test","text":"\nKolmogorov-Smirnov Test used want check two datasets come distribution. Note comparing entire distribution instead just medians.\n1. Generating data:\n2. Performing Kolmogorov-Smirnov TestThe p-value much smaller 0.05. Thus reject null hypothesis two datasets population.\n","code":"\ndata1 <- rpois(n=30, lambda=5)\ndata2 <- rnorm(100)\nks.test(data1, data2)## \n##  Exact two-sample Kolmogorov-Smirnov test\n## \n## data:  data1 and data2\n## D = 0.99, p-value = 5.707e-14\n## alternative hypothesis: two-sided"},{"path":"hypothesis-testing-guide-in-r.html","id":"kruskal-wallis-test","chapter":"27 Hypothesis Testing Guide in R","heading":"27.11 Kruskal-Wallis Test","text":"\nKruskal-Wallis Test used compare three groups data categorical. non-parametric alternative one-way ANOVA test.\n1. Importing data: let us use PlantGrowth dataset, assume doesn’t meet assumption ANOVA test. three groups dataset, including one control group two treatment groups.\n2. Conducting Kruskal-Wallis Test:Since p-value smaller 0.05, reject null hypothesis three groups significantly different. However, similar case ANOVA test, still need conduct pair-wise analysis order check two groups different\n","code":"\nkruskal_data <- PlantGrowth\nhead(kruskal_data)##   weight group\n## 1   4.17  ctrl\n## 2   5.58  ctrl\n## 3   5.18  ctrl\n## 4   6.11  ctrl\n## 5   4.50  ctrl\n## 6   4.61  ctrl\nkruskal.test(weight ~ group, data = kruskal_data)## \n##  Kruskal-Wallis rank sum test\n## \n## data:  weight by group\n## Kruskal-Wallis chi-squared = 7.9882, df = 2, p-value = 0.01842"},{"path":"hypothesis-testing-guide-in-r.html","id":"references-2","chapter":"27 Hypothesis Testing Guide in R","heading":"27.12 References:","text":"Special thanks Professor Pascal Wallisch amazing DS Intro course. cheatsheet inspired lectureshttps://data-flair.training/blogs/chi-square-test--r/https://www.statology.org/z-test--r/http://www.sthda.com/english/wiki/one-way-anova-test--rhttps://rpubs.com/pg2000in/PairedSampletTesthttps://www.statology.org/kolmogorov-smirnov-test-r/http://www.sthda.com/english/wiki/kruskal-wallis-test--r","code":""},{"path":"python-tutorial-gather-data-through-api-and-web-scraping.html","id":"python-tutorial-gather-data-through-api-and-web-scraping","chapter":"28 Python tutorial: gather data through API and web scraping","heading":"28 Python tutorial: gather data through API and web scraping","text":"Yaohong LiangI wrote medium blog talk get data API requests web scraping using python. Since getting data always first thing data analysis, think helpful anyone wants know get data . blog introduce 2 methods extract data Internet. first one API requests, one web scraping. provided step--step examples method, also discuss pros cons end article. blog can found following link:Python tutorial: gather data API web scraping","code":""},{"path":"an-interactive-dashboard-covid-19-visualization-with-shiny-and-plotly.html","id":"an-interactive-dashboard-covid-19-visualization-with-shiny-and-plotly","chapter":"29 An Interactive Dashboard: COVID-19 Visualization with Shiny and Plotly","heading":"29 An Interactive Dashboard: COVID-19 Visualization with Shiny and Plotly","text":"Ning KangI created dashboard Shiny made interactive plots ggplot2 Plotly. Users can choose two geography levels: state region. Users prompted choose one multiple regions among eleven regions region selected. Users can also decide number variables visualize. multiple variables chosen, facet grid plot displayed. slider change date range, change plot accordingly.link interactive dashboard: COVID-19 Interactive Dashboard","code":""},{"path":"an-interactive-dashboard-covid-19-visualization-with-shiny-and-plotly.html","id":"motivation-for-the-project","chapter":"29 An Interactive Dashboard: COVID-19 Visualization with Shiny and Plotly","heading":"29.1 Motivation for the Project","text":"community contribution, made dashboard visualize New York State’s Covid-19 testing 2020-03-01 2022-11-13. pandemic significantly shaped past three years, many things changed since 2020. Policies changed compared 2020, wondered degree number/percentage people tested positive changed different regions differed. data source, New York State Health Data, enables users visualize data Tableau. However, many commands intuitive. Also, interactive options available R libraries regarding multiple selections filters data. built easier--use interactive visualization dashboard, checking boxes selecting dropdowns yields informative plots.","code":""},{"path":"an-interactive-dashboard-covid-19-visualization-with-shiny-and-plotly.html","id":"evaluation-of-the-project","chapter":"29 An Interactive Dashboard: COVID-19 Visualization with Shiny and Plotly","heading":"29.2 Evaluation of the Project","text":"Shiny intuitive framework building web applications R syntax, knowledge HTML, CSS, JavaScript required. powerful yet easy learn. hadn’t used Shiny project. reading tutorials sample projects practicing, learned structure, unique reactivity, resemblance differences traditional web development tools. implemented Plotly add interactivity plots, enabling tooltips zooming .Users can choose two geography levels: state region. Users prompted choose one multiple regions among eleven regions region selected. Users can also decide number variables visualize. multiple variables chosen, facet grid plot displayed. slider change date range, change plot accordingly.project second time, consider adding cleograph maps. add options sidebar panel graphs, side--side bar charts. also utilize self-created functions improve efficiency. Since data updated daily, web scrapping also used keep plot updated.","code":""},{"path":"an-interactive-dashboard-covid-19-visualization-with-shiny-and-plotly.html","id":"references-3","chapter":"29 An Interactive Dashboard: COVID-19 Visualization with Shiny and Plotly","heading":"29.3 References","text":"Data source: https://health.data.ny.gov/Health/New-York-State-Statewide-COVID-19-Testing/xdss-u53eData source: https://health.data.ny.gov/Health/New-York-State-Statewide-COVID-19-Testing/xdss-u53ehttps://shiny.rstudio.com/tutorial/written-tutorial/lesson1/https://shiny.rstudio.com/tutorial/written-tutorial/lesson1/https://mastering-shiny.org/index.htmlhttps://mastering-shiny.org/index.html","code":""},{"path":"interactive-plots-for-different-types-of-graphs-in-r.html","id":"interactive-plots-for-different-types-of-graphs-in-r","chapter":"30 Interactive plots for different types of graphs in R","heading":"30 Interactive plots for different types of graphs in R","text":"Tongni Chen Tao Yu","code":"\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(gapminder)\nlibrary(\"heatmaply\")\nlibrary(dygraphs)\nlibrary(treemap)\nlibrary(collapsibleTree)\nlibrary(networkD3)"},{"path":"interactive-plots-for-different-types-of-graphs-in-r.html","id":"introduction-3","chapter":"30 Interactive plots for different types of graphs in R","heading":"30.1 introduction","text":"Data visualization useful also necessary get information large data frames. learn use various packages class visualize data. , think can readable graphs, can graphs show information, like detailed numeric text information, like presentation others. purpose, like introduce interactive plots R.introduce 5 packages R can create interactive plots.first one Plotly, powerful package make various types interactive graphs, including line plots, histograms, bar charts, etc., like introduce 4 packages focus one specific type graph. can probably options flexiblility create desired type graphs packages:heatmaply: create interactive heatmaps;dygraphs: focus change variables respect time;treemap: create interactive tree graphs;networkD3: create interactive network graphs.","code":""},{"path":"interactive-plots-for-different-types-of-graphs-in-r.html","id":"plotly","chapter":"30 Interactive plots for different types of graphs in R","heading":"30.2 Plotly","text":"Plotly powerful R package make interactive graphs, including line plots, scatter plots, box plots, histograms, etc. following section, introduce 3 examples.","code":""},{"path":"interactive-plots-for-different-types-of-graphs-in-r.html","id":"scatter-plot","chapter":"30 Interactive plots for different types of graphs in R","heading":"30.2.1 Scatter plot","text":"produce interactive scatter plots, can first use ggplot2, learned class, just call one function make interactive.using plotly, can check information dot much easily. can simply click specific dots interested, appear detailed text numeric information dot, like GDP, life expectancy, continent example.","code":"\nscatter <- gapminder %>%\n  filter(year==1977) %>%\n  ggplot(aes(gdpPercap, lifeExp,color=continent)) +\n  geom_point()\n\nggplotly(scatter)"},{"path":"interactive-plots-for-different-types-of-graphs-in-r.html","id":"boxplots","chapter":"30 Interactive plots for different types of graphs in R","heading":"30.2.2 Boxplots","text":"Besides just calling one function, Plotly also functions make graphs. example draw interactive boxplots Plotly without ggplot.example shows use functions plotly create boxplots two samples Exponential distribution parameter = 3 Normal distribution mean = 10, sd = 1.Interactive boxplots plotly can show detailed numerical maximum, minimum, median, Q1, Q3 values move mouse onto specific box, easier us compare different samples.","code":"\ndata1 = ~rexp(3)\ndata2 = ~rnorm(10,1)\nbox <- plot_ly(y=data1, \n               type = \"box\")\nbox <- box %>% add_trace(y = data2)\nbox"},{"path":"interactive-plots-for-different-types-of-graphs-in-r.html","id":"histograms","chapter":"30 Interactive plots for different types of graphs in R","heading":"30.2.3 Histograms","text":"example shows use plotly create interactive histogram graph desired bin size customized layout, color, title, etc.Interactive histogram graphs plotly can show range bin counts bin move mouse onto specific bins.Plotly can many types interactive graphs, like bar charts, pie charts, line plots, etc.information, library Plotly R package: https://plotly.com/r/.","code":"\ndata3 = rnorm(30,5)\nhist <- plot_ly(x = data3, \n                type = \"histogram\",\n                nbinsx = 5,\n                marker = list(color = \"lightgray\",\n                              line = list(color = \"darkgray\",width = 2)))%>% \n        layout(title = \"Frequency distribution of Normal(30,5)\",\n               yaxis = list(title = \"value\"),\n               xaxis = list(title = \"frequency\"))\n\nhist"},{"path":"interactive-plots-for-different-types-of-graphs-in-r.html","id":"specialized-package-for-specific-types-of-graphs","chapter":"30 Interactive plots for different types of graphs in R","heading":"30.3 Specialized package for specific types of graphs","text":"Plotly creates various types graphs described . , like introduce packages focus specific type graph. can probably options flexiblility create desired type graphs packages.","code":""},{"path":"interactive-plots-for-different-types-of-graphs-in-r.html","id":"heatmaply","chapter":"30 Interactive plots for different types of graphs in R","heading":"30.4 Heatmaply","text":"package create interactive heatmaps. introduce examples Heatmaply section.example uses mtcars, dataframe R information cars different brands.column dataframe part car, like gear, carb.row dataframe different brands.assignment x y features, default show heatmap columns rows dataframe. move mouse one specific rectangle, appear car brand rectangle part car rectangle .can also assign desired x y features. example, interested correlations different parts cars.heatmaply_cor useful funtion create correlation matrixs.example shows create heatmap column mtcars.","code":"\nheatmaply(normalize(mtcars))\nheatmaply_cor(\n  cor(mtcars),\n  xlab = \"Features\",\n  ylab = \"Features\"\n)"},{"path":"interactive-plots-for-different-types-of-graphs-in-r.html","id":"time-series","chapter":"30 Interactive plots for different types of graphs in R","heading":"30.5 Time Series","text":"Time series type data indexed time order, often used represent change variable respect time, package supports interactive time series graph dygraphs:dygraphs automatically shows detailed numerical data upper right hand side follows mouse cursor. can also drag mouse range zoom part graph, can also double click graph zoom back original full graph. following demo, can achieve simply feeding package data, automatically generates functions . However notice package supports data xts format.(data can converted xts format) used quantmod sample time series data, notice ’s much data conversion needed. Also package supports drawing multiple column graph.One can also add range selector helps selecting range passing generated dygraph object dyRangeSelector()","code":"\nlibrary(quantmod)\ngetSymbols(\"MSFT\",from=\"2019-01-01\")## [1] \"MSFT\"\nMSFT[1:3,1]##            MSFT.Open\n## 2019-01-02     99.55\n## 2019-01-03    100.10\n## 2019-01-04     99.72\ndygraph(MSFT[,1])\ndygraph(MSFT[,1:3])\ndygraph(MSFT[,1]) %>% dyRangeSelector()"},{"path":"interactive-plots-for-different-types-of-graphs-in-r.html","id":"tree","chapter":"30 Interactive plots for different types of graphs in R","heading":"30.6 Tree","text":"Trees often used represent parent child relations, type graph useful representing example family lineage, job specialization, various data stored computers uses binary n-ary tree. One problem tree huge expanding , package deals question collapsibleTree, creates interactive tree graph unfolds child node one clicks parent node, retrieves clicked . , tree specific type data structure requires data conversion diagram can created. One common convert data data frame, give example .First retrieve data tree structure.can see data countries continent belongs earth, can create level 3 tree Earth->continent->country. create collapsible tree, need specify data hierarchies (appears data frame column name), case continent, country. can also set root node name, set weather graph zoomable .can also summarize numerical value node based total count leaf descendents using collapsibleTreeSummary setting attribute=“column_name” desired attribute, also aesthetic settings package though discuss detail .","code":"\ndata(GNI2014)\nhead(GNI2014)##   iso3          country     continent population    GNI\n## 3  BMU          Bermuda North America      67837 106140\n## 4  NOR           Norway        Europe    4676305 103630\n## 5  QAT            Qatar          Asia     833285  92200\n## 6  CHE      Switzerland        Europe    7604467  88120\n## 7  MAC Macao SAR, China          Asia     559846  76270\n## 8  LUX       Luxembourg        Europe     491775  75990\ncollapsibleTree(\n  GNI2014,\n  hierarchy = c(\"continent\",\"country\"),\n  root=\"Earth\",\n  zoomable=FALSE\n  )\nlibrary(collapsibleTree)\ncollapsibleTreeSummary(\n  GNI2014,\n  hierarchy = c(\"continent\",\"country\"),\n  root=\"Earth\",\n  attribute=\"population\",\n  zoomable=FALSE\n  )"},{"path":"interactive-plots-for-different-types-of-graphs-in-r.html","id":"graphnetwork-graph","chapter":"30 Interactive plots for different types of graphs in R","heading":"30.7 Graph(Network Graph)","text":"’s also cool package draws 3d graphs, graph stands usual graph learn math class nodes edges. Since graphs sometimes multiple edges connecting nodes, hard drawn 2D plain, package networkD3 provides interactive graph drawing type graph. input data also simple, requires table three columns, first two two nodes connected edge third column edge value, lets create one simple data frame can used .various interesting settings can made graph, example: charge determines strong nodes attracted/repulsed, fontSize set font size node names, opacity opacity graph, linkDistance length edges. color settings nodes edges nodeColour linkColour…","code":"\nSource=c(\"A\",\"A\",\"B\",\"B\",\"C\",\"D\",\"D\",\"D\",\"E\",\"F\")\nTarget=c(\"B\",\"C\",\"F\",\"D\",\"B\",\"E\",\"F\",\"C\",\"A\",\"C\")\nedge_value=c(1,2,3,4,5,6,7,8,9,10)\nexample_graph<-data.frame(Source,Target,edge_value)\nsimpleNetwork(\n  example_graph\n              )\nsimpleNetwork(\n  example_graph,\n  charge=20,\n  fontSize=30,\n  linkDistance = 200,\n  opacity=0.7\n              )"},{"path":"interactive-plots-for-different-types-of-graphs-in-r.html","id":"evaluation-2","chapter":"30 Interactive plots for different types of graphs in R","heading":"30.8 Evaluation","text":"completing community contribution, learned basic functionality various interactive data visualization packages specializes different types graphs, including plotly common histogram/boxplot/scatterplot, heatmaply heat map, dygraphs time series analysis, collapsible tree tree diagrams networkD3 (network)graphs. initially intended work one specific package soon realized convenient packages well documented can easily find tutorials online, decided introduce various packages show can terms enhancing data visualization believe helpful students looking good packages targeted specific types graphs. time allows, willing look introduce types graphs besides current ones, might introduce packages sophisticated graphs. can also discuss packages detail give better explaination full capability.","code":""},{"path":"introduction-to-plotly-in-r.html","id":"introduction-to-plotly-in-r","chapter":"31 Introduction to Plotly in R","heading":"31 Introduction to Plotly in R","text":"Jingqi Huang, Yi Lu","code":""},{"path":"introduction-to-plotly-in-r.html","id":"overview","chapter":"31 Introduction to Plotly in R","heading":"31.1 Overview","text":"learned exploratory data analysis throughout semester, discovered various R packages techniques help us perform analysis conduct research upon large dataset. example, histogram boxplot unidimensional continuous variables, scatterplot heatmap two continuous variables. However, addition static graphs, interactive ones also play important part modern standard data analysis research purposes. help Columbia Data Science community holistically equipped, team decided bring table. One package implements interactive plots plotly. R package creating interactive publication-quality graphs. https://plotly.com/r/ provides rich examples package R various tags. want extract basic logic use plotly combine relevant examples page.","code":""},{"path":"introduction-to-plotly-in-r.html","id":"install-and-packages","chapter":"31 Introduction to Plotly in R","heading":"31.2 Install and Packages","text":"","code":"\n# install.packages(\"ggplot2\")\n# install.packages(\"plotly\")\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(dplyr)\nlibrary(gapminder)"},{"path":"introduction-to-plotly-in-r.html","id":"basic-grammar","chapter":"31 Introduction to Plotly in R","heading":"31.3 Basic Grammar","text":"Basic grammar plotly simple. type specified, default things set makes sense.Plotly’s graph described two categories: traces layout. Multiple parts graph can added add_trace() add changed configurations. Multiple texts can set add_notations() specifying locations xref yref. Axis title can set layout(). Plotly can convert ggplot graph interactive mode wrap ggplot p ggplotly(p).mind, let’s go package together.","code":"p <- plot_ly(dataframe, x=~column, y=~column2, type=\"graph type such as scatter, bar, box, heatmap, etc.\", mode=\"mode type such as markers, lines, and etc.\")\np <-p %>% add_trace()\np <-p %>% add_notations()\np <-p %>% layout()\np"},{"path":"introduction-to-plotly-in-r.html","id":"basic-examples","chapter":"31 Introduction to Plotly in R","heading":"31.4 Basic examples","text":"","code":""},{"path":"introduction-to-plotly-in-r.html","id":"histogram","chapter":"31 Introduction to Plotly in R","heading":"31.4.1 Histogram","text":"","code":"\ndf <- data.frame(type=rep(c(\"A\", \"B\"), each=500), subtype=rep(c(\"1\", \"2\"), each=250), value=rnorm(1000))\nhist <- ggplot(df, aes(x=value, fill=subtype))+\n  geom_histogram(position=\"identity\", alpha=0.5, binwidth=0.2)+\n  facet_grid(~type)\nggplotly(hist)"},{"path":"introduction-to-plotly-in-r.html","id":"d-histogram","chapter":"31 Introduction to Plotly in R","heading":"31.4.2 2D Histogram","text":"","code":"\np <- plot_ly(x = filter(df, type==\"A\")$value, y = filter(df, type==\"B\")$value)\nhist_2d <- subplot(add_markers(p, alpha=0.4), add_trace(p, type='histogram2dcontour'), add_histogram2d(p))\nhist_2d"},{"path":"introduction-to-plotly-in-r.html","id":"boxplot","chapter":"31 Introduction to Plotly in R","heading":"31.4.3 Boxplot","text":"","code":"\nboxplt <- plot_ly(diamonds, x = ~price/carat, y = ~clarity, color = ~clarity, type = \"box\") %>%\n  layout(title=\"Interactive BoxPlot with Plotly\")\n\n# Second method\np <- ggplot(diamonds, aes(x=clarity, y=price/carat, color=clarity)) +\n  geom_boxplot() + \n  coord_flip() +\n  ggtitle(\"BoxPlot with ggplot2\")\n# the following line generates the same interactive graph\n# ggplotly(p)\n\nboxplt"},{"path":"introduction-to-plotly-in-r.html","id":"d-scatter-plot","chapter":"31 Introduction to Plotly in R","heading":"31.4.4 2D Scatter Plot","text":"","code":"\nscatter2d <- plot_ly(filter(diamonds, color=='D'), x=~carat, y=~price, color=~clarity, marker=list(size=4, opacity=0.5), \n        # hover text\n        text = ~paste(\"Price: \", price, \"$<br>Cut: \", cut, \"<br>Clarity: \", clarity)) %>%\n  # set title and axis\n  layout(title=\"Interactive Scatter Plot with Plotly\")\n\nscatter2d"},{"path":"introduction-to-plotly-in-r.html","id":"d-scatter-plot-1","chapter":"31 Introduction to Plotly in R","heading":"31.4.5 3D Scatter Plot","text":"","code":"\nscatter3d <- plot_ly(diamonds[sample(nrow(diamonds), 1000), ], x=~price/carat, y=~table, z=~depth, color=~cut, \n        marker = list(size=4, opacity=0.5))%>%\n  layout(title=\"Interactive 3D Scatter Plot with Plotly\")\n\nscatter3d\nmtcars <- mutate(mtcars, type = case_when(mtcars$am == 0 ~ \"Auto\", mtcars$am == 1 ~ \"Manual\"))\nplot_ly(mtcars, x=~mpg, y=~wt, z=~hp, color=~type) %>%\n  layout(title=\"Interactive 3D Scatter Plot with Plotly\", \n         scene = list(xaxis = list(title = \"mpg\"), yaxis = list(title = \"weight\"), zaxis = list(title = \"horsepower\")))"},{"path":"introduction-to-plotly-in-r.html","id":"line-plot","chapter":"31 Introduction to Plotly in R","heading":"31.4.6 Line Plot","text":"","code":"\na <- rnorm(100, 5, 1)\nb <- rnorm(100, 0, 1)\nc <- rnorm(100, -5, 1)\ndf <- data.frame(x=c(1:100), a, b, c)\n\nlineplt <- plot_ly(df, x = ~x) %>%\n  add_trace(y = ~a, name=\"line\", type=\"scatter\", mode = \"lines\", line=list(color='rgb(23, 54, 211)', width=2)) %>% \n  add_trace(y=~b, name=\"dot line with markers\", mode = \"lines+markers\", line=list(dash='dot')) %>% \n  add_trace(y=~c, name=\"scatter markers only\", mode = \"markers\") %>%   #same as scatter plot\n  layout(title=\"Interactive Line Plot with Plotly\", yaxis=list(title=\"value\"))\n\nlineplt"},{"path":"introduction-to-plotly-in-r.html","id":"bar-plot","chapter":"31 Introduction to Plotly in R","heading":"31.4.7 Bar Plot","text":"","code":"\nbarplt <- plot_ly(count(diamonds, cut, clarity), x=~cut, y=~n, color=~clarity, type=\"bar\", text=~n, marker=list(opacity=0.4, line=list(color='rgba(8,48,148, 1)', width=1.5))) %>% \n  layout(barmode = 'group')\n\nbarplt"},{"path":"introduction-to-plotly-in-r.html","id":"some-intersesting-examples","chapter":"31 Introduction to Plotly in R","heading":"31.4.8 Some intersesting examples","text":"","code":"\n# Initialization\nquestion <- c('The course was effectively<br>organized',\n       'The course developed my<br>abilities and skills for<br>the subject',\n       'I would recommend this<br>course to a friend',\n       'Any other questions')\ndf <- data.frame(question, sa=c(21, 24, 27, 29), a=c(30, 31, 26, 24), ne=c(21, 19, 23, 15), ds=c(16, 15, 11, 18), sds=c(12, 11, 13, 14))\nanswer_label <- c('Strongly<br>agree', 'Agree', 'Neutral', 'Disagree', 'Strongly<br>disagree')\n\n# Interactive plot\np <- plot_ly(df, x=~sa, y=~question, type=\"bar\", orientation=\"h\", marker = list(color = 'rgba(38, 24, 74, 0.8)',\n                      line = list(color = 'rgb(248, 248, 249)', width = 1))) %>% \n  add_trace(x=~a, marker = list(color = 'rgba(71, 58, 131, 0.8)')) %>% \n  add_trace(x=~ne, marker = list(color = 'rgba(122, 120, 168, 0.8)')) %>%\n  add_trace(x=~ds, marker = list(color = 'rgba(164, 163, 204, 0.85)')) %>% \n  add_trace(x=~sds, marker = list(color = 'rgba(190, 192, 213, 1)')) %>% \n  layout(barmode='stack', \n                  xaxis = list(title = \"\", showgrid = FALSE,showticklabels = FALSE, zeroline = FALSE), \n                  yaxis = list(title=\"\"), \n                  paper_bgcolor = 'rgb(248, 248, 255)',\n                  plot_bgcolor = 'rgb(248, 248, 255)',\n                  margin = list(l = 120, r = 10, t = 40, b = 10),\n                  showlegend = FALSE) %>% \n  add_annotations(xref='x', yref='y', x=~sa/2, y=~question, text=paste(df[,\"sa\"], '%'), font=list(size=12, color=\"white\"), showarrow=FALSE) %>% \n  add_annotations(x=~sa+a/2, text=paste(df[,\"a\"], '%'), font=list(size=12, color=\"white\"), showarrow=FALSE) %>% \n  add_annotations(x=~sa+a+ne/2, text=paste(df[,\"ne\"], '%'), font=list(size=12, color=\"white\"), showarrow=FALSE) %>% \n  add_annotations(x=~sa+a+ne+ds/2, text=paste(df[,\"ds\"], '%'), font=list(size=12, color=\"white\"), showarrow=FALSE) %>%\n  add_annotations(x=~sa+a+ne+ds+sds/2, text=paste(df[,\"sds\"], '%'), font=list(size=12, color=\"white\"), showarrow=FALSE) %>%\n  add_annotations(xref = 'x', yref = 'paper',\n                  x = c(21 / 2, 21 + 30 / 2, 21 + 30 + 21 / 2, 21 + 30 + 21 + 16 / 2,\n                        21 + 30 + 21 + 16 + 12 / 2), y = 1.05,\n                  text = answer_label,\n                  font = list(size = 12, color = 'rgb(67, 67, 67)'), showarrow = FALSE)\n\np"},{"path":"introduction-to-plotly-in-r.html","id":"animations-with-plotly","chapter":"31 Introduction to Plotly in R","heading":"31.5 Animations with Plotly","text":"","code":"\ndf <- data.frame(x = c(1:10), y = rnorm(10), time = c(1:10))\nplot_ly(df, x = ~x, y = ~y, frame = ~time, type = 'scatter', mode = 'markers', showlegend = F)\ndf <- gapminder \nplot_ly(df, x=~gdpPercap, y=~lifeExp, color=~continent, size=~pop, frame=~year, type=\"scatter\", mode=\"markers\", text=~country, hoverinfo = \"text\") %>%\n  layout(xaxis = list(type = \"log\"))"},{"path":"introduction-to-plotly-in-r.html","id":"self-evaluation","chapter":"31 Introduction to Plotly in R","heading":"31.6 Self-evaluation","text":"project generally meets expectation derived motivation described beginning project. explained basic language format provided code example graph. learned use plotly package build various types graphs. combined rich separate examples plotly website concentrated form.However, missing detailed explanation rely codes graphs explain correspondingly. also using simple datasets built-R, create similar examples website. make detailed well-explained, use newer data next time.","code":""},{"path":"introduction-to-plotly-in-r.html","id":"reference-1","chapter":"31 Introduction to Plotly in R","heading":"31.7 Reference:","text":"https://plotly.com/r/","code":""},{"path":"machine-learning-interview-mindmap-and-commonly-asked-questions.html","id":"machine-learning-interview-mindmap-and-commonly-asked-questions","chapter":"32 Machine Learning Interview mindmap and commonly asked questions","heading":"32 Machine Learning Interview mindmap and commonly asked questions","text":"Haolong LiuAs community contribution, mindmap can found hereDescription: created mind map machine learning interviews included many commonly asked questions, gives people broad understanding many machine learning concepts articulate knowledge interview.Motivation: preparing 2023 summer machine learning engineer intern technical interview. Therefore, beneficial organize important machine learning knowledge commonly asked interview questions can perform better.need addresses: Machine learning really broad subject can go deep. mind map certainly comprehensive. example, include RNN CNN. However, machine learning intern jobs mostly likely ask deep questions. mind map gives people directions subject need know. Plus specific questions help people better understand prepare.\nmight differently: Include industrial application related questions experience.","code":""},{"path":"data-visualization-with-seaborn.html","id":"data-visualization-with-seaborn","chapter":"33 Data Visualization with Seaborn","heading":"33 Data Visualization with Seaborn","text":"Yingjie Qu (yq2350) & Liwen Zhu (lz2512)created introduction data visualization Seaborn, package python. introduction includes importing package visualizing typical graphs, histograms scatterplots. also show draw complex diagrams, biplots, ridge plots, help packages.Please look files ‘https://github.com/A1anZhu/python_seaborn’.","code":""},{"path":"tutorial-of-making-different-types-of-charts-interactive.html","id":"tutorial-of-making-different-types-of-charts-interactive","chapter":"34 Tutorial of making different types of charts interactive","heading":"34 Tutorial of making different types of charts interactive","text":"Shumin Song","code":"\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(\"httr\")\nlibrary(\"readxl\")\nlibrary(dplyr)\nlibrary(collapsibleTree)\n# devtools::install_github(\"rstudio/d3heatmap\")\nlibrary(d3heatmap) # need to be installed from source\nlibrary(gapminder)\nlibrary(ggridges)\nlibrary(networkD3)\nlibrary(igraph)\nlibrary(quantmod)\nlibrary(dygraphs)"},{"path":"tutorial-of-making-different-types-of-charts-interactive.html","id":"motivation-5","chapter":"34 Tutorial of making different types of charts interactive","heading":"34.1 Motivation","text":"already learned create different types charts graphs using ggplot2 package class. However, charts graphs made static, means readers read passively focus general information distribution entire data set.order deal problems, can make interactive charts graphs. Interactive data visualization provides tools readers engage, explore adjust data information efficient way. example, readers can observe specific values different aspects data point graph, allows identify trends relationships within data set. addition, analyzing complex data, interactive controls like zooming filtering introduce simplified ordered information readers help generate insights solve problem. tutorial, show create interactive charts graphs R several graph categories.","code":""},{"path":"tutorial-of-making-different-types-of-charts-interactive.html","id":"interactive-scatter-plot","chapter":"34 Tutorial of making different types of charts interactive","heading":"34.2 Interactive Scatter Plot","text":"can create interactive scatter directly using plotly package. use dataset “mtcars” ggplot2 package following example. plot data points regarding wt(weight) x-axis mpg(miles per gallon) y-axis. can find detailed introduction plot_ly() function URL: https://www.rdocumentation.org/packages/plotly/versions/4.10.0/topics/plot_lyIn graph, can:\n1. zoom zoom graph focus data points within specific area\n2. hover data points check exact wt mpg values point\n3. double click graph return default view graph","code":"\nplot_ly(mtcars, type = \"scatter\", x = ~wt, y = ~mpg, mode = \"markers\",\n        hovertemplate = paste(\n          \"%{xaxis.title.text}: %{x:.2f}<br>\",\n          \"%{yaxis.title.text}: %{y:.2f}<br><extra><\/extra>\"\n        )\n      )"},{"path":"tutorial-of-making-different-types-of-charts-interactive.html","id":"interactive-bubble-plot","chapter":"34 Tutorial of making different types of charts interactive","heading":"34.3 Interactive Bubble Plot","text":"Similarly, can create interactive bubble plot dataset “mtcars” using plotly. plot data points regarding wt(weight) x-axis mpg(miles per gallon) y-axis. addition, include cyl(cylinder engine) color categories data points qsec(1/4 mile time) data point bubble size.bubble graph, can things previous scatter plot. Moreover, can hover bubbles see specific cyl values different data points distinguish data points’ differences qsec values bubble size.","code":"\nplot_ly(mtcars, x = ~wt, y = ~mpg, text = ~cyl, size = ~qsec,\n        color = ~cyl, sizes = c(10, 50),\n        marker = list(opacity = 0.6, sizemode = \"diameter\"),\n        hovertemplate = paste(\n          \"%{xaxis.title.text}: %{x:.2f}<br>\",\n          \"%{yaxis.title.text}: %{y:.2f}<br>\",\n          \"cyl:%{text}<br><extra><\/extra>\"\n        ))"},{"path":"tutorial-of-making-different-types-of-charts-interactive.html","id":"interactive-heatmap","chapter":"34 Tutorial of making different types of charts interactive","heading":"34.4 Interactive Heatmap","text":"can use d3heatmap package create interactive heatmap graph. still use mtcars dataset following example. can find detailed d2heatmap() function usage description https://rdrr.io/github/rstudio/d3heatmap/man/d3heatmap.html.graph , every row represents observation car x-axis represents car’s name. Every column graph represents values particular variable “cyl”, “wt”, “mpg” cars data set y-axis represents variable data set. use “BuPu” color palette cause cells low values filled blue cells high values filled purple. can help readers observe interpret difference variable value cars.several interact ways interactive heapmap graphs:\n1. can hover cell see specific information car name, variable column exact value variable car.\n2. Zoom zoom graph focus specific area double click return default view.\n3. Click specific car name variable select particular row column graph.","code":"\nd3heatmap(mtcars, scale = \"column\", col = \"BuPu\",\n          xlab = \"Variable\", ylab = \"Car Name\")"},{"path":"tutorial-of-making-different-types-of-charts-interactive.html","id":"interactive-tree-diagrams","chapter":"34 Tutorial of making different types of charts interactive","heading":"34.5 Interactive Tree Diagrams","text":"create interactive tree diagrams, need use collapsibleTree package. can find detailed usage description collapsibleTree() function https://www.rdocumentation.org/packages/collapsibleTree/versions/0.1.7/topics/collapsibleTree.use dataset “geography” following example. can download dataset https://data.world/glx/geography-table.graph, can click node show hide child nodes. addition, can hover onto node see total number countries, decendant nodes node tree.","code":"\n# Import geography dataset\nGET(\"https://query.data.world/s/mmol5szlwinfp4mfzkxa73qlrp2yli\", write_disk(tf <- tempfile(fileext = \".xlsx\")))## Response [https://download.data.world/file_download/glx/geography-table/Geography%20Table%20-%20Data.World.xlsx?auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OnNodW1pbi1zIiwiaXNzIjoiYWdlbnQ6c2h1bWluLXM6OjhmMzZjMGFjLWYzZTYtNDY4MS04OWJmLTBmZTcxNGQyZjRmNSIsImlhdCI6MTY2ODM5NjIyMSwicm9sZSI6WyJ1c2VyIiwidXNlcl9hcGlfYWRtaW4iLCJ1c2VyX2FwaV9lbnRlcnByaXNlX2FkbWluIiwidXNlcl9hcGlfcmVhZCIsInVzZXJfYXBpX3dyaXRlIl0sImdlbmVyYWwtcHVycG9zZSI6ZmFsc2UsInVybCI6IjJhN2VlYzVjNmE4Zjc0OTZjZWM3MDE3MjBkMTA2NjBlZTBmMTFmMDEifQ.T6wiF_83KIiOn2slG0ElDBkL50g_Ops9RBFPAL0dhG4ZpmU5gZeukpwia9CsRM1ozwYNAKJoy97qdVi5pxGxTw]\n##   Date: 2022-11-17 17:12\n##   Status: 200\n##   Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\n##   Size: 15.1 kB\n## <ON DISK>  /tmp/RtmpeJPYmc/file54696addb1f6.xlsx\ngeography <- read_excel(tf)\n\n# view general info of geography dataset\nhead(geography)## # A tibble: 6 × 6\n##   country               region sub_region      continent type            juris…¹\n##   <chr>                 <chr>  <chr>           <chr>     <chr>           <chr>  \n## 1 Abkhazia              Europe <NA>            Europe    Partially Reco… \"Post-…\n## 2 Afghanistan           Asia   Southern Asia   Asia      Country         \"Indep…\n## 3 Ajaria                Europe <NA>            Europe    Region          \"Polit…\n## 4 Akrotiri and Dhekelia Europe <NA>            Europe    Part of a Larg… \"Briti…\n## 5 Aland Islands         Europe <NA>            Europe    Archipelago     \"Regio…\n## 6 Albania               Europe Southern Europe Europe    Country         \"Indep…\n## # … with abbreviated variable name ¹​jurisdiction\ngeography %>%\n  group_by(continent, type) %>%\n  summarize(`Number of Countries` = n()) %>%\n  collapsibleTreeSummary(\n    hierarchy = c(\"continent\", \"type\"),\n    root = \"geography\",\n    width = 600,\n    attribute = \"Number of Countries\"\n  )"},{"path":"tutorial-of-making-different-types-of-charts-interactive.html","id":"interactive-ridgeline-plot","chapter":"34 Tutorial of making different types of charts interactive","heading":"34.6 Interactive Ridgeline Plot","text":"can use plotly package create interactive ridgeline plot graphs. use “gapminder” dataset gapminder package following example. plot density ridgeline life expectancy different countries different years.graph, can hover ridgeline area horizontally see density change different life expectancy values. can also hover vertically see overall density alteration according change year.","code":"\nridgeline <- ggplot(data = gapminder, aes(x = lifeExp, fill = year)) +\n  geom_density() + \n  facet_grid(year~.) +\n  xlab(\"Life Expectancy in Birth\") +\n  ylab(\"Year\")\n(interactive_ridgeline <- ggplotly(ridgeline))"},{"path":"tutorial-of-making-different-types-of-charts-interactive.html","id":"interactive-network-graph","chapter":"34 Tutorial of making different types of charts interactive","heading":"34.7 Interactive Network Graph","text":"use networkD3 package make interactive network graphs. create nodes edges manually. can find detailed usage description simpleNetwork() function https://www.rdocumentation.org/packages/networkD3/versions/0.4/topics/simpleNetworkIn graph, can zoom using scroll wheel hover node check nodes directly connected current node. can also drag node see neighbors edges via node clearly.","code":"\n# create nodes and edges of graph\ndf <- data.frame(\n  from = c(\"A\", \"A\", \"B\", \"D\", \"C\", \"D\", \"E\", \"B\", \"C\", \"B\"),\n  to = c(\"B\", \"E\", \"F\", \"A\", \"C\", \"A\", \"B\", \"D\", \"A\", \"C\")\n)\n\nsimpleNetwork(df, height=\"300px\", width=\"300px\", \n              linkColour = \"red\", nodeColour = \"blue\", zoom = T)"},{"path":"tutorial-of-making-different-types-of-charts-interactive.html","id":"interactive-time-series-graph","chapter":"34 Tutorial of making different types of charts interactive","heading":"34.8 Interactive Time Series Graph","text":"use dygraphs package make interactive time series graphs. following example, show price Apple stock(AAPL) alteration based time change. can find detailed description dygraph() function https://www.rdocumentation.org/packages/dygraphs/versions/1.1.1.6/topics/dygraphIn graphs, can hover along price line see AAPL stock price variation within day closing price variation time period.","code":"\n# get AAPL price data\ngetSymbols(\"AAPL\")## [1] \"AAPL\"\ndygraph(OHLC(AAPL))\n# focus on AAPL price change from 2020 to current date\ngraph <- dygraph(OHLC(AAPL))\ndyShading(graph, from=\"2020-01-01\", \n          to=\"2022-11-11\", color=\"#FFE6E6\")"},{"path":"tutorial-of-making-different-types-of-charts-interactive.html","id":"my-evaluation-of-tutorial","chapter":"34 Tutorial of making different types of charts interactive","heading":"34.9 My Evaluation of Tutorial","text":"tutorial, learned several crucial packages creating interactive graphs plotly, d3heatmap ‘dygraphs’ well showed advantages interactive graphs. Nevertheless, shortcomings can improved. instance, didn’t explain parameters details interactive graph making functions like d3heatmap(), might cause confusions readers make graphs . addition, show basic application creating interactive graphs. time space, introduce advanced application interactive charts.","code":""},{"path":"tutorial-of-making-different-types-of-charts-interactive.html","id":"citation-sources","chapter":"34 Tutorial of making different types of charts interactive","heading":"34.10 Citation Sources","text":"R Graph Gallery: https://r-graph-gallery.com/interactive-charts.htmlPlotly R Open Source Graphing Libraries: https://plotly.com/r/networkD3 R package: http://christophergandrud.github.io/networkD3/dygraphs R: https://rstudio.github.io/dygraphs/collapsible tree diagrams R: https://github.com/AdeelK93/collapsibleTree","code":""},{"path":"cheatsheet-of-ggplot2-ggplot2-alluvial-heatmap.html","id":"cheatsheet-of-ggplot2-ggplot2-alluvial-heatmap","chapter":"35 Cheatsheet of ggplot2 (ggplot2 & alluvial & heatmap)","heading":"35 Cheatsheet of ggplot2 (ggplot2 & alluvial & heatmap)","text":"Yuehan Hu Wen Chen","code":""},{"path":"cheatsheet-of-ggplot2-ggplot2-alluvial-heatmap.html","id":"the-cheatsheet-link","chapter":"35 Cheatsheet of ggplot2 (ggplot2 & alluvial & heatmap)","heading":"35.1 The Cheatsheet Link:","text":"https://github.com/yuehanhu/ggplot2cheatsheet/blob/main/Cheatsheet.pdf","code":""},{"path":"cheatsheet-of-ggplot2-ggplot2-alluvial-heatmap.html","id":"introduction-to-ggplot2","chapter":"35 Cheatsheet of ggplot2 (ggplot2 & alluvial & heatmap)","heading":"35.2 Introduction to ggplot2","text":"ggplot2 plotting package creates complex plots data based grammar graphics. Moreover, ggplot2 provides programmatic interface specifying variables plot, displayed, general visual properties. package provides convenient way us create different kinds distributions.","code":""},{"path":"cheatsheet-of-ggplot2-ggplot2-alluvial-heatmap.html","id":"summary-to-the-cheatsheet","chapter":"35 Cheatsheet of ggplot2 (ggplot2 & alluvial & heatmap)","heading":"35.3 Summary to the Cheatsheet","text":"cheatsheet includes three parts, first part includes basic definition, essential grammar common visualizations ggplot2, provides us clearly frame use standard format easy way distinguish delicate difference visualizations. second part includes brief description, essential grammar, example, different curve types, color legend customizations ggalluvial. Alluvial useful visualize frequency distributions time frequency tables involving several categorical variables. third part includes short introduction, example, color legend customizations heatmap. Heatmap good us show relationships two variables, one plotted axis.","code":""},{"path":"cheatsheet-of-ggplot2-ggplot2-alluvial-heatmap.html","id":"the-evaluation-of-the-cheatsheet","chapter":"35 Cheatsheet of ggplot2 (ggplot2 & alluvial & heatmap)","heading":"35.4 The evaluation of the Cheatsheet","text":"Although many similarities part grammar creating different visualizations, marked difference grey, help us distinguish remember. cheatsheet summarize important kinds visualizations ggplot2, also lead us review content ggplot2 class generally.","code":""},{"path":"chord-diagrams-using-circlize.html","id":"chord-diagrams-using-circlize","chapter":"36 Chord diagrams using circlize","heading":"36 Chord diagrams using circlize","text":"Pia-Kelsey O’Neill","code":""},{"path":"chord-diagrams-using-circlize.html","id":"overview-1","chapter":"36 Chord diagrams using circlize","heading":"36.1 Overview","text":"Chord Diagrams circular visualizations depict inter-relationships categorical data. can used depict flow migration countries, interactions within set people (relevant research neuroscientist) transitions behaviors animals. tutorial, begin presenting anatomy chord diagram. Next, ’ll review considerations deciding whether chord diagrams appropriate dataset. become familiar chordDiagram function R using two data sets demonstrate simple (interactions main characters sitcom Friends) complex (migration Canadian provinces) uses beautiful visualization tool.","code":""},{"path":"chord-diagrams-using-circlize.html","id":"introduction-4","chapter":"36 Chord diagrams using circlize","heading":"36.2 Introduction","text":"","code":""},{"path":"chord-diagrams-using-circlize.html","id":"anatomy-of-a-chord-diagram","chapter":"36 Chord diagrams using circlize","heading":"36.2.1 Anatomy of a chord diagram","text":"chord diagram shows connections different categories data. Data separated groups organized tracks sectors around circle. size track proportional number data points category. Arcs chords form connections tracks running across expanse circle. number chords extend track depends number target categories. two important features arc:Color. direction data flow categories (migrants one country another) color arc can used depict directionality. Thus, arc’s color match color parent track comes . Note data directionality thus color less important (see Friends example ).Color. direction data flow categories (migrants one country another) color arc can used depict directionality. Thus, arc’s color match color parent track comes . Note data directionality thus color less important (see Friends example ).Thickness. thickness arc represents size flow two categories wider arc represents data flow thinner arc less data flow.Thickness. thickness arc represents size flow two categories wider arc represents data flow thinner arc less data flow.","code":""},{"path":"chord-diagrams-using-circlize.html","id":"considerations-for-making-a-chord-diagram","chapter":"36 Chord diagrams using circlize","heading":"36.2.2 Considerations for making a Chord Diagram","text":"Chord diagrams high aesthetic appeal, may always appropriate method show relationships entities data even data categorical. , ’ll discuss questions might ask data determine chord diagram might appropriate .relationships many--many? Chord diagrams work best data category relationship multiple categories (including ). words, useful displaying data relationships many--many. Datasets one--many relationships might better visualizing using alluvial sankey diagrams.relationships many--many? Chord diagrams work best data category relationship multiple categories (including ). words, useful displaying data relationships many--many. Datasets one--many relationships might better visualizing using alluvial sankey diagrams.many categories? limits number groups can technically depicted chord diagram. chord diagrams can become difficult read interpret number groups high. many chords thinner difficult disentangle. Adding interactivity can help highlighting one sector time (see Interactivity using chorddiag ) ideally, chord diagrams contain 10 fewer categories. Adjustments might made data beforehand reduce number categories. example, want depict migration flow, instead displaying migration countries dataset, group continents regions instead, display subset countries.many categories? limits number groups can technically depicted chord diagram. chord diagrams can become difficult read interpret number groups high. many chords thinner difficult disentangle. Adding interactivity can help highlighting one sector time (see Interactivity using chorddiag ) ideally, chord diagrams contain 10 fewer categories. Adjustments might made data beforehand reduce number categories. example, want depict migration flow, instead displaying migration countries dataset, group continents regions instead, display subset countries.directionality flow? Chord diagrams can directional non-directional. Directional data two chords sector, chord going given category target coming target. Non-directional symmetric data hand one value per chord (value direction). Adjustments color can made chord diagram depending directionality data.directionality flow? Chord diagrams can directional non-directional. Directional data two chords sector, chord going given category target coming target. Non-directional symmetric data hand one value per chord (value direction). Adjustments color can made chord diagram depending directionality data.","code":""},{"path":"chord-diagrams-using-circlize.html","id":"the-chorddiagram-function","chapter":"36 Chord diagrams using circlize","heading":"36.3 The chordDiagram function","text":"create chord diagrams use chordDiagram function circlize package R. circlize package contains methods circos tool used graphing circular representations, especially used field Genomics. chordDiagram help documentation describes data arranged. summarize briefly :chordDiagram takes datafame three columns:rn: first column “” column adjacency list row sector/track/category name.cn: second column “” column adjacency list row sector/track/category name.value: values interaction relation columns 1 2, number counts two categories.","code":""},{"path":"chord-diagrams-using-circlize.html","id":"basic-chord-diagrams-friends","chapter":"36 Chord diagrams using circlize","heading":"36.4 Basic Chord diagrams: Friends","text":"example, use chord diagrams make simple visualization relationships six main characters popular TV show Friends. visualize dyadic (pairwise) storylines characters show across episodes. Note dyads considered example, Season 1 Ep.1, plotline involving Chandler Joey Ross included chord diagram. relationships non-directional (symmetrical) meaning example, Joey plot line Rachel Rachel plotline Joey.","code":"\ndf = read.csv(\"https://raw.githubusercontent.com/apalbright/Friends/master/raw_data/friendsdata.csv\")\n#The six friends are defined as follows: Chandler=1 Joey=2 Monica=3 Phoebe=4 Rachel=5 Ross=6\nfriends= combn(c(\"Chandler\", \"Joey\", \"Monica\", \"Phoebe\", \"Rachel\", \"Ross\"),2)\nrelations = data.frame(from=friends[1,],to=friends[2,])\ndyads = c(\"12\",\"13\",\"14\",\"15\",\"16\",\"23\",\"24\",\"25\",\"26\",\"34\",\"35\",\"36\",\"45\",\"46\",\"56\")\ntotal=list()\nfor (x in dyads){\ntotal[x] = df%>%\n    filter(dynamics==x)%>%\n    count()\n}\nrelations[\"Total\"]=as.numeric(unlist(total))\nchordDiagram(relations)"},{"path":"chord-diagrams-using-circlize.html","id":"customizing-color","chapter":"36 Chord diagrams using circlize","heading":"36.4.1 Customizing color","text":"color schemes chordDiagram default random. ’ll notice run code colors change, appear different every time function called. Sometimes random colors close spectrum. order better distinguish different arcs, can specify colors well adjust transparency border features arcs.","code":"\nchordDiagram(relations,\n             grid.col = c(\"#cc99c9\", \"#9ec1cf\", \"#9ee09e\", \"#fdfd97\", \"#feb144\", \"#ff6663\"),\n             transparency = 0.1,\n             link.lwd = 1,    # Set arc line width\n             link.border = 1) # Set arc border color to black\ncircos.clear()"},{"path":"chord-diagrams-using-circlize.html","id":"adding-interactivity-using-the-chorddiag-package","chapter":"36 Chord diagrams using circlize","heading":"36.4.2 Adding Interactivity using the chorddiag package","text":"Highlighting specific relationships one--one can make chord diagram easier read understand. ’ll add interactivity chord diagram using second R package, chorddiag.Now, mousing chord highlights particular relationship. also simplified visual removing tick marks outer edge circle. data instead displayed tag pops tag mouse chord.improvements: Since know dataset non-directional, color patterns necessary. Mousing chord shows equal number relations Friends pair (.e. Ross–>Rachel Rachel–>Ross 70 storylines). directional data, color chord matches parent track. , make sense use gradient color changes one Friend . described detail blog post Nadieh Bremer.","code":"\nmat_friends=c(0,36,63,6,7,12,\n              36,0,7,20,26,14,\n              63,7,0,18,12,4,\n              6,20,18,0,17,14,\n              7,26,12,17,0,70,\n              12,14,4,14,70,0)\nrelations2= matrix(mat_friends,nrow=6,ncol=6,byrow=TRUE)\nfriends = c(\"Chandler\", \"Joey\", \"Monica\", \"Phoebe\", \"Rachel\", \"Ross\")\ndimnames(relations2) <- list(from = friends,\n                    to = friends)\ngroupColors = c(\"#cc99c9\", \"#9ec1cf\", \"#9ee09e\", \"#fdfd97\", \"#feb144\", \"#ff6663\")\nchorddiag(relations2, groupColors=groupColors, showTicks = 0)"},{"path":"chord-diagrams-using-circlize.html","id":"complex-chord-diagrams-canada-migration","chapter":"36 Chord diagrams using circlize","heading":"36.5 Complex Chord Diagrams: Canada Migration","text":"now look complex dataset categories directional. ’ll use Migration dataset carData package R shows number migrants travel 10 provinces Canada within period 1966-1971.","code":"\ncanada = Migration%>%select(source, destination, migrants)\nchordDiagram(canada,\n             grid.col = brewer.pal(10, 'Set3'),\n             transparency = 0.1,\n             link.lwd = .2,    # Set arc line width\n             link.border = 1) # Set arc border color to black)"},{"path":"chord-diagrams-using-circlize.html","id":"simplifying-data","chapter":"36 Chord diagrams using circlize","heading":"36.5.1 Simplifying data","text":"can simplify data ’re visualizing taking thinner chords. Perhaps ’re interested larger groups migrants. ’ll select threshold groups greater 12,000.greatly simplifies chord diagram makes individual chords bit easier distinguish. However, lose data. example, thresholding cut migration data fron Prince Edward Island.","code":"\ncanada_subset=canada%>%filter(migrants>12000)%>%group_by(source)\n\nchordDiagram(canada_subset,\n             grid.col = brewer.pal(9, 'Set3'),\n             transparency = 0.1,\n             link.lwd = .2,    # Set arc line width\n             link.border = 1) # Set arc border color to black)"},{"path":"chord-diagrams-using-circlize.html","id":"summary","chapter":"36 Chord diagrams using circlize","heading":"36.6 Summary","text":"Chord diagrams make attractive visualization tools depicting relationships data categories. great way communicate information right data. However, can fall prey -cluttering can make diagram difficult interpret. Caution taken deciding whether use chord diagram data. reasonable minimize number categories connections display chord diagram might helpful. Otherwise, using different type diagram alluvial, sankey, arc diagrams may appropriate.","code":""},{"path":"chord-diagrams-using-circlize.html","id":"sources-3","chapter":"36 Chord diagrams using circlize","heading":"36.7 Sources","text":"Chapter 14 circlize package book details chordDiagram function.Friends dataset researcher Alex Albright.chorddiag package Matthias Flor.Blog post adding color gradient symmetric data Nadieh Bremer.Storytelling using animated chord diagrams Nadieh Bremer.Five example uses chord diagrams.","code":""},{"path":"video-guide-to-reigniting-your-creavite-spark-for-visualizations.html","id":"video-guide-to-reigniting-your-creavite-spark-for-visualizations","chapter":"37 Video guide to reigniting your creavite spark for visualizations","heading":"37 Video guide to reigniting your creavite spark for visualizations","text":"Imani Oluwafumilayo Maliti","code":""},{"path":"video-guide-to-reigniting-your-creavite-spark-for-visualizations.html","id":"video","chapter":"37 Video guide to reigniting your creavite spark for visualizations","heading":"37.1 Video","text":"\nsituation embedded work device, following link video: https://youtu./Q4CwEbKsBsQ\n Note: hard hearing simply prefer subtitles, embedded video YouTube video equipped Closed Captioning make viewing experience accessible . ","code":""},{"path":"video-guide-to-reigniting-your-creavite-spark-for-visualizations.html","id":"motivation-explanation","chapter":"37 Video guide to reigniting your creavite spark for visualizations","heading":"37.2 Motivation & Explanation","text":"orig inal motivation project brainstorm viables activities people partake reignite creative spark creating data visualizations. culture, storyteller—always viewed data visualizations prime, modern way storytelling. trade, content creator. specialize editing videos creating graphics convey story, inspire people something great lives. Naturally, visualize data, try incorporate artistic cultural aspects training. strive make accessible visualizations also fun, engaging, intentional; however, many spaces data scientists prioritize creativity. Although understand importance practicality “professionalism”, strongly believe creative mindset major strength. result, created video explain three activities can aid one’s journey making creative visualizations.\nOriginally, wanted make video form Tik Tok. hope share platform make information accessible community needs boost impact. However, found 20 minutes content cut , edit, piece together. Ultimately, left final 6 minute video—long post Tik Tok. re-project, done shorter video; turn, enabled post . compensate missing information explanations, pair said video blog post goes detail activity. , feel like video came pretty well proud final products.","code":""},{"path":"video-guide-to-reigniting-your-creavite-spark-for-visualizations.html","id":"resources","chapter":"37 Video guide to reigniting your creavite spark for visualizations","heading":"37.3 Resources","text":"B., Du Bois William E, et al. W. E. B. Du Bois’s Data Portraits: Visualizing Black America. W.E.B. Du Bois Center University Massachusetts Amherst, 2018. “BOOK.” Dear Data, http://www.dear-data.com/thebook.","code":""},{"path":"tutorial-on-machine-learning-in-r.html","id":"tutorial-on-machine-learning-in-r","chapter":"38 Tutorial on Machine Learning in R","heading":"38 Tutorial on Machine Learning in R","text":"Priyanka Balakumar Hao Pan","code":""},{"path":"tutorial-on-machine-learning-in-r.html","id":"introduction-5","chapter":"38 Tutorial on Machine Learning in R","heading":"38.1 Introduction","text":"Machine learning branch computer science studies design algorithms can learn. Within machine learning, exists three main categories: supervised learning, unsupervised learning, reinforcement learning. ‘Machine Learning R’ cheat sheet explores basic supervised unsupervised machine learning techniques.","code":""},{"path":"tutorial-on-machine-learning-in-r.html","id":"motivation-6","chapter":"38 Tutorial on Machine Learning in R","heading":"38.2 Motivation","text":"several advantages implementing machine learning using R. Firstly, R provides easily explainable code especially helpful starting machine learning needing explain code. addition, R perfect language easy data visualization. corresponding functions different machine learning techniques allow user visualize understand performance results.link cheatsheet:https://github.com/Stephen-Pan30/EDAV-CommunityContribution/blob/main/Machine%20Learning%20Cheatsheet.pdf","code":""},{"path":"data-importance-visualization.html","id":"data-importance-visualization","chapter":"39 Data importance & visualization","heading":"39 Data importance & visualization","text":"Utsav Vachhani","code":""},{"path":"data-importance-visualization.html","id":"description","chapter":"39 Data importance & visualization","heading":"39.1 Description:","text":"document collection thoughts importance data visualization blog post format. article, go brief history data visualization came around purpose served. Additionally, connect utilized today present use cases. blog intended non-technical users, also introduce fundamental graphs common data visualizations. Finally, touch negative uses data visualization recent times analyze instances alert audience lookout.","code":""},{"path":"data-importance-visualization.html","id":"motivation-7","chapter":"39 Data importance & visualization","heading":"39.2 Motivation:","text":"Data visualization always interesting come business background. serves great complement rigorous analysis experimentation done data science , gives us concise way show insights appealing visualizations. also like introduces creative artistic component otherwise analysis heavy workload. noticed sometimes professionals, especially ones interested data science related fields, focus lot getting results enough time translate properly. want blog showcase data visualization influential today since lot people believe everything see online without proper research. Therefore, imperative least know basics identify inaccuracies shown. completed personal website, planning include blog article highlight significance data visualization.Link pdf","code":""},{"path":"edav-survey-and-analysis.html","id":"edav-survey-and-analysis","chapter":"40 EDAV Survey and Analysis","heading":"40 EDAV Survey and Analysis","text":"Varalika Mahajan Vrinda Bhat","code":""},{"path":"edav-survey-and-analysis.html","id":"project-proposal","chapter":"40 EDAV Survey and Analysis","heading":"40.0.1 Project Proposal","text":"","code":""},{"path":"edav-survey-and-analysis.html","id":"project-group-cc5","chapter":"40 EDAV Survey and Analysis","heading":"40.0.1.1 Project Group: CC5","text":"Varalika Mahajan: vm2695Vrinda Bhat: vgb2113","code":""},{"path":"edav-survey-and-analysis.html","id":"visualization-preference-analysis","chapter":"40 EDAV Survey and Analysis","heading":"40.0.1.2 Visualization Preference Analysis","text":"","code":""},{"path":"edav-survey-and-analysis.html","id":"overview-2","chapter":"40 EDAV Survey and Analysis","heading":"40.0.1.2.1 Overview","text":"Form Link: https://forms.gle/SYKeS6fqGktr5qrN8No responses: 80Data Collected: https://docs.google.com/spreadsheets/d/1apWvWCVmk4donteDaWEuMjDvHc1gJZxfrbSXeILNJyE/edit?usp=sharingFull Document Link: https://docs.google.com/document/d/1RKa9HXl6icDS5ci4K7oLATZjFOp4oWNzELslTATMJL8/edit?usp=sharing","code":""},{"path":"edav-survey-and-analysis.html","id":"goals","chapter":"40 EDAV Survey and Analysis","heading":"40.0.1.2.2 Goals:","text":"understand people’s opinions different visualizations: Different views graphs visualizations help us understand importance structural necessity existing -used graphs.Validate factors like age, work experience, gender impact opinion: Usually applying learned classroom concepts real-life work-related problems gives us better understanding meaningful business insights. Thus, checked factors like experience, age, gender showed huge impact choices.","code":""},{"path":"visualizing-graphs-and-networks.html","id":"visualizing-graphs-and-networks","chapter":"41 Visualizing graphs and networks","heading":"41 Visualizing graphs and networks","text":"Vritansh KamalLink presentation resources :- https://docs.google.com/presentation/d/1LOT2tx0TrxtLs3Dks0rEN04_WKYvzp9wCJ0amissUo0/edit#slide=id.p","code":""},{"path":"visualizing-graphs-and-networks.html","id":"motivations-1","chapter":"41 Visualizing graphs and networks","heading":"41.1 Motivations","text":"community contribution, decided give presentation visualizing networks EDAV. ’ve explored open-source tools, part research industry.Graphs can reveal highly complex relationships explored using right kind tools. involves visualizing graphs(networks) different traditional visualization methods. visualizations, able understand clusters graphs form, shortest path, extract relevant information data structured. discovered many use cases evergrowing industry Industrial IoT, bank transactions, blockchain. server-side tools can perform really well. challenge create visualizations browsers using javascript create scalable tangible products saas environment.visualizations make use user’s CPU/ GPU perform computation visualizing data. libraries like CytoscapeJS, D3Js-force graph, etc. don’t scale well size nodes edges graph increases. tools perform slowly browsers crash frequently size graphs increases.found library Vasco Asturiano open-source MIT License support rendering webGL-based graphs. helps solve problems ability interact GPU. can help visualize graphs ease order tens thousands nodes edges. also includes customizations adding images links nodes, adding particles emission, etc. helps bring virtual graphs much possible close real world.#Learning\nefficient library, forms abstraction top d3js components provides scalability. time explored built prototype using network dataset. key analyze networks identify relationships display accordingly.","code":""},{"path":"github-initial-setup.html","id":"github-initial-setup","chapter":"42 Github initial setup","heading":"42 Github initial setup","text":"Joyce Robbins","code":""},{"path":"github-initial-setup.html","id":"create-new-repo","chapter":"42 Github initial setup","heading":"42.1 Create new repo","text":"Create new repository copying template: http://www.github.com/jtr13/cctemplate following instructions README.","code":""},{"path":"github-initial-setup.html","id":"pages-in-repo-settings","chapter":"42 Github initial setup","heading":"42.2 Pages in repo settings","text":"Change source gh-pagesMay trigger GHA get work","code":""},{"path":"github-initial-setup.html","id":"add-packages-to-description-file","chapter":"42 Github initial setup","heading":"42.3 Add packages to DESCRIPTION file","text":"Need better process…Downloaded submissions CourseWorksCreate DESCRIPTION file. Add add dependencies projthis::proj_update_deps()https://twitter.com/ijlyttle/status/1370776366585614342Add Imports real DESCRIPTION file.Found problematic packages looking reverse dependencies packages failed install:devtools::revdep()Also used pak::pkg_deps_tree()Problems:magickrJava dependency qdap","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"tutorial-for-pull-request-mergers","chapter":"43 Tutorial for pull request mergers","heading":"43 Tutorial for pull request mergers","text":"","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"general","chapter":"43 Tutorial for pull request mergers","heading":"43.1 General","text":"following checklist steps perform merging pull request. point, ’re sure , request review one PR leaders.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-branch","chapter":"43 Tutorial for pull request mergers","heading":"43.2 Check branch","text":"PR submitted non-main branch.PR submitted main branch, provide instructions fix problem:Close PR.Close PR.Follow instructions forgetting branch committed pushed GitHub: https://edav.info/github#fixing-mistakesFollow instructions forgetting branch committed pushed GitHub: https://edav.info/github#fixing-mistakesIf trouble 2., delete local folder project, delete fork GitHub, start .trouble 2., delete local folder project, delete fork GitHub, start .Open new PR.Open new PR.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"examine-files-that-were-added-or-modified","chapter":"43 Tutorial for pull request mergers","heading":"43.3 Examine files that were added or modified","text":"ONE .Rmd file.ONE .Rmd file.additional resources resources/<project_name>/ folder.additional resources resources/<project_name>/ folder.files root directory besides .Rmd file.files root directory besides .Rmd file.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-.rmd-filename","chapter":"43 Tutorial for pull request mergers","heading":"43.4 Check .Rmd filename","text":".Rmd filename words joined underscores, white space. (Update: need branch name.).Rmd filename can contain lowercase letters. (Otherwise filenames sort nicely repo home page.)","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-.rmd-file-contents","chapter":"43 Tutorial for pull request mergers","heading":"43.5 Check .Rmd file contents","text":"file contain YAML header --- line.second line blank, followed author name(s).first line start single hashtag #, followed single whitespace, title.additional single hashtag headers chapter. (, new chapters created.)hashtag headers followed numbers since hashtags create numbered subheadings. Correct: ## Subheading. Incorrect: ## 3. Subheading.file contains setup chunk .Rmd file, contain setup label. (bookdown render fail duplicate chunk labels.)\n.e. use {r, include=FALSE} instead {r setup, include=FALSE}.\nSee sample .RmdLinks internal files must contain resources/<project_name>/ path, : ![Test Photo](resources/sample_project/election.jpg)file contain install.packages(), write functions, setwd(), getwd().’s anything else looks odd ’re sure, assign jtr13 review explain issue.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"request-changes","chapter":"43 Tutorial for pull request mergers","heading":"43.6 Request changes","text":"problems checks listed , explain pull request merged request changes following steps:, add changes requested label pull request.job pull request done now. contributors fix requests, review either move forward merge explain changes still need made.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"steps-to-merge-the-pr","chapter":"43 Tutorial for pull request mergers","heading":"43.7 Steps to Merge the PR","text":"click “Merge” things .","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"update-the-branch","chapter":"43 Tutorial for pull request mergers","heading":"43.7.1 Update the branch","text":"“Update Branch” visible toward end Conversation tab pull request, click . ensure working --date versions _bookdown.yml DESCRIPTION.Next make changes files contributor’s branch.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"add-the-filename-of-the-chapter-to-_bookdown.yml","chapter":"43 Tutorial for pull request mergers","heading":"43.7.2 Add the filename of the chapter to _bookdown.yml","text":"Go “Files Changed” copy filename .Rmd file.Open branch submitted PR following steps:\naccess PR branch:\n\nMake sure PR branch checking PR branch name shown (main):\nOpen branch submitted PR following steps:access PR branch:Make sure PR branch checking PR branch name shown (main):Add name new file single quotes followed comma labelled section (eg. Cheatsheets, Tutorials etc).Add name new file single quotes followed comma labelled section (eg. Cheatsheets, Tutorials etc).Save edited version.Save edited version.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"add-part-names-to-.rmd-for-every-first-article-in-part","chapter":"43 Tutorial for pull request mergers","heading":"43.7.3 (Add part names to .Rmd for every first article in part)","text":"adding first chapter PART.One person manage , otherwise hard keep project organized.every first article part, add chapter name top .Rmd file, propose changes. example like .\n","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"add-new-libraries-to-description.","chapter":"43 Tutorial for pull request mergers","heading":"43.7.4 Add new libraries to DESCRIPTION.","text":"Check .Rmd libraries needed. missing, add DESCRIPTION file contributor’s branch, manner edited _bookdown.yml file.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"merge-the-pull-request","chapter":"43 Tutorial for pull request mergers","heading":"43.7.5 Merge the pull request","text":"’re sure things correctly, assign one maintainers @jtr13 review merge PR.Return PR main page repo www.github.com/jtr13/...Return PR main page repo www.github.com/jtr13/...necessary resolve merge conflicts clicking resolve merge conflicts button:necessary resolve merge conflicts clicking resolve merge conflicts button:delete lines <<<<<<< xxxx, ======= >>>>>>>> main edit file desired. Click “Marked resolved” button green “Commit merge” button. –>Click “Merge pull request” “Confirm merge”. Add thank note perhaps emoji :tada:.","code":""},{"path":"tutorial-for-pull-request-mergers.html","id":"check-actions","chapter":"43 Tutorial for pull request mergers","heading":"43.7.6 Check Actions","text":"minutes, click Actions tabs check whether build successful: green dot indicates successful run, red X indicates failed run.minutes, click Actions tabs check whether build successful: green dot indicates successful run, red X indicates failed run.Check log figure went wrong, can, fix . ’re sure , problem, just open issue linking failed run others can help (important can fix problems quickly). (click revert merge).Check log figure went wrong, can, fix . ’re sure , problem, just open issue linking failed run others can help (important can fix problems quickly). (click revert merge).","code":""}]
